[{"categories":["theory"],"content":"介绍感知机","date":"2023-02-02","objectID":"/deeplearning_01_perceptron/","tags":["deeplearn"],"title":"深度学习:感知机","uri":"/deeplearning_01_perceptron/"},{"categories":["theory"],"content":"感知机 最近陈硕在给我授课，讲深度学习，第一节内容主要是感知机 1. 什么是感知机 感知机是二分类的线性模型，其输入是实例的特征向量，输出的是实例的类别，分别为0和1，属于判别模型。感知机接收多个输入信号，输出一个信号。 下图是一个接收两个输入信号的感知机的例子。 其中$x_{1}、 x_{2}$是输入信号，$y$是输出信号， $w_{1}、 w_{2}$是权重。图中的○称为“神经元”或者“节点”。输入信号被送往神经元时，会被分别乘以固定的权重。神经元会计算传送过来的信号的总和（$w_{1}x_{1} + w_{2}x_{2}$），只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活” 。这里将这个界限值称为阈值，用符号$\\theta$表示。 把上述内容用数学式来表示，就是下面这个式子 $$ y = \\begin{cases} 0 \\ (w_{1}x_{1} + w_{2}x_{2} \\le \\theta)\\ 1 \\ (w_{1}x_{1} + w_{2}x_{2} \\gt \\theta)\\ \\end{cases} \\ (1.1) $$ 2. 感知机模型 感知机是有生物学上的一个启发，我们的大脑可以认为是一个神经网络，这么一个生物的神经网络是由神经元组织起来的，在这个生物的神经网络里边，神经元的一些工作机制就是通过这样一个下面图的结构来运行的。首先接收到一些信号，这些信号通过这些树突组织，树突组织接收到这些信号送到细胞里边的细胞核，这些细胞核对接收到的这些信号（如光、声音）到树突的时候会产生一些微弱的生物电，从而形成一些刺激，那么在细胞核里边对这些收集到的接收到的刺激进行综合的处理，当它的信号达到了一定的阈值之后，它就会被激活，从而产生一个刺激的输出，那么就会形成一个我们大脑接收到的进一步的信号，再通过轴突来输出计算的，这就是我们人脑的一个神经元进行感知的时候大致的一个工作原理。 结合神经元模型有人提出了经典的抽象模型：M-P神经元模型，如下图 而感知机模型是从神经元模型发展过来的。感知机是由两层神经元组成的一个简单模型。只有输出层是M-P 神经元，即只有输出层神经元进行激活函数处理，也称为功能神经元（ functional neuron）；输入层只是接受外界信号（样本属性）并传递给输出层（输入层的神经元个数等于样本的属性数目），而没有激活函数。 (1.1)公式对应 将输入和权重扩展到多维，则式子(1.1)可以表示为 $$ y = \\begin{cases} 0 \\ (\\sum w_{i}x_{i} - \\theta \\le 0)\\ 1 \\ (\\sum w_{i}x_{i} - \\theta \\gt 0)\\ \\end{cases} \\ (2.1) $$ 其中激活函数为越阶函数 3. 感知机的应用 感知机可以用来表示简单的逻辑电路，逻辑电路是有两个输入和一个输出的门电路,最简单的例子当然是逻辑电路当中的与或门。与门、或门、非门其实都差不多，都是有两个输入和一个输出。下图为与门的真值表 $x_1$ $x_2$ $y$ 0 0 0 1 0 0 0 1 0 1 1 1 下面考虑用感知机来表示这个与门,需要做的就是确定公式(1.1)成立时能满足图中的真值表的$(w_1,w_2,\\theta)$的值 $x_1$ $x_2$ $y$ (1.1)代入 阈值条件 0 0 0 $w_1 * 0 + w_2 * 0 -\\theta \\lt 0$ $\\theta \\gt 0$ 0 1 0 $w_1 * 0 + w_2 * 1 -\\theta \\lt 0$ $\\theta \\gt w_2$ 1 0 0 $w_1 * 1+ w_2 * 0 -\\theta \\lt 0$ $\\theta \\gt w_1$ 1 1 1 $w_1 * 1 + w_2 * 1 -\\theta \\lt 0$ $\\theta \\le w_1 + w2$ 很明显该表有值，如$w_1 = w_2 且 \\theta = 1.5 w_1$时 同理，或门和非门也是可以表示的 或门： $x_1$ $x_2$ $y$ (1.1)代入 阈值条件 0 0 0 $w_1 * 0 + w_2 * 0 -\\theta \\lt 0$ $\\theta \\gt 0$ 0 1 0 $w_1 * 0 + w_2 * 1 -\\theta \\ge 0$ $\\theta \\le w_2$ 1 0 0 $w_1 * 1+ w_2 * 0 -\\theta \\ge 0$ $\\theta \\le w_1$ 1 1 1 $w_1 * 1 + w_2 * 1 -\\theta \\ge 0$ $\\theta \\le w_1 + w2$ 与非门： $x_1$ $x_2$ $y$ (1.1)代入 阈值条件 0 0 1 $w_1 * 0 + w_2 * 0 -\\theta \\gt 0$ $\\theta \\lt 0$ 0 1 1 $w_1 * 0 + w_2 * 1 -\\theta \\gt 0$ $\\theta \\lt w_2$ 1 0 1 $w_1 * 1+ w_2 * 0 -\\theta \\gt 0$ $\\theta \\lt w_1$ 1 1 0 $w_1 * 1 + w_2 * 1 -\\theta \\le 0$ $\\theta \\ge w_1 + w2$ 但异或门没法处理 $x_1$ $x_2$ $y$ (1.1)代入 阈值条件 0 0 0 $w_1 * 0 + w_2 * 0 -\\theta \\lt 0$ $\\theta \\gt 0$ 0 1 0 $w_1 * 0 + w_2 * 1 -\\theta \\ge 0$ $\\theta \\le w_2$ 1 0 0 $w_1 * 1+ w_2 * 0 -\\theta \\ge 0$ $\\theta \\le w_1$ 1 1 1 $w_1 * 1 + w_2 * 1 -\\theta \\lt 0$ $\\theta \\gt w_1 + w2$ 表中的条件明显矛盾，故不存在解 事实上，感知机是一种判别式的线性分类模型，可解决与、或、非这样的简单的线性可分问题，但感知机的局限性就在于它只能表示由一条直线分割的空间，对于异或问题不能用一条直线解决，如下图 4. 多层感知机 感知机可以通过“叠加层”来实现异或门，如下图 将最左边的一列称为第0层，中间的一列称为第1层，最右边的一列称为第2层。其中s1为与非门，s2为或门，s1和s2再做与运算，则该网络能够表示异或门。 $x_1$ $x_2$ $s_1$ $s_2$ $y$ 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 异或门因为叠加了2层感知机，因而称为\"多层感知机\"，当然加了一层后已经不能称为感知机了，已经算神经网络了，这个下一节展开。 ","date":"2023-02-02","objectID":"/deeplearning_01_perceptron/:0:1","tags":["deeplearn"],"title":"深度学习:感知机","uri":"/deeplearning_01_perceptron/"},{"categories":["notes"],"content":"记录go1.x error相关内容","date":"2022-05-31","objectID":"/notes-007-golang-error/","tags":["golang"],"title":"golang error","uri":"/notes-007-golang-error/"},{"categories":["notes"],"content":"go error 记录go1.x error相关内容 1. 原生error error 只是一个普通的interface,在buildin.go 里给出了定义: // The error built-in interface type is the conventional interface for // representing an error condition, with the nil value representing no error. type error interface { Error() string } 当返回值为nil时，表示没有错误，所以调用方需要通过类似err != nil的方式来处理。 该接口只有一个方法，返回具体消息内容，可以使用errors.New(text string) 来返回一个error对象，入参只有一个string，为具体消息内容。如bufio.go内置的错误 用该方法返回的对象，即使文本相同，返回的error对象也是不同的，从源码中可以知道原因： // New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return \u0026errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 如上，该方法返回的是errorString结构体对象的指针，因而是用地址作为比较。使用该种方式也能保证预定义的error只有一个，避免值复制。 PS:1.为了防止自定义error过多，可以像基础库中设计的类似，在包内定义统一的error，以达到公用的目的，如上图的bufio.go中的内置错误 也可以通过实现error接口以实现自定义error类型，同时还能传递上下文信息，如： type MyError struct { Msg string Type string } func (err *MyError) Error() string { return fmt.Sprintf(\"%s:%s\",err.Type,err.Msg); } 2. error的判定方式 2.1 Sentinel error 哨兵error，即预定义error，在这种方式中，错误被定义成了被包导出的变量.如：if err == io.EOF {}，这里的io.EOF便是哨兵error.可以通过判断error是否跟这个错误进行比较，就可以知道此处出现的error是否属于这个错误. 2.2 Error types 通过断言转换来确定error的原始类型以达到判定的目的，例如： type MyError struct { Msg string } func (e *MyError) Error() string { return fmt.Sprintf(\"%s\",e.Msg) } err := something() switch err := err.(type) { case nil: // call succeeded, nothing to do case *MyError: fmt.Println(“error occurred on line:”, err.Line) default: // unknown error } 无论是对于哨兵错误还是错误类型断言，使用方都需要了解其使用包的错误定义细节，而包的提供方则需要提供可能的错误类型，加强了包之间的耦合，当错误类型很多时，维护会变得困难。 2.3 Opaque errors 不透明错误处理：通过行为来断言错误，而不是类型。如net包里定义的错误，通过判断Temporary或者Timeout来判断具体是什么错。 package net type Error interface { error Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary? } // main.go if nerr, ok := err.(net.Error); ok \u0026\u0026 nerr.Temporary() { time.Sleep(1e9) continue } if err != nil { log.Fatal(err) } 3. error和panic 关于error和panic设计上的区别，可以看下Dave Cheney的博客https://dave.cheney.net/tag/panic。大体意思就是，Go设计者觉得Exception这个东西，在设计上经历过C、C++后，在Java中总算是上道了，但还是被乱用了。在Java中，不管异常是大是小，不管是简单还是严重，都往上抛给调用方，导致调用方无脑通过try…catch…finally对异常进行了捕获，没有针对异常的严重性分开处理。同时try…catch…finally这种方式将异常与流程控制混在一起会很容易使得代码变得混乱。 Go设计者则认为错误(error)和异常(panic)是不同的，error是指意料中的问题，如文件不存在这种逻辑条件上的错误；panic是指意料外的问题，如数组越界这种系统异常。对于error，可以通过多值返回的形式通知调用方，上游需要显示处理；而panic的处理的捕获则需要借助defer和recover，类似于catch和finally的效果。 panic的捕获方式如下: func main() { fmt.Println(\"c\") defer func() { // 必须要先声明defer，否则不能捕获到panic异常 fmt.Println(\"d\") if err := recover(); err != nil { fmt.Println(err) // 这里的err其实就是panic传入的内容 } fmt.Println(\"e\") }() f() //开始调用f fmt.Println(\"f\") //这里开始下面代码不会再执行 } func f() { fmt.Println(\"a\") panic(\"异常信息\") fmt.Println(\"b\") //这里开始下面代码不会再执行 } -------output------- c a d 异常信息 e 通过捕获panic，使得必要时程序不至于中断，比如web服务，应该展示错误给到前端，而不是退出程序。 当然个人觉得这两个是相对的，毕竟函数里什么场景返回error，什么场景抛出panic，都是明确的。同时，作为函数提供者无法预测使用者的业务场景，可能某些error对于上层业务来说就是panic。 4. github/pkg/errors 上面的例子看出，在打印eroor时，只打印了错误信息，从实现上也可以看出来，不像java的exception一样会存储上下文堆栈信息，因而对定位问题不太友好。当然我们可以手动的在每个函数的调用入口处打印日志来模拟错误调用栈，只是比较低效，也比较挫，代码也不好看。这里介绍一个比较常用的组件github/pkg/errors，可以实现打印错误信息时附加堆栈信息。 先来看个例子，常规的error处理时，是这样 func callF() error { //模拟抛出error return errors.New(\"src error\") } err := callF() if err != nil { return err } 直接把error抛给了上层，这时候上下文是不带堆栈信息的，因而上层打印时只有错误信息的字符串，而pkg/erros使用时是这样的 err := callF() if err != nil { return errors.Wrap(err, \"faile when use\") } 通过Wrap方法，附加了额外的错误信息。同时，但使用fmt.Printf(\"%+v\\n\", err)时，可以查看调用堆栈。如下为本机测试调用栈内容 官方的demo还展示了如何获取原始error以及获取调用栈的方式，这里不再赘述。下面主要介绍下pkg/errors的具体实现。 下面是整个包的结构关系，使用了https://github.com/jfeliu007/goplantuml提供的工具生成。这个工具展示了大致的关系，有些细节没有展示出来，下面会同时说明。 先简单介绍下各个结构体体 error就不用说了 uintptr:是golang的内置类型，是能存储指针的整型，能用于指针运算； runtime.Callers可用来获取当前goroutine函数调用栈的程序计数器及其相关信息，返回相应函数指针的地址值，结果存在[]uintptr中,可以通过uintptr获得对饮函数指针的函数名、行号、文件名 Frame:uintptr的别名，由于要存储调用链的函数指针，故名帧，个人觉得只是为了让意思更贴切易懂 stack:[]uintptr的别名，表示调用栈 StackTrace:[]Frame的别名，表示栈帧，类似于Fr","date":"2022-05-31","objectID":"/notes-007-golang-error/:1:0","tags":["golang"],"title":"golang error","uri":"/notes-007-golang-error/"},{"categories":["srccode"],"content":"这节介绍Provider的启动过程","date":"2020-12-10","objectID":"/dubbo_03_provider/","tags":["doubbo"],"title":"Dubbo Provider启动都做了什么","uri":"/dubbo_03_provider/"},{"categories":["srccode"],"content":" 这节介绍Provider的启动过程，既服务发布。 先从Demo看起： public class ApplicationApi { public static void main(String[] args) throws Exception { ServiceConfig\u003cDemoServiceImpl\u003e service = new ServiceConfig\u003c\u003e(); service.setApplication(new ApplicationConfig(\"dubbo-demo-api-provider\")); service.setRegistry(new RegistryConfig(\"zookeeper://127.0.0.1:2181\")); service.setInterface(DemoService.class); service.setRef(new DemoServiceImpl()); service.export(); System.in.read(); } } 上面Demo主要做了几件事 新建一个ServiceConfig对象，既服务配置对象 为服务配置设置ApplicationConfig，既服务对应的项目配置 为服务配置设置RegistryConfig，既注册中心配置 指定服务关联的接口DemoService 指定服务关联的实现DemoServiceImpl 调用ServiceConfig的export方法暴露服务 这里重点关注export方法。 在这之前先说下服务暴露的主要流程：一个应用(ApplicationConfig)包含很多服务，一个服务(ServiceConfig)需要服务提供者(ProviderConfig)通过某种协议(ProtocolConfig)将自身的信息注册到注册中心(RegistriesConfig)，这就是服务暴露主要做的事情。 export方法主要围绕上面几个组件展开。 1.设置默认配置 export会先检查当前环境是否准备就绪，主要是检查各组件配置，如ProviderConfig、ProtocolConfig、ApplicationConfig、ModuleConfig、RegistriesConfig、MonitorConfig等。对于某些为空的配置项则会使用默认值，如： 创建ProviderConfig，设置prefix，如果有传则使用原值，没有则新建一个ProviderConfig，并设置prefix为dubbo.provider 创建ProtocolConfig，设置prefix，如果有则使用原值，如果没有设置则新建一个ProtocolConfig，使用默认协议dubbo,并设置prefix为dubbo.protocol. 以上各配置项都继承自AbstractConfig 各配置的实例对象会托管到ConfigMananger，同时被ServiceConfig引用。各实例初始化后的主要值如下： PS:当id为空时，会设置默认值为default。 2.暴露服务 ServiceConfig准备完配置后就开始进行服务的暴露，主要内容为doExportUrls方法。 该方法分为两个过程： 加载所有的注册中心配置RegistriesConfig 遍历所有的协议配置ProtocolConfig，使用各种协议将服务本身注册到所有的注册中心 2.1 加载注册中心配置 加载ServiceConfig指定的所有注册中心配置对象，并以URL的形式返回。需要提及的一点时，Dubbo中为了增加统一的拦截处理，会把URL的协议改为registry，等拦截处理完后再修改回来。 如开头例子的URL会从 zookeeper://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=dubbo-demo-api-provider\u0026dubbo=2.0.2\u0026pid=1204\u0026timestamp=1606640163895 修改为： registry://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=dubbo-demo-api-provider\u0026dubbo=2.0.2\u0026pid=1204\u0026registry=zookeeper\u0026timestamp=1606640163895 PS：Dubbo使用URL用于在各个扩展点之间传递数据，一个标准的 URL 格式至多可以包含如下的几个部分 protocol://username:password@host:port/path?key=value\u0026key=value 2.2 注册服务 ServiceConfig会遍历所有的协议配置ProtocolConfig，对于每种协议，会将服务自身注册到所有配置的注册中心，过程如下： 前面都在准备URL的各种参数，以便于构造ServiceConfig对应的URL对象，开头例子Service对应的URL为： dubbo://10.35.25.111:20880/org.apache.dubbo.demo.DemoService?anyhost=true\u0026application=dubbo-demo-api-provider\u0026bind.ip=10.35.25.111\u0026bind.port=20880\u0026deprecated=false\u0026dubbo=2.0.2\u0026dynamic=true\u0026generic=false\u0026interface=org.apache.dubbo.demo.DemoService\u0026methods=sayHello\u0026pid=18164\u0026release=\u0026side=provider\u0026timestamp=1606657116399 构造完URL后便正式进入服务暴露的过程，包括本地暴露和远程暴露。这两种方式都是可选的，可以通过scope参数来控制，可选值包括 none：不对外进行暴露 remote：只暴露远程服务 local：只暴露本地服务 空：同时暴露本地服务和远程服务（默认值） 2.2.1 暴露本地服务 指暴露在同一个JVM里面，不用通过调用注册中心如ZK来进行远程通信。例如：在同一个服务，自己调用自己的接口，就没必要进行网络IP连接来通信。如下为本地暴露的内容 本地服务暴露给注册中心的URL为: injvm://127.0.0.1/org.apache.dubbo.demo.DemoService?anyhost=true\u0026application=dubbo-demo-api-provider\u0026bind.ip=10.35.25.111\u0026bind.port=20880\u0026deprecated=false\u0026dubbo=2.0.2\u0026dynamic=true\u0026generic=false\u0026interface=org.apache.dubbo.demo.DemoService\u0026methods=sayHello\u0026pid=23480\u0026release=\u0026side=provider\u0026timestamp=1606665693215 本地暴露时主要做几件事： 拷贝原URL，将协议转为injvm 设置URL的host为127.0.0.1，端口为0 将本地URL转为Exporter 2.2.2 暴露远程服务 指暴露给远程客户端的IP和端口号，以便通过网络来实现通信。在原URL基础上，会尝试再增加一些可选的参数，如监控:monitor，invoker代理:proxy，最后Service对外开放的URL为： dubbo://10.35.25.111:20880/org.apache.dubbo.demo.DemoService?anyhost=true\u0026application=dubbo-demo-api-provider\u0026bind.ip=10.35.25.111\u0026bind.port=20880\u0026deprecated=false\u0026dubbo=2.0.2\u0026dynamic=true\u0026generic=false\u0026interface=org.apache.dubbo.demo.DemoService\u0026methods=sayHello\u0026pid=23480\u0026release=\u0026side=provider\u0026timestamp=1606665693215 然后会将该Service的URL添加到Registry的URL中，同时使用Registry的URL转为Exporter。 从2.7.0版本开始，增加了服务元数据存储，将原来注册到注册中心的URL进行减负，抽取一些参数存储到元数据存储中，减少注册中心的负担。 3. 代理逻辑 Dubbo可以选择多种通信协议，也可以选择不同的注册中心，为了统一处理，抽象出了一个Proxy层和Protocol层。不管是本地暴露，还是远程暴露，都涉及到ProxyFactory和Protocol接口，二者都是动态来适配具体的代理插桩逻辑和协议实现逻辑,这两个都用到了上一节提到的自适应扩展机制SPI。 3.1 ProxyFactory ProxyFactory的定义如下： @SPI(\"javassist\") public interface ProxyFactory { @Adaptive({PROXY_KEY}) \u003cT\u003e T getProxy(Invoker\u003cT\u003e invoker) throws RpcException; @Adaptive({PROXY_KEY}) \u003cT\u003e T getP","date":"2020-12-10","objectID":"/dubbo_03_provider/:0:0","tags":["doubbo"],"title":"Dubbo Provider启动都做了什么","uri":"/dubbo_03_provider/"},{"categories":["notes"],"content":"总结下之前看到的一些关于MySQL索引原理的内容，好记性不如烂笔头","date":"2020-11-09","objectID":"/notes_005_mysql_innodb/","tags":["work"],"title":"MySQL InnoDB索引那点事儿","uri":"/notes_005_mysql_innodb/"},{"categories":["notes"],"content":"总结下之前看到的一些关于MySQL索引原理的内容，好记性不如烂笔头。 1. B+树 我们知道InnoDB的索引是以B+树的形式组织的。B+树是一种树数据结构，是一个n叉树，每个节点通常有多个孩子，一颗B+树包含根节点、内部节点和叶子节点。 下面是B+树的示例： B+树把所有的数据都存储在叶子节点中，内部节点只存放关键字和孩子指针，因此最大化了内部节点的分支因子，所以B+树的遍历也更加高效。 B+树通常用于数据库和操作系统的文件系统中，其特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+树适合作为数据库的基础结构，完全是因为计算机的内存-机械硬盘两层存储结构。内存可以完成快速的随机访问（随机访问即给出任意一个地址，要求返回这个地址存储的数据）但是容量较小。而硬盘的随机访问要经过机械动作（1磁头移动、2盘片转动），访问效率比内存低几个数量级，但是硬盘容量较大。典型的数据库容量大大超过可用内存大小，这就决定了在B+树中检索一条数据很可能要借助几次磁盘IO操作来完成。 使用B+树作为索引结构有如下优势： 1.B+树非叶子节点上是不存储数据的，仅存储键值**（聚集索引）**。 之所以这么做是因为在数据库中页的大小是固定的，InnoDB中页的默认大小是 16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。 另外真实数据库中的B+树应该是非常扁平的，其阶数是等于键值的数量的，如果我们的B+树一个节点可以存储1000个键值，那么3层B+树可以存储1000×1000×1000=10亿个数据。一般根节点是常驻内存的，所以一般我们查找10亿数据，只需要2次磁盘IO。 2.B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。因而B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。 2.InnoDB页存储结构 2.1 存储结构 存储引擎中所有数据都被存储在表空间中，表又由Segment(段)、Extent(区)、Page(页)组成，如下为MySQL技术内幕中介绍的InnoDB逻辑存储结构： 1.表空间：在默认情况下，InnoDB存储引擎有一个共享表空间 ibdata1，所有的数据都放在这个表空间内.如果启用了innodb_file_per_table参数，每张表的表空间只存放数据、索引和插入缓冲bitmap页，其他的数据如undo信息、插入缓冲、double write buffer等还是存放在共享表空间中。 2.段：常见的段有数据段、索引段、回滚段等。数据段是B+树的叶子结点，索引段为B+树的非叶子结点 3.区：区由连续页组成，每个区大小固定为1MB，为保证区中page的连续性通常InnoDB会一次从磁盘中申请4-5个区。在默认page的大小为16KB的情况下，一个区则由64个连续的page。 4.页：页是InnoDB磁盘管理的最小单位也叫做块，默认大小为16kB。常见的页有数据页、undo页、系统页等。类型为B-tree Node的页存放的即是表中行的实际数据 5.行：InnoDB存储引擎中数据是按行进行存放的，每个页中最多存放7992行记录 2.2 页结构 Page是整个InnoDB存储的最基本构件，也是InnoDB磁盘管理的最小单位，与数据库相关的所有内容都存储在这种Page结构里。每个Page使用一个32位的int值来唯一标识，这也正好对应InnoDB最大64TB的存储容量（16Kib * 2^32 = 64Tib）。一个Page的结构如下所示： 涉及的内容包括： 页头(Page Header)：记录页面的控制信息，包括页的左右兄弟页面指针、页面空间使用情况等 Infimum(最小虚记录)/Supremum(最大虚记录)：两个固定位置存储的虚记录，本身并不存储数据。最小虚记录比任何记录都小，而最大虚记录比任何记录都大。这两个用来代表开头结尾的Record存储在System Records的段里,这个System Records和User Records是两个平行的段。 记录堆(Record Heap)：也称为User Records,以链表的形式存储一条条行记录，表示页面已分配的记录空间，也是索引数据的真正存储区域。记录堆分为两种，即有效记录(黄色)和已删除记录(紫色)。有效记录就是索引正常使用的记录，而已删除记录表示索引已经删除，不再使用的记录。随着记录的更新和删除越来越频繁，记录堆中已删除记录将会越多，即会出现越来越多的空洞（碎片）。这些已删除记录连接起来，就会成为页面的自由空间链表。 未分配空间(Free Space)：指页面未使用的存储空间，随着页面不断使用，未分配空间将会越来越小。当新插入一条记录时，首先尝试从自由空间链表中获得合适的存储位置（空间足够），如果没有满足的，就会在未分配空间中申请。 Slot区：也称为Page Directory，页中某些记录的相对位置，用于提升查询效率。slot是一些页面有效记录的指针，每个slot占两个字节，存储了记录相对页面首地址的偏移。如果页面有n条有效记录，那么slot的数量就在n/8+2~n/4+2之间，它是记录页面有序和二分查找的关键。 页尾(Page Tailer)：页面最后部分，占8个字节，主要存储页面的校验信息。 上面提到，页头里包含了唯一id，页的左右兄弟页面指针，从而可以将页抽象为如下结构： Page的头部保存了两个指针，分别指向前一个Page和后一个Page，根据这两个指针我们很容易想象出Page链接起来就是一个双向链表的结构。 InnoDB的行数据和索引的存储都位于User Records，存在4种不同的Record，它们分别是： 主键索引树非叶节点 主键索引树叶子节点 辅助键索引树非叶节点 辅助键索引树叶子节点 这4种节点的Record格式有一些差异，但是它们都存储着Next指针指向下一个Record。User Record在Page内以单链表的形式存在，最初数据是按照插入的先后顺序排列的，但是随着新数据的插入和旧数据的删除，数据物理顺序会变得混乱，但他们依然保持着逻辑上的先后顺序。 将该结构扩展到多个页就有如下形式： 根据最大最小虚记录将多个页内记录的顺序连接起来。 2.3 页内查询 前面提到User Records中的记录是以单链表的形式存在，这样在插入一条记录时，只要修改前后两条记录的指针就行，这样就可以避免记录的移动同时保证了有序性。但是，带来的问题是，链表是无法在对数时间内使用二分查找，这样的设计会导致查询效率低下。为了高效的在一个页中查找指定的一条记录，InnoDB使用Page Directory提供了解决方案。 InnoDB会将一个页中的所有记录划分成若干个组，每组4-8个记录。将每个组最后一个记录相对于第一个记录的地址偏移量（可以定位到真实数据记录）提取出来存放在页中一个叫做Page Directory的数组中，数组中的元素就是这些地址偏移量，也称为槽(slot)。 所以在一个页中根据主键查找记录是很快的，步骤为： 二分法确定该记录所在的槽，并找到该槽所在分组中主键值最小的那条记录。 通过next_record属性遍历单链表找到记录 对于插入操作，首先通过查询的方式确定插入的位置，在自由空间链表或未分配空间中获得空间并写记录内容，slot所指向的链高度加1，同时维护好原链表的关系。 插入记录后，如果Slot支链高度超过8，那么就将该支链拆分为两个子链，同时多申请一个slot（平移此slot及其后面的空间）。 3. 索引结构 MySql提供了两种索引存储方式，一种叫做聚簇索引，一种叫做非聚簇索引。 3.1. 聚簇索引 行数据和主键B+树存储在一起，辅助键B+树只存储辅助键和主键，主键和非主键B+树几乎是两种类型的树。InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上。 考虑如下的数据： 其中Id作为主索引，Name作为辅助索引，则聚集索引的结构如下： 当通过主键索引查找数据时，会连带返回对应的记录。当通过辅助键查找数据时，根据索引找到叶子节点中的主键值，根据主键值再到聚簇索引中得到完整的一行记录，该行为也即我们常说的回表。需要说明一点的是，对于联合主键，当存在辅助索引时，辅助索引也会保留联合主键的多个字段，从而影响到索引文件的大小。 下面以开头的B+树为例，再结合Page结构，展示其内部组织方式（只展示其中一部分）： 注意Page和B+树节点之间并没有一一对应的关系，Page只是作为一个Record的保存容器，它存在的目的是便于对磁盘空间进行批量管理。 3.2 非聚簇索引 主键B+树在叶子节点存储指向真正数据行的指针，而非主键。MyISAM使用的是非聚簇索引，非聚簇索引的两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已， 对于上面的表数据，非聚集索引的结构如下： 非聚集索引中，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。 3.3 联合索引 联合索引又叫复合索引。对于复合索引，Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分，即我们常说的最左前缀匹配原则。由于联合索引的匹配是从做往右进行，且不能跳过中间列，因而在设计联合索引时最好","date":"2020-11-09","objectID":"/notes_005_mysql_innodb/:0:0","tags":["work"],"title":"MySQL InnoDB索引那点事儿","uri":"/notes_005_mysql_innodb/"},{"categories":["notes"],"content":"搜罗了一下常见的分布式唯一ID方案","date":"2020-09-20","objectID":"/notes_004_distrubte_id/","tags":["work"],"title":"常见的分布式唯一ID方案","uri":"/notes_004_distrubte_id/"},{"categories":["notes"],"content":"最近看一个新系统，发现里面有很多场景用到唯一id，便搜罗了一下常见的方案。 对于分布式id，需要满足下面的基本要求 全局唯一 趋势递增 1. UUID UUID（Universally Unique Identifier）全局唯一标识符，定义为一个字符串主键，采用32位数字组成，编码采用16进制，定义了在时间和空间都完全惟一的系统信息。 UUID的编码规则： 1~8位采用系统时间，在系统时间上精确到毫秒级保证时间上的惟一性； 9~16位采用底层的IP地址，在服务器集群中的惟一性； 17~24位采用当前对象的HashCode值，在一个内部对象上的惟一性； 25~32位采用调用方法的一个随机数，在一个对象内的毫秒级的惟一性。 通过以上4种策略可以保证惟一性。在系统中需要用到随机数的地方都可以考虑采用UUID算法。 UUID可能会是大家很快想到的，因为它现成，全球唯一，不需要中心协调器来控制唯一。主流语言中都会有内置现成的api直接生成。但却不推荐，因为它 无序，没有自增趋势，作为主键插入效率低下（如MySql） 过长，浪费存储空间 无法存储业务逻辑，可读性差，当然如果你的id没有长度限制，可以通过拼接前缀/后缀来增加信息 2. 中心协调器类 可以引入中心协调器类，通过该系统自带的特性来完成id的生成和分配。 2.1 数据库自增主键 Don’t say so match，大家应该都用过，通过DB的auto_increment自增主键来控制id的唯一以及有序，使用简单。当然缺点也是明显的，依赖DB存在单点问题，当然可以通过主从模式来解决单点问题。 网上还有有人介绍了自增主键的另一种模式，如下 引入多实例，为每个实例设置初始值以及固定的步长来降低单点的风险，以及分摊DB压力。当然只是降低，单点问题还是存在的，同时还不容易扩容，也需要客户端做支持。对于趋势递增则需要ID服务来维持，它需要轮训访问后端的各个DB实例，以维持趋势递增的特性。 2.2 Redis Redis提供了incr命令可以实现id的原子性自增，能够达到类似DB的auto_increment的效果。使用Redis需要注意持久化的问题，避免Redis重启后数据丢失导致id重复。 2.3 ZooKeeper zookeeper自带生成顺序节点的功能，可以使用其生成顺序节点的编号来作为id。客户端创建完节点后，通过解析返回的节点名来获得当前分配的id。 中心协调器类其实都差不多，将id的生成转到中心协调器上。 3. 数据库号段 数据库号段的方式如下： 涉及的表结构如下： type字段用来区分不同的业务，隔离不同业务之间的相互影响；max_id字段则表示当前业务类型已经分配的最大id值，下一次分配则从该值开始；step为步长；state用来做锁控制，这里用的是乐观锁，也可以不用该字段，改为行锁(select ... for update)。 以bizType1为例，数据库中记录着bizType1的下一个id起始值3000，以及对应的步长1000。当应用启动后首次使用时，尝试去获取bizType1这条记录的锁，获取到锁的应用读取max_id和step的值，同步更新到内存，然后将max_id的值加上步长后更新回表中，这个值便是下一个id的起始值。当应用实例内存中的步长没有消耗完前，直接通过应用内部自己自增返回id，避免频繁请求DB。当应用消耗完后则再次访问DB同步更新max_id和step，反复循环下去。 开头讲到的最近接触的新系统用的就是号段的方式来生成唯一id，但它不是用乐观锁的方式而是用行锁。测试环境给的步长比较小，刚好测试同学在做压测造数据的时候并发开的大，导致抢锁锁频繁抛异常了。当然如果使用乐观锁也会存在饥饿的情况，会导致一直获取不到锁而一直忙等。 看完上面的过程，其实核心点在于有个第三方系统来提供锁和存储以及应用端的配合，所以其实不用DB也可以实现该功能。 4. Snowflake雪花算法 相信大家都听过这个算法，都知道这个算法是由Twitter提出来的，既然大家都知道就不多说了，那大家也都看过下面这张图： 该算法使用一个64 bit的整型数据，包括 首位不用的1个bit(最高位是标识位，为1表示为负数，不使用) 41个bit的毫秒级时间(41位的长度可以使用69年)， 10个bit的工作机器id，包括5个bit的datacenterId和5个bit的workerId(10位的长度最多支持部署1024个节点） 12个bit的毫秒内的计数（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号） 一共加起来刚好64位，为一个Long型。 Snowflake算法核心把时间戳，工作机器id，序列号组合在一起。整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和机器ID作区分），并且效率较高，经测试，snowflake每秒能够产生26万id左右，完全满足需要。 Snowflake算法中41个bit的时间戳完全依赖于时间的，如果有时钟回拨的情况发生，则会生成重复的id。时钟回拨涉及两种情况 实例停机→时钟回拨→实例重启→计算ID 实例运行中→时钟回拨→计算ID 对于时间回拨，网上给出了很多处理方法，包括： 如果发现有时钟回拨，时间很短比如5毫秒,就等待，然后再生成；或者就直接报错，交给业务层去处理 可以找2bit位作为时钟回拨位，发现有时钟回拨就将回拨位加1，达到最大位后再从0开始进行循环 实例启动后，改用内存生成时间，如百度开源的UidGenerator，该方式可以解决时钟回拨的第2种情况。对于时钟回拨的第1中情况，UidGenerator在实例启动后使用未分配过的工作机器id来解决，当然这样做就得管理工作机器id，因而需要一个外部存储，增加了复杂度。 ","date":"2020-09-20","objectID":"/notes_004_distrubte_id/:0:0","tags":["work"],"title":"常见的分布式唯一ID方案","uri":"/notes_004_distrubte_id/"},{"categories":["srccode"],"content":"Dubbo自适应扩展机制","date":"2020-09-07","objectID":"/dubbo_02_extend/","tags":["doubbo"],"title":"Dubbo自适应扩展机制","uri":"/dubbo_02_extend/"},{"categories":["srccode"],"content":" 上一节提到过，Dubbo里除了Service和Config层为API，其它各层均为SPI。相比于Java中的SPI仅仅通过接口类名获取所有实现，Dubbo的实现可以通过接口类名和key值来获取一个具体的实现。通过SPI机制，Dubbo实现了面向插件编程，只定义了模块的接口，实现由各插件来完成。 1. 使用方式 1.1 Java SPI 在扩展类的jar包内，放置扩展点配置文件META-INF/service/接口全限定名，内容为：扩展实现类全限定名，多个实现类用换行符分隔。 如下为Mysql中Driver接口的实现： package com.mysql.jdbc; import java.sql.SQLException; public class Driver extends NonRegisteringDriver implements java.sql.Driver { ... } 调用时使用ServiceLoader加载所有的实现并通过循环来找到目标实现类 ServiceLoader\u003cDriver\u003e loadedDrivers = ServiceLoader.load(Driver.class); Iterator\u003cDriver\u003e driversIterator = loadedDrivers.iterator(); try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } 1.2 Dubbo SPI 拿Dubbo中Protocol接口来说，Protocol的定义如下： package org.apache.dubbo.rpc; import org.apache.dubbo.common.URL; import org.apache.dubbo.common.extension.Adaptive; import org.apache.dubbo.common.extension.SPI; @SPI(\"dubbo\") public interface Protocol { int getDefaultPort(); @Adaptive \u003cT\u003e Exporter\u003cT\u003e export(Invoker\u003cT\u003e invoker) throws RpcException; @Adaptive \u003cT\u003e Invoker\u003cT\u003e refer(Class\u003cT\u003e type, URL url) throws RpcException; void destroy(); } 需要指出的是Invoker基础了Node接口，该Node接口提供了getUrl方法，既每个方法都能从入参获得URL对象。 public interface Node { URL getUrl(); boolean isAvailable(); void destroy(); } 要求 1.接口上有org.apache.dubbo.common.extension.SPI注解，提供默认的实现 2.对于支持自适应扩展的方法要求方法入参能获得org.apache.dubbo.common.URL对象，同时方法上有org.apache.dubbo.common.extension.Adaptive注解，Adaptive注解可以提供多个key名，以便从URL中获取对应key的值，从而匹配到对应的实现**(这里Protocol比较特别，没有提供key名也能根据URL来动态获取实现，后面会说明)** 3.在扩展类的jar包内，放置扩展点配置文件META-INF/dubbo/接口全限定名，内容为：配置名=扩展实现类全限定名，多个实现类用换行符分隔。如Protocol的默认实现: 注意：META-INF/dubbo/internal为Dubbo内部实现的配置文件路径 调用时通过ExtensionLoader根据需要来选择具体的实现类， ExtensionLoader\u003cProtocol\u003e loader = ExtensionLoader.getExtensionLoader(Protocol.class); 可选方式包括 1.选择默认的实现 Protocol protocol = loader.getDefaultExtension(); 2.根据指定key选择实现 Protocol protocol = loader.getExtension(\"dubbo\"); 3.根据URL参数动态获取实现 Protocol protocol = loader.getAdaptiveExtension(); 2. Dubbo SPI 特性 Dubbo对Java中的标准SPI进行了扩展增强，官方文档中提到其提供了如下特性： 扩展点自动包装 扩展点自动装配 扩展点自适应 扩展点自动激活 在介绍各个特性前先介绍下大概的内部实现。从上面的使用中可以看到Dubbo对SPI扩展的主要实现在ExtensionLoader类中，关于这个类源码的讲解可以看官方文档，讲解的很详细，这边主要说下大概过程： 根据传入的类型从classpath中查找META-INF/dubbo/internal和META-INF/dubbo路径下所有对应的扩展点配置文件 读取扩展点配置文件中所有的键值对 根据键值对缓存Class对象，如果类有同类型参数的构造函数，则为包装类，会缓存在另一个容器中 实例化对象，缓存后并返回 2.1 扩展点自动包装 在返回真正实例前，会用该类型的包装类进行包装，既采用装饰器模式进行功能增强。 if (CollectionUtils.isNotEmpty(wrapperClasses)) { // 循环创建 Wrapper 实例 for (Class\u003c?\u003e wrapperClass : wrapperClasses) { // 将当前 instance 作为参数传给 Wrapper 的构造方法，并通过反射创建 Wrapper 实例。 // 然后向 Wrapper 实例中注入依赖，最后将 Wrapper 实例再次赋值给 instance 变量 instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } 其实就是使用静态代理来实现AOP 2.2 扩展点自动装配 返回实例前会遍历所有的setXXX方法，判断set方法参数是否存在自适应对象，如果存在则通过ExtensionLoader加载自适应对象然后进行赋值，可以通过方法上加org.apache.dubbo.common.extension.DisableInject注解来屏蔽该功能。该功能其实就是实现了IOC，具体可以看ExtensionLoader的injectExtension方法。 2.3 扩展点自适应 同上面介绍的一样，Dubbo的SPI可以根据传入的URL参数中携带的数据来动态选择具体的实现。 2.4 扩展点自动激活 上面介绍过，Adaptive注解是加在方法上的，类似的有个注解org.apache.dubbo.common.extension.Activate是加在实现类上。当加在Class上时，ExtensionLoader会将对应的key和Class信息缓存到另一个容器中，后续可以通过ExtensionLoader获取某一类的实现列表，既如下方法 public List\u003cT\u003e getActivateExtension(URL url, String[] values){ ... } 3. ExtensionLoader自适应扩展机制 ExtensionLoader自适应扩展机制的大概实现逻辑是这样的：Dubbo会为拓展接口生成具有代理功能的代码，然后通过 javassist 或 jdk 编译这段代码，得到 Class 类。最后再通过反射创建代理类，在代理类中，就可以通过URL对象的参数来确定到底调用哪个实现类。主要实现在createAdaptiveExtensionClass方法中。 private Class\u003c?\u003e createAdaptiveExtensionClass() { String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); ClassLoader classLoader = findClassLoader(); org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader); } 上面的Protocol接口经过处理后的内容如下： public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol { public void destroy() { throw new UnsupportedOperationException( \"The method public abstr","date":"2020-09-07","objectID":"/dubbo_02_extend/:0:0","tags":["doubbo"],"title":"Dubbo自适应扩展机制","uri":"/dubbo_02_extend/"},{"categories":["srccode"],"content":"这篇是开门贴，内容来自网上","date":"2020-08-30","objectID":"/dubbo_01_introduce/","tags":["doubbo"],"title":"Dubbo简介","uri":"/dubbo_01_introduce/"},{"categories":["srccode"],"content":" 这篇是开门贴，内容来自网上。 Dubbo是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和Spring框架无缝集成。Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。(来自百度百科) 1. 整体架构 Dubbo的整体架构如下： 涉及到的组件包括： Provider：暴露服务的服务提供方 Consumer：调用远程服务的服务消费方 Registry：服务注册与发现的注册中心 Monitor：统计服务的调用次数和调用时间的监控中心 Container：服务运行容器 调用流程为： 服务容器负责启动，加载，运行服务提供者。\r服务提供者在启动时，向注册中心注册自己提供的服务。\r服务消费者在启动时，向注册中心订阅自己所需的服务。\r注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\r服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\r服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\r(上面内容来自Dubbo官方文档) 2. 使用demo 2.1 Api方式 纯Api方式调用模式如下： Provider： public class ApplicationApi { public static void main(String[] args) throws Exception { ServiceConfig\u003cDemoServiceImpl\u003e service = new ServiceConfig\u003c\u003e(); service.setApplication(new ApplicationConfig(\"dubbo-demo-api-provider\")); service.setRegistry(new RegistryConfig(\"zookeeper://127.0.0.1:2181\")); service.setInterface(DemoService.class); service.setRef(new DemoServiceImpl()); service.export(); System.in.read(); } } Consumer： public class ApplicationApi { public static void main(String[] args) { ReferenceConfig\u003cDemoService\u003e reference = new ReferenceConfig\u003c\u003e(); reference.setApplication(new ApplicationConfig(\"dubbo-demo-api-consumer\")); reference.setRegistry(new RegistryConfig(\"zookeeper://127.0.0.1:2181\")); reference.setInterface(DemoService.class); reference.setAsync(true); DemoService service = reference.get(); String message = service.sayHello(\"dubbo\"); System.out.println(message); } } 展示纯Api调用方式有利于看清事物的本质 (上面代码来自dubbo-demo-api模块) 2.2 Spring方式 Spring方式调用模式如下： dubbo-provider： \u003cbeans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"\u003e \u003cdubbo:application name=\"demo-provider\"/\u003e \u003cdubbo:registry address=\"zookeeper://127.0.0.1:2181\"/\u003e \u003cdubbo:protocol name=\"dubbo\"/\u003e \u003cbean id=\"demoService\" class=\"org.apache.dubbo.demo.provider.DemoServiceImpl\"/\u003e \u003cdubbo:service interface=\"org.apache.dubbo.demo.DemoService\" ref=\"demoService\"/\u003e \u003c/beans\u003e dubbo-consumer： \u003cbeans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"\u003e \u003cdubbo:application name=\"demo-consumer\"/\u003e \u003cdubbo:registry address=\"zookeeper://127.0.0.1:2181\"/\u003e \u003cdubbo:reference id=\"demoService\" check=\"false\" interface=\"org.apache.dubbo.demo.DemoService\"/\u003e \u003c/beans\u003e 有了Bean后便可以在Spring中进行操作。 (上面代码来自dubbo-demo-xml模块) 3. 框架设计 Dubbo的分层结构如下： 涉及到的各层职责为： config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool (上面内容来自Dubbo官方文档) 可以看到，除Service 和 Config 层为 API，其它各层均为 SPI，这也是Dubbo面向插件设计的核心。 最终调用链为： 核心过程抽象为： 后续内容也是根据这个流程来展开并进行扩充。 最后就是，Dubbo官方文档是最好的文档，基本看懂官方文档对Dubbo也就熟络了，这个系列主要以笔者自己结合官方文档看源码笔记为主。 ","date":"2020-08-30","objectID":"/dubbo_01_introduce/:0:0","tags":["doubbo"],"title":"Dubbo简介","uri":"/dubbo_01_introduce/"},{"categories":["notes"],"content":"介绍Socks协议","date":"2020-08-29","objectID":"/notes_003_socks/","tags":["work"],"title":"Socks协议","uri":"/notes_003_socks/"},{"categories":["notes"],"content":"SOCKS：防火墙安全会话转换协议 （Socks: Protocol for sessions traversal across firewall securely） SOCKS协议提供一个框架，为在 TCP和UDP域中的客户机/服务器应用程序能更方便安全地使用网络防火墙所提供的服务。协议工作在OSI参考模型的第5层(会话层)，使用TCP协议传输数据，因而不提供如传递ICMP信息之类的网络层网关服务。 当防火墙后的客户端要访问外部的服务器时，就跟SOCKS代理服务器连接。这个代理服务器控制客户端访问外网的资格，允许的话，就将客户端的请求发往外部的服务器。Socks不要求应用程序遵循特定的操作系统平台，Socks 代理与应用层代理、 HTTP 层代理不同，Socks代理只是简单地传递数据包，而不必关心是何种应用协议（比如FTP、HTTP和NNTP请求）。所以，Socks代理比其他应用层代理要快得多。它通常绑定在代理服务器的1080端口上。 这个协议最初由David Koblas开发，而后由NEC的Ying-Da Lee将其扩展到SOCKS4。最新协议是 SOCKS5，与前一版本相比，增加支持UDP、验证，以及IPv6。 1. Socks4 Socks4的建立过程如下： 1.客户端先跟代理服务器建立socket连接 2.客户端向代理服务器发送链接请求包，第一个包的格式为 3.代理服务器收到第一个包后根据实际情况作出判断，并给客户端发送响应包，格式为： 4.当代理服务器返回拒绝后则直接断开客户端链接；否则充当客户端与目的主机之间建立连接并进行双向传递，对客户端而言，就如同直接在与目的主机相连。 2. Socks5 SOCKS5比SOCKS4a多了验证、IPv6、UDP支持。 Socks5的建立过程如下： 1.客户端先跟代理服务器建立socket连接 2.客户端向代理服务器发送链接请求包，该包用来确认协议版本及认证方式，格式为： 3.代理服务器从客户端提供的方法中选择一个认证方法并通过回包来通知客户端，格式为： 当返回结果为OXFF(代理服务端无可接受认证方法)时，客户端需要关闭连接，流程结束。 4.选定认证方法后，客户端和代理服务器需要根据选定的认证方式执行对应的认证。如果认证失败则中断链接。 5.认证通过后，客户端则向代理服务器发起请求，第一个包格式为： 6.代理服务器收到包后进行处理，作出判断后发送回包，回包格式为： 7.当代理服务器返回拒绝后则直接断开客户端链接；否则充当客户端与目的主机之间建立连接并进行双向传递，对客户端而言，就如同直接在与目的主机相连。 3. Jsocks github上实现socks协议的项目有很多，这里选jsocks()https://github.com/ravn/jsocks)来说明。顾名思义，jsock是用Java写的，项目本身实现了socks4和socks5协议。 jsocks实现功能同上面大体相同，代码也比较简单，这边不做说明。这里只提一点jsocks里的认证方式，在源码的IdentAuthenticator类里。这个类没有使用用户名密码方式，也没有自定义认证协议，而是直接通过判断协议里的用户名跟客户端的发起方是否是同一个人来进行验证。 实现上在验证方式上选择无需验证，然后为每个请求方的ip范围分配一个用户，只有对应用户才能继续往下走。jsocks通过访问客户端的113端口来判断发起方同配置中的用户是否一致，只有匹配的用户流程才能继续玩下走。113端口是一个许多计算机上运行的协议，用于鉴别TCP连接的用户。相当于把socks5原来的认证流程换为了代理服务器主动访问客户端进行验证。当验证通过后，jsocks这时候会持有客户端的socket(RemoteSocket)，并代替客户端向目标地址发起socket(OutSocket)连接，后面会循环把RemoteSocket的数据流写入到OutSocket里以完成数据的传输。 4. 参考资料 https://zh.wikipedia.org/wiki/SOCKS ","date":"2020-08-29","objectID":"/notes_003_socks/:0:0","tags":["work"],"title":"Socks协议","uri":"/notes_003_socks/"},{"categories":["srccode"],"content":"这节介绍jvm-sandbox的事件机制","date":"2020-08-02","objectID":"/sandbox_02_event/","tags":["jvm-sandbox"],"title":"JVM层面的切面实现 : jvm-sandbox 之 \u003c事件机制\u003e","uri":"/sandbox_02_event/"},{"categories":["srccode"],"content":"这节介绍jvm-sandbox的事件机制，事件机制提供了切面通知的核心功能，内部主要结合asm和观察者模式来实现。jvm-sandbox提供的事件包括： 上面的截图是官网github wiki对事件的介绍，包括提供的事件类型、事件的作用域以及状态机流转。概括的说就是，jvm-sandbox围绕了目标方法这个切面点，提供了多种通知机制。 1.观察者模式 观察者模式的简单示意如下： Observer(观察者)观察Subject(目标)，Subject在发生变化时通知Observer。具体到这里，模型抽象为: 目标对象为符合条件的类的方法，观察者则为EventListener实现类。一般我们在实现时， Subject都会有一个Observer列表，以及提供一个添加观察者的方法(add) 用户通过调用Subject的add方法，触发观察，把Observer添加到Observer列表中 Subject在事件发生时，遍历Observer列表，通知到Observer 以此达到目的。下面来看jvm-sandbox如何实现该过程。 2. 触发观察DefaultModuleEventWatcher.watch 从官网的例子开始 /** * 一个损坏的钟实现 */ static class BrokenClock extends Clock { @Override void checkState() { throw new IllegalStateException(); } @Override void delay() throws InterruptedException { Thread.sleep(10000L); } } /** * 修复损坏的钟模块 */ @Information(id = \"broken-clock-tinker\") public class BrokenClockTinkerModule implements Module { @Resource private ModuleEventWatcher moduleEventWatcher; @Http(\"/repairCheckState\") public void repairCheckState() { moduleEventWatcher.watch( // 匹配到Clock$BrokenClock#checkState() new NameRegexFilter(\"Clock\\\\$BrokenClock\", \"checkState\"), // 监听THROWS事件并且改变原有方法抛出异常为正常返回 new EventListener() { @Override public void onEvent(Event event) throws Throwable { // 立即返回 ProcessControlException.throwReturnImmediately(null); } }, // 指定监听的事件为抛出异常 Event.Type.THROWS ); } } 按上一节的介绍，每个Module类都会分配一个MOduleEventWatcher，注入的对象为DefaultModuleEventWatcher。DefaultModuleEventWatcher是jvm-sandbox内置的默认观察者实现门户类(没有实现EventWatcher)，用于将用户定义的EventWatcher添加到目标类中。上面例子中的watch动作最终会调用到如下方法 private int watch(/*匹配器*/final Matcher matcher, /*事件监听器*/final EventListener listener, final Progress progress, /*观察的时间类型*/ final Event.Type... eventType) 该方法的主要流程如下: 概括来说就是，每一次watch(观察)都会对应一个watchId**(1)，对应多个需要处理的class(2)，对应一个EventListener(3)，对应一个SandboxClassFileTransformer** (4)，激活后会对应一个EventProcessor (5) watchId由Sequencer进行分配，该ID序号是全局的，目前的实现是从1000开始的int，每次获取都加1 通过CoreLoadedClassDataSource找出符合条件的Class列表 EventListener由用户传入，会在用户指定的事件发生时进行回调通知 SandboxClassFileTransformer实现了ClassFileTransformer接口，提供了AOP代码的织入逻辑的入口，真正的字节码处理动作由EventEnhancer和EventWeaver完成。SandboxClassFileTransformer的构造方法如下， SandboxClassFileTransformer(/*观察动作id*/final int watchId, /*模块id*/final String uniqueId, /*类匹配器*/final Matcher matcher, /*监听器*/ final EventListener eventListener, final boolean isEnableUnsafe, final Event.Type[] eventTypeArray, /*命名空间*/final String namespace) { this.watchId = watchId; this.uniqueId = uniqueId; this.matcher = matcher; this.eventListener = eventListener; this.isEnableUnsafe = isEnableUnsafe; this.eventTypeArray = eventTypeArray; this.namespace = namespace; //为每个EventListener实例分配一个全局的id，便于传递 this.listenerId = ObjectIDs.instance.identity(eventListener); } 在构造方法中会为EventListener对象分配一个全局的id(listenerId)，这个id会跟事件处理器(EventListener)对象进行映射，并缓存起来，后续可以通过id获取该对象。 当进行观察时，会使用asm将listenerId织入到目标方法中，从而实现上面提到的调用add方法的效果。 再调用Instrument的reTransform方法，对符合条件的类重头应用一遍类处理器，从而达到新增监听器的效果。 调用EventListenerHandler的active方法激活该事件处理器，本质是将该对象缓存在内部的Map中 // 全局处理器ID:处理器映射集合 private final Map\u003cInteger/*LISTENER_ID*/, EventProcessor\u003e mappingOfEventProcessor = new ConcurrentHashMap\u003cInteger, EventProcessor\u003e(); 后续可以通过该listenerId获取到对应的对象。 3. Subject的Observer列表 “add“方法的具体实现是由EventEnhancer和EventWeaver完成。内容上偏底层，主要是字节码操作。这边直接给出处理后效果，以开头的例子为例，感兴趣的可以看源码了解具体的实现。BrokenClock增强后的内容如下: public class BrokenClock extends Clock { public BrokenClock() { } void checkState() { boolean var10000 = true; try { Ret var5 = Spy.spyMethodOnBefore(new Object[0], \"default\", 1000, 1001, \"com.alibaba.jvm.sandbox.qatest.core.enhance.target.BrokenClock\", \"checkState\", \"()V\", this); int var6 = var5.state; if (var6 != 1) { if (var6 != 2) { var10000 = true; throw new IllegalStateException();//原方法内容 } else { throw (Throwable)var5.respond; } } else { Object var2 = var5.respond; } } catch (Throwable var1) { boolean var10001 = true; Ret var3 = Spy.spyMethodOnThrows(var1, \"default\", 1000); int var10002 = var3.state; if (var10002 != 1) { if (var10002 != 2) { var10001 = true; throw var1; } else { throw (Throwable)var3.respond; } } else { Object var4 = var3","date":"2020-08-02","objectID":"/sandbox_02_event/:0:0","tags":["jvm-sandbox"],"title":"JVM层面的切面实现 : jvm-sandbox 之 \u003c事件机制\u003e","uri":"/sandbox_02_event/"},{"categories":["srccode"],"content":"jvm-sandbox的启动","date":"2020-07-24","objectID":"/sandbox_01_start/","tags":["jvm-sandbox"],"title":"JVM层面的切面实现 : jvm-sandbox 之 \u003c应用启动\u003e","uri":"/sandbox_01_start/"},{"categories":["srccode"],"content":"1. 启动 sandbox源码各模块的结构如下: sandbox安装后的目录结构如下: 按照官方的教程，启动命令如下： ./sandbox.sh -p 2343 查看对应的脚本，函数定义如下： 翻译过来就是执行如下命令 java -Xms128M -Xmx128M -Xnoclassgc -ea -jar /xxx/sandbox-core.jar 2342 /xxx/sandbox-agent.jar home=/xxx;token=xxx;server.ip=xxx;service.port=xxx;namespace=xxx 按顺序将参数定义为 targetJvmPid:目标应用pid agentJarPath:附加的agent包路径 cfg:agent-main的参数,包括home路径;该次唯一标识toke;ip端口以及命名空间 查看sandbox-core模块的pom.xml \u003carchive\u003e \u003cmanifest\u003e \u003cmainClass\u003ecom.alibaba.jvm.sandbox.core.CoreLauncher\u003c/mainClass\u003e \u003c/manifest\u003e \u003c/archive\u003e 找到启动类 com.alibaba.jvm.sandbox.core.CoreLauncher 该类存在一个main方法，接收3个参数，并实例化一个CoreLauncher实例，它在构造方法中完成agent的attach动作. public CoreLauncher(final String targetJvmPid, final String agentJarPath, final String token) throws Exception { attachAgent(targetJvmPid, agentJarPath, token); } 主要是以agent-main的方式执行。 去到sandbox-agent模块的pom.xml，有如下配置 \u003carchive\u003e \u003cmanifestEntries\u003e \u003cPremain-Class\u003ecom.alibaba.jvm.sandbox.agent.AgentLauncher\u003c/Premain-Class\u003e \u003cAgent-Class\u003ecom.alibaba.jvm.sandbox.agent.AgentLauncher\u003c/Agent-Class\u003e \u003cCan-Redefine-Classes\u003etrue\u003c/Can-Redefine-Classes\u003e \u003cCan-Retransform-Classes\u003etrue\u003c/Can-Retransform-Classes\u003e \u003c/manifestEntries\u003e \u003c/archive\u003e 分别指定了premain和agent的启动类com.alibaba.jvm.sandbox.agent.AgentLauncher 查看入口agentmain方法 处理agent传入的cfg参数字段，解析为k-v对，然后执行install方法，并将结果写入到了${HOME}/.sandbox.token里,该文件记录的内容为 default;21988529;0.0.0.0;32165//命名空间;token;ip;port 2. AgentLauncher.install sandbox-agent模块里AgentLauncher类的install方法将完成主要的加载过程,包括: 将系统参数序列化，用于后续反射调用 将sandbox-spy.jar 加入BootstrapClassLoader 分别为每个namespace初始化一个SandboxClassLoader自定义类加载器，其继承自URLClassLoader，指向sandbox-core.jar，支持加载该jar包中的类。结合第2步，SandboxClassLoader目前加载的自定义jar包括sandbox-spy.jar和sandbox-core.jar。其中sandbox-core.jar包括了源码里的sandbox-core-api模块。注意，SandboxClassLoader位于sandbox-agent.jar包中，其父类加载器为AppClassLoader 使用SandboxClassLoader反射加载并实例化sandbox-core.jar里的com.alibaba.jvm.sandbox.core.CoreConfigure，传入第1步的参数以及sandbox.properties文件的路径 使用SandboxClassLoader反射加载并实例化sandbox-core.jar里的com.alibaba.jvm.sandbox.core.server.ProxyCoreServer，该步会实例化sandbox-core.jar里的com.alibaba.jvm.sandbox.core.server.jetty.JettyCoreServer实例 执行JettyCoreServer的bind方法，加载自定义模块、启动http服务 3. JettyCoreServer.bind JettyCoreServer的bind方法主要完成Http服务的启动以及各模块的加载，主要动作为: 初始化JvmSandbox对象 初始化Http服务 初始化Jetty处理器 启动Http服务 重置所有用户模块，先卸载再加载 注，当前的ClassLoader为每个namespace对应的SandboxClassLoader，后续该包里加载的类的类加载器都是这个，影响的类位于sandbox-core.jar中，对应源码里的sandbox-common-api、sandbox-provider-api、sandbox-api、sandbox-core模块。 3.1 初始化JvmSandbox对象 JvmSandbox表示一个沙箱对象，关系如下，依赖CoreConfigure和CoreModuleManager，分别表示系统配置信息和模块管理。CoreModuleManager的实现类为DefaultCoreModuleManager，为主要功能。 同时在初始化的时候还会调用SpyUtils，为每个namespace分配公共的EventListenerHandler(SpyHandler实现)类 private void init() { SpyUtils.init(cfg.getNamespace());//初始化SpyUtils，分配公共的EventListenerHandler(SpyHandler实现)类 } 3.2 初始化Http服务 初始化Http服务,启动一个Jetty Server，并设置为daemon 3.3 初始化Jetty处理器 初始化Jetty处理器，实现一个请求分发器，可以通过http的方式来触发**@Command**注解的方法。 注册的处理器有两种: web-scoket-servet 访问路径为 /sandbox/${namespace}/module/websocket/* 处理类为WebSocketAcceptorServlet module-http-servlet 访问路径为 /sandbox/${namespace}/module/http/* 处理类为ModuleHttpServlet，这边重点介绍http处理器 3.3.1 ModuleHttpServlet 该Servlet要求请求URL按照如下格式： /sandbox/${namespace}/module/http/${uniqueId}/${command}?${k1}=${v1}\u0026${k2}=${v2} ${uniqueId}:模块id ${command}:模块下的方法，需要加@Command注解 {k1}=${v1}\u0026${k2}=${v2}:方法参数 对于一个http请求，具体流程为: 解析url得到模块id，如果模块不存在则返回，否则从模块管理类CoreModuleManager中获取对应的模块CoreModule 匹配对应的方法,获得Method对象查找有@Command注解且匹配/${uniqueId}/${command}的方法，具体会将模块id和@Command的值用/进行拼接 生成方法调用参数，遍历方法的入参类型，按照类型设置对应的入参列表，支持的类型包括: HttpServletRequest HttpServletResponse Map\u003cString,String[]\u003e：使用http请求的参数 String：使用url中?后面的内容 PrintWriter：HttpServletResponse.getWriter() OutputStream：HttpServletResponse.getOutputStream() 反射执行Method 相当于自己实现了一个http请求分发器 3.4 启动Http服务 启动Jetty http服务 3.5 重置所有用户模块 主要调用CoreModuleManager的reset方法，完成模块的重置。先卸载各个模块再进行加载。 在这之前先介绍模块的生命周期 (来自官网github wiki，官网都有，懒的搬了) 上面少了一个loadCompleted事件，会在模块加载完成，模块完成加载后调用。作者的意思是方法比较常用，所以单独出来成为一个接口。 模块的卸载会先将模块进行冻结，然后再将模块卸载，期间会触发onFrozen和onUnload事件。有点需要注意的是冻结和卸载的不同，冻结只","date":"2020-07-24","objectID":"/sandbox_01_start/:0:0","tags":["jvm-sandbox"],"title":"JVM层面的切面实现 : jvm-sandbox 之 \u003c应用启动\u003e","uri":"/sandbox_01_start/"},{"categories":["srccode"],"content":"本文先介绍零拷贝的相关背景，再介绍RocketMQ中mmap的应用，为后面介绍MessageStore做过渡","date":"2020-05-18","objectID":"/rocketmq_09_consumequeue/","tags":["rocketmq"],"title":"RocketMQ消息的存储消费模型","uri":"/rocketmq_09_consumequeue/"},{"categories":["srccode"],"content":"这节介绍RocketMQ中消息的存储模型：CommitLog和ConsumeQueue。CommitLog用于存储Producer的消息，ConsumeQueue接受CommitLog分配的消息，等待Consumer消费。 1. 存储消费模型 RocketMQ采用了单一的日志文件，即把同1台机器上面所有topic的所有queue消息都存放在一个文件里面，以避免随机的磁盘写入。其存储结构如下： Broker会把所有消息都存在一个单一的CommitLog文件里面，然后由后台线程异步的同步到ConsumeQueue中，再由Consumer进行消费。 该模型下，ConsumeQueue中并不需要存储消息的内容，而是存储消息在CommitLog中的offset。也就是说，ConsumeQueue其实是CommitLog的一个索引文件。即CommitLog的写入是顺序的，而读取需要支持随机读的，支持该特性的实现就是上一节提到的MappedFileQueue。 2. CommitLog CommitLog的很多操作都基于MappedFileQueue来操作，在MappedFileQueue上增加了CRUD操作。CommitLog的调用过程如下： 初始化时会初始化相关的组件，包括MappedFileQueue、FlushCommitLogService、AppendMessageCallback等。 MappedFileQueue主要设定了文件的路径位置和每个MappedFile的大小(1024 * 1024 * 1024 = 1G)。 FlushCommitLogService的实现类有3个GroupCommitService、FlushRealTimeService和CommitRealTimeService。前两个用于刷盘，如果开启了异步刷盘，则使用GroupCommitService，该实现会将刷盘请求缓存起来，到时间后再执行刷盘；FlushRealTimeService，该实现直接定时刷固定页的数据，如果启用了堆外缓冲区则使用GroupCommitService，否则使用FlushRealTimeService。后面的CommitRealTimeService则用于将堆外缓冲区中的数据写到FileChannel中(如果启用了堆外缓冲，调用MappedFileQueue的commit方法)。 AppendMessageCallback主要用于实现具体消息写入ByteBuf的方式。 此外，还缓存了每个topic下每个queue对应的逻辑偏移量 private HashMap\u003cString/* topic-queueid */, Long/* offset */\u003e topicQueueTable = new HashMap\u003cString, Long\u003e(1024); 加载主要是调用MappedFileQueue的load方法，最后启动FlushCommitLogService服务。 同时，CommitLog还通过ReputMessageService，将消息offset放到了ConsumeQueue以及IndexService，ReputMessageService的调用在DefaultMessage里。 2.1. 追加消息 追加消息的大致过程如下，其中写入消息时会加锁，从而保证每个CommitLog文件的写都是顺序写入的。 其中AppendMessageCallback主要完成了对消息写入ByteBuff的处理，包括单笔和批量消息。这里主要介绍单笔消息的写入：计算一条消息每一部分的大小和内容，然后写入到byteBuffer中，byteBuffer是MappedFile slice后的内容，写入每个部分如下： 大部分内容通过字段便能够看出具体的意思，这里不再赘述，只对一些内容进行介绍。 计算消息的全局ID：MessageId，MessageId由存储的broker机器的ip地址+commitLog中的起始物理offset组成。MessageId会带在返回结果PutMessageResult中返回。 写入成功后会将topic-queue的逻辑偏移量+1(逻辑偏移量表示消息数量的大小，一条消息进来下标就会长1) 写入之前会计算消息的大小，如果超过设定的单条消息的大小(默认512K)则拒绝写入 写入之前会判断当前文件剩余内容是否足够，如果不够则会插入一条空白消息，将剩余部分填满，返回文件已满，上层判断文件满了，会重新生成一个文件，将消息再次写入.空白消息写入的内容为totalSize+magicCode+0值,其中正常消息的magicCode为-626843481，空白消息为-875286124 2.2. 读取消息 根据所给的起始offset(物理偏移量),确定该offset所在MappedFile后，获取从offset开始到MappedFile当前可读的所有内容。 MappedFile里会维护一个fileFromOffset属性，标记当前文件存储消息的起始偏移量，该值也是文件的文件名，默认值每个文件为1G=1073741824,即每个文件名的步长为1073741824。对于给定的offset，只要找到符合fileFromOffset \u003c= offset \u003c fileFromOffset + mappedFileSize(1G)的MappedFile即可。找到目标MappedFile后，通过offset%mappedFileSize可以计算出所给的起始offset在当前文件中的位置。 获得ByteBuff内容后，可以调用checkMessageAndReturnSize方法，从ByteBuff中还原消息，返回DispatchRequest(不含消息body内容)。 前面提到，ReputMessageService会从CommitLog中读取消息，然后用于构建ConsumeQueue和IndexFile，这里传送的内容就是DispatchRequest。DefaultMessageStore会定时从CommitLog中读取消息，并将解析出的DispatchRequest对象传给ConsumeQueue和IndexService。 2.3. 删除消息 调用MappedFileQueue，按照offset或者过期时间(默认72小时)删除物理文件 3. ConsumeQueue 代表一个topic下一个queue的消费队列。ConsumeQueue底层基于MappedFileQueue，存储每个topic-queueId下对应消息的offset，但消息被实际消费时，再通过offset从CommitLog中查找具体的消息内容。 ConsumeQueue的调用过程和提供方法同CommitLog类似，也是初始化时从指定的路径下重构MappedFileQueue，并提供了CRUD方法来操作文件。 ConsumeQueue以路径的形式来分割每个topic下queue的存储，每个q对应的数据存储路径为 /DirToStore/topic/queueId/ 每次写入的数据格式(数据单元)为： 物理偏移量(long/8)|消息大小(int/4)|逻辑偏移量(long/8) = 20 ConsumeQueue初始化MappedFile的默认大小为 30000 * 20，即每个文件存30万条记录，没个文件名的步长为600000，消费时只要每次读取20个字节便能查找到每个消息的offset。 4. IndexService IndexService用于构建消息的索引文件IndexFile。ConsumeQueue中的消息都是通过offset从CommitLog中查到对应消息内容，但不知道消息的offset，又想通过其他特征(key)来查找消息时便没法完成，索引文件IndexFile就是为了支持该功能。 IndexFile对应的文件名为yyyyMMddHHmmssSSS，即时间戳。IndexFile的结构如下，由3部分组成： 4.1. HEADER 头部信息，包括该文件的开始/结束时间，起始/结束物理偏移量以及槽的数量和索引的数量，头部信息的长度是固定的，为40个字节。 4.2. SLOT 槽，对于每个key值，通过计算hash值，会对应到一个槽下标slotPos，槽只存储一个int数字，指向INDEX的下标。通过40 + hash(key) * 4 可以定位到槽的物理位置，再读取4个字节可以得到INDEX的下标。hash值的计算如下： public int indexKeyHashMethod(final String key) { int keyHash = key.hashCode(); int keyHashPositive = Math.abs(keyHash); if (keyHashPositive \u003c 0) keyHashPositive = 0; return keyHashPositive; } 当hash值出现冲突时，使用链表法，将冲突的hash内容放到INDEX中，连成链表，在下面会介绍。 4.3. INDEX 存储消息对应的物理offset的信息，包括Key的hash值、消息在CommitLog的起始物理offset，相对于索引文件开始时间的差值、上一个槽指向的INDEX下标值，长度为20个字节。通过槽获得索引的下标后，可以通过 40 + 槽总数量* 4 + 索引下标 + 20 定位到该索引内容。默认槽的数量为5000000，索引最大的数量为5000000 * 4。 新加入","date":"2020-05-18","objectID":"/rocketmq_09_consumequeue/:0:0","tags":["rocketmq"],"title":"RocketMQ消息的存储消费模型","uri":"/rocketmq_09_consumequeue/"},{"categories":["srccode"],"content":"本文先介绍零拷贝的相关背景，再介绍RocketMQ中mmap的应用，为后面介绍MessageStore做过渡","date":"2020-05-14","objectID":"/rocketmq_08_mappedfile/","tags":["rocketmq"],"title":"RocketMQ文件存储的基础:MappedFile和MappedFileQueue","uri":"/rocketmq_08_mappedfile/"},{"categories":["srccode"],"content":"RocketMQ文件存储的基础:MappedFile和MappedFileQueue RocketMQ中的MappedFile类对应一个文件的mmap映射,是RocketMQ实现高效存储的基础。本文先介绍零拷贝的相关背景，再介绍RocketMQ中mmap的应用，为后面介绍MessageStore做过渡。 1. 零拷贝 零拷贝（zero copy）指的是当拷贝发生时，CPU并不参与实际的拷贝过程。CPU可以切换到其他线程，数据的拷贝过程异步进行，异步过程通常要由硬件DMA实现。常用的零拷贝有 mmap 和 sendFile。 采用传统的读写操作将磁盘中的数据发送到网络中，通常经历2次用户态/内核态的切换，并且读和写操作CPU分别要参与一次拷贝过程。 我们知道，操作系统设置了用户态和内核态两种状态，用户态想要获取系统资源(例如访问硬盘), 必须通过系统调用进入到内核态, 由内核态获取到系统资源,再切换回用户态返回应用程序。同时，操作系统在内核态中也增加了一个\"内核缓冲区\"(kernel buffer)，读取数据时并不是直接把数据读取到应用程序的缓存区(app buffer), 而是先读取到内核缓冲区, 再由内核缓冲区复制到应用程序的缓存区。 传统的IO读写过程，数据会在用户态和内核态之间发送多次复制和多次上下文切换，如下： 主要流程为： 硬盘拷贝到内核缓冲区(DMA COPY) 内核缓冲区拷贝到应用程序缓冲区(CPU COPY) 应用程序缓冲区拷贝到socket缓冲区(CPU COPY) socket buf拷贝到网卡的buf(DMA COPY) 即一次读写过程涉及到2次cpu copy, 还有4次的上下文切换。 很明显,第2次和第3次的copy只是把数据复制到app buffer又原封不动的复制回来, 为此带来了两次的cpu copy和两次上下文切换, 是完全没有必要的。 1.1 PageCache pagecache是文件系统层级的缓存，从磁盘里读取的内容是存储到这里，这样程序读取磁盘内容就会非常快。page cache的大小为一页，通常为4K。 Java里的写操作都是写到PageCache里便认为逻辑落盘成功，后续操作是通过操作系统把它刷到磁盘文件上。 1.2. sendfile linux内核2.1开始引入一个叫sendFile系统调用 ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 这个系统调用可以在内核态内把数据从内核缓冲区直接复制到套接字(SOCKET)缓冲区内, 从而可以减少上下文的切换和不必要数据的复制,如下： 涉及到数据拷贝变成: 硬盘拷贝到内核缓冲区(DMA COPY) 内核缓冲区拷贝到socket缓冲区(CPU COPY) socket缓冲区拷贝到网卡的buf(DMA COPY) sendfile只能将数据从文件传递到套接字上，反之则不行。 使用sendfile不仅减少了数据拷贝的次数，还减少了上下文切换。 Java类库通过java.nio.channels.FileChannel的transgerTo方法支持零拷贝。而在Netty中也通过在FileRegion中包装了NIO的FileChannel.transferTo()方法实现了零拷贝。RocketMQ在涉及到网络传输的地方也使用了该方法。 FileChannel本身不是基于零拷贝实现的，而是是基于块来实现的。FileChannel配合着ByteBuffer，将读写的数据缓存到内存中，然后以批量/缓存的方式read/write，省去了非批量操作时的重复中间操作，操纵大文件时可以显著提高效率。FileChannel的write方法将数据写入PageCache后就认为落盘了，最终还是要操作系统完成PageCache到磁盘的最终写入。FileChannel的force方法则是用于通知操作系统进行及时的刷盘。 1.3. mmap mmap也是零拷贝实现的一种，它利用共享内存空间的方式, 把文件映射到用户空间里的虚拟内存，省去了从内核缓冲区复制到用户空间的过程。 void mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); mmap通过内存映射文件的方法，将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示： 如上，每个进程都有独立的进程地址空间，通过页表和MMU，可将虚拟地址转换为物理地址，每个进程都有独立的页表数据，这可解释为什么两个不同进程相同的虚拟地址，却对应不同的物理地址。 mmap内存映射的实现过程，总的来说可以分为三个阶段： 进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域 调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝 前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。 完成上面步骤后，目前只是建立了地址映射，真正的硬盘数据还没有拷贝到内存中。这时候进程的读或写操作访问虚拟地址空间这一段映射地址时，通过查询页表，会发现这一段地址并不在物理页面上，因此将引发缺页异常。缺页异常会进行一系列判断，确定无非法操作后，会触发内核发起请求调页过程。 调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中，之后进程便可对这片主存进行读或者写的操作。如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。 修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。 Java中的MappedByteBuffer便是对应mmap实现，在Java中一次只能映射1.5~2G的文件内存。其中MappedByteBuffer的put方法实际上是将数据写到了虚拟内存，而虚拟内存是依赖于操作系统的定时刷盘的。可以手动通过MappedByteBuffer的force方法来手动控制刷盘。 1.4. mmap和sendFile的区别 mmap适合小数据量读写,sendFile适合大文件传输。 mmap 需要 4 次上下文切换，3次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用DMA方式，减少CPU拷贝，mmap 则不能 sendFile必须从内核拷贝到Socket缓冲区 RocketMQ因为有小块数据传输的需求，因而选择了mmap。RocketMQ为了提高写的效率，也支持使用FileChannel(开启堆外缓冲区且使用异步刷盘且为Master节点时)。下面为网上别人测试得出的使用mmap和FileChannel的结果 数据来源于https://www.jianshu.com/p/d0b4ac90dbcb 虽然FileChanel在读写时不支持零拷贝，但是基于ByteBuff缓冲，在数据量稍大时是有一定优势的。 2. MappedFile RocketMQ中的MappedFile类对应一个文件的mmap映射，提供了初始化、追加写、刷盘、清除、数据预热等功能。MappedFile支持同时使用mmap和FileChannel操作文件。两者同时使用时，mmap用于读，FileChannel则用于写，默认情况下只使用mmap进行读写。 定义如下： public class MappedFile extends ReferenceResource { public static final int OS_PAGE_SIZE = 1024 * 4; protected static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME); private static final AtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);//总的虚拟内存大小 private static final AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);//总的映射文件数 protected final AtomicInteger wrotePosition = new AtomicInteger(0);//当前mmap文件的写位置 //ADD BY ChenYang protected final AtomicInteger committedPosition = new AtomicInteger(0);//当前mmap文件的提交位置 private final AtomicInteger flushedPo","date":"2020-05-14","objectID":"/rocketmq_08_mappedfile/:0:0","tags":["rocketmq"],"title":"RocketMQ文件存储的基础:MappedFile和MappedFileQueue","uri":"/rocketmq_08_mappedfile/"},{"categories":["srccode"],"content":"这节介绍下RocketMQ中最后的一个部分，也是内容较多的一部分：Broker","date":"2020-05-04","objectID":"/rocketmq_07_broker/","tags":["rocketmq"],"title":"RocketMQ的心脏:Broker","uri":"/rocketmq_07_broker/"},{"categories":["srccode"],"content":"RocketMQ的心脏:Broker 这节介绍下RocketMQ中最后的一个部分，也是内容较多的一部分：Broker。 Broker的启动同其他几个组件一样，从XXXStartup(BrokerStartup)类的main方法开始，首先加载对应的配置文件XXXConfig(BrokerConfig、NettyServerConfig、NettyClientConfig、MessageStoreConfig)，然后实例化XXXController(BrokerController)，接着调用Controller的initialize方法，最后注册ShutdownHook。 Broker在构造方法中，会进行如下的实例化动作： 包括： 配置类：BrokerConfig、NettyServerConfig、NettyClientConfig、MessageStoreConfig 管理类：ConsumerOffsetManager(偏移量管理)、TopicConfigManager(topic配置管理)、ConsumerManager(消费者管理)、ConsumerFilterManager(消费者过滤管理)、ProducerManager(生产者管理)、SubscriptionGroupManager(订阅组管理)、FilterServerManager(服务端过滤管理)、BrokerStatsManager(broker状态管理) 服务类：PullMessageProcessor(拉取消息处理器)、PullRequestHoldService(拉取请求缓存服务)、ClientHousekeepingService(客户端长连接服务)、SlaveSynchronize(slave同步) 监听类：NotifyMessageArrivingListener(通知消息到达监听器)、DefaultConsumerIdsChangeListener(客户端id改变监听器) 工具类：Broker2Client、BrokerOuterAPI 线程队列类：发送线程、拉取线程、查询线程、客户端管理线程、消费者管理线程、心跳线程、事务线程 Broker的初始化和启动过程如下： 初始化的步骤为： 加载配置文件,由TopicConfigManager处理:存储每个topic的配置信息；ConsumerOffsetManager:缓存所有topic@group对应的queue的偏移量；SubscriptionGroupManager:存储每个group的配置信息；ConsumerFilterManager:Topic的过滤表达式信息 加载消息存储内容,由MessageStore处理 注册请求处理器，由NettyRequestProcesser处理，根据RequestCode，分发远程请求给对应的Processer，包括SendMessageProcessor、QueryMessageProcessor、ClientManageProcessor、ConsumerManageProcessor、AdminBrokerProcessor 每隔一天记录broker状态，BrokerStats会打印当天接受/处理的消息总数 每一段时间（默认5s）记录消费者消费的偏移量，ConsumerOffsetManager会将缓存topic下每个q对应的消费偏移量进行持久化存储为json 每10s记录消费者过滤情况，ConsumerFilterManager会将缓存topic的过滤表达式持久化存储为json 每3min“保护”broker，BrokerStatsManager会每秒/分钟/小时记录各字表的次数和消费消息的大小，如果记录的客户端消费失败字节数大于配置的参数，会将该topic设置为不可消费 每1s打印打印消息队列水位线，包括发送Queue数量、拉取Queue数量、查询Queue数量 每1分钟打印处理的消息量 同步namesrv地址列表，由BrokerOutterAPI处理，如果指定了namesrv地址，则使用该列表；否则从配置的网络路径上同步 (slave)每1min同步slave，SlaveSynchronize会通过BrokerOutterApi向master请求数据同步 (master)每1min打印slave比master落后的消息数，MessageStore会打印最大的消费偏移量-已经同步给slave的偏移量 初始化事务服务 启动步骤包括： 启动消息存储服务MessageStore 启动Netty服务RemotingServer 启动文件监听服务FileWatchService，监听tls证书，在发生变化时重新加载 启动API服务BrokerOuterAPI 启动缓存pull请求处理服务PullRequestHoldService，对每个topic下的q的pull请求，定时再次执行 启动客户端连接服务ClientHouseKeepingService，每10s清除超时没有消息的客户端连接 启动服务端过滤服务FilterServerManager，每30s执行本地脚本 注册broker，后面每一段时间(不超过1分钟)注册broker，首次启动会向所有namesrv同步broker信息和所持有的topic信息，后面每隔一段时间同步一次 启动broker状态管理BrokerStatsManager 启动请求过期清理任务BrokerFastFailure，如果开启了快速失效的配置，会定时清理缓存中的过期请求 启动事务消息检查服务TransactionalMessageCheckService 下面将介绍其中几块内容。 1. SendMessageProcessor 消息发送处理器，主要处理Producer发送的消息和Consumer的重试消息。 1.1. 处理发送消息请求 主要过程为： 解析请求头，得到SendMessageRequestHeader 构建上下文对象，SendMessageContext 执行前置hook，调用SendMessageHook的sendMessageBefore方法 执行核心处理逻辑，分为单消息和批量消息的处理，主要是先进行前置检查，如判断MesageStore是否已经启动、Queue是否正确等，然后将请求内容包装为Broker内部处理的形式，交由MessageStore处理放入CommitLog中。其中单消息包装为MessageExtBrokerInner、批量消息包装为MessageExtBatch 执行后置hook，调用SendMessageHook的sendMessageAfter方法 1.2. 处理Consumer的重试消息 在介绍Consumer消费消息过程时提到过，在Push模式下，如果消息消费失败，可以将消息重新返回Consumer实例的内存缓存队里中等待消费，也可以由Consumer模拟Producer角色，将消息发送到Broker，等待再次消费。 主要过程为： 解析请求头，得到ConsumerSendMsgBackRequestHeader 如果原消息Id不为空，执行消费后置hook，调用ConsumeMessageHook.consumeMessageAfter 检查前置判断条件，包括所在Group是否存在、是否有权限等 默认放到Retry重试队列中，分配新的topic，格式为 ``%RETRY%+Group```` 检查重试队列配置，包括重试队列配置是否为空、重置队列是否可写等 根据原消息的偏移量offset在CommitLog中查找原消息内容(MessageExt格式) 判断该消息的重试次数是否已经超过设定的最大值(默认16次)，如果是，则将放到DLQ死信队列中，将topic格式更新为``%DLQ%+Group```` 将原消息重新包装为MessageExtBrokerInner对象，并调用MessageStore放到CommitLog中 2. PullMessageProcessor 消息拉取处理器，在介绍消费者消费消息过程时提到过，RocketMQ内部都是通过Pull方式从Broker拉取消息的，Push模式是通过包装Pull方式，由RocketMQ定时发起，并自动处理offset、消息重试动作。 PullMessageProcessor主要的工作是根据客户端提供的offset，从ConsumeQueue中获取到该topic-queueId在CommitLog中的起始位置，每次读取消息都会从ConsumeQueue中尽可能多的读取消息，并计算出客户端下次的offset,把结果返回。如果提供的offset过大，会将请求暂缓，在超时时间内或者ConsumeQueue的数据符合后，再次处理请求。 具体的处理流程如下： 上面过程比较清晰，大多是前置检查，主要看\"判断GetMessageResult\"的过程，如下： 该过程主要是设置返回结果RemotingCommand的值，包括： 偏移量:下次消费的起始偏移量、下次可消费的最小偏移量、下次可消费的最大偏移量 消费节点:下次从master节点还是slave节点消费 消费结果：成功(SUCCESS)、未找到符合条件的消息(PULL_NOT_FOUND)、直接重试(PULL_RETRY_IMMEDIATELY)、消息被移动(PULL_OFFSET_MOVED) 该过程有几点需要说明： 在判断response状态码进行后续处理前会执行一次前置调用，调用consumerMessageBefore，","date":"2020-05-04","objectID":"/rocketmq_07_broker/:0:0","tags":["rocketmq"],"title":"RocketMQ的心脏:Broker","uri":"/rocketmq_07_broker/"},{"categories":["srccode"],"content":"这节介绍CNameServer","date":"2020-04-15","objectID":"/rocketmq_06_nameserver/","tags":["rocketmq"],"title":"轻量级注册中心：RocketMQ NameServer","uri":"/rocketmq_06_nameserver/"},{"categories":["srccode"],"content":"NameServer实现比较简单，主要包括配置管理、路由管理两块。其主要功能是为整个MQ集群提供服务协调与治理，具体就是记录维护Topic、Broker的信息，及监控Broker的运行状态，为client提供路由能力。NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 NameServer为生产者和消费者提供Meta数据，以确定消息该发往哪个Broker或者该从哪个Broker拉取消息。有了Meta数据后，生产者和消费者就可以直接和 Broker交互了。这种点对点的交互方式最大限度降低了消息传递的中间环节，缩短了链路耗时。 1. 启动 NameServer的启动过程如下： 加载本地的备份文件，载入k-v对，有KVConfigManager持有，格式如下 HashMap\u003cString/* Namespace */, HashMap\u003cString/* Key */, String/* Value */\u003e\u003e configTable = new HashMap\u003cString, HashMap\u003cString, String\u003e\u003e(); 在有值发生变化的时候就会执行一次持久化 2. 初始化NettyRemotingServer，传入BrokerHousekeepingService，会在客户端连接发生变化的时候进行路由管理的变更 3. 初始化线程池，用于NettyRemotingServer分发请求，详见上一节关于Netty的介绍 4. 注册请求处理器，NameServer的实现为DefaultRequestProcessor，提供了包括PUT_KV_CONFIG、GET_KV_CONFIG等管理功能的CRUD远程调用入口 5. 启动定时器，每5秒扫描超时的broker连接并移除 6. 启动定时器，每10分钟打印一次kv对信息 2. 服务管理 NameServer的对外服务入口由DefaultRequestProcessor提供，主要包括配置管理和路由管理，分别由KVConfigManager和RouteInfoManager实现。 2.1. KVConfigManager 比较简单，中规中矩的一个类，内部有一个configTable按照命名空间管理配置键值对，除了put和get操作外，还有持久化为json以及加载持久化文件的操作。 2.2. RouteInfoManager RouteInfoManager主要用来管理Broker及Topic对应的路由信息，类关系如下： 包括： Topic对应的Queue列表 Queue所在的Broker，以及Queue对应的属性 Broker对应的集群信息、集群中的实例地址信息 每个Broker实例对应的存活信息，包括最后更新时间、版本号、Netty io连接、HA地址 集群对应的Broker列表 主要用于管理Broker和Topic的路由信息。 2.2.1. 注册Broker(registerBroker) 方法定义如下： public RegisterBrokerResult registerBroker( /*集群名*/final String clusterName, /*broker地址*/final String brokerAddr, /*broker名*/final String brokerName, /*brokerId*/final long brokerId, /*ha地址*/final String haServerAddr, /*broker上对应的topic配置项*/final TopicConfigSerializeWrapper topicConfigWrapper, /*需要过滤的server列表*/final List\u003cString\u003e filterServerList, /*broker对应的channel*/final Channel channel) 过程如下： 2.2.2. 根据topic选择路由信息(pickupTopicRouteData) 方法定义如下： public TopicRouteData pickupTopicRouteData(final String topic) 返回结果为： public class TopicRouteData extends RemotingSerializable { private String orderTopicConf; private List\u003cQueueData\u003e queueDatas;//topic中的queue private List\u003cBrokerData\u003e brokerDatas;//topic分布在哪些broker private HashMap\u003cString/* brokerAddr */, List\u003cString\u003e/* Filter Server */\u003e filterServerTable; ... } 即根据topic名找到该topic下所有Queue在Broker上的分布信息，过程如下： 2.2.3 去注册Broker(unregisterBroker) 去掉属性中持有的关于该Broker对应的所有数据，可以类比上面的过程看源码。 RouteInfoManager的其他服务也类似，都是从持有的各个属性中查找到数据有并返回。 相对于ZooKeeper这种支持强一致性的注册中心来说，NameServer实现上比较轻量，RocketMQ的架构设计决定了它不需要进行Master选举，用不到其他复杂的功能，只需要一个轻量级的元数据服务器就足够了。中间件对稳定性要求很高，RocketMQ的NameServer只有很少的代码，容易维护，所以不需要再依赖另一个中间件，从而减少整体维护成本。 ","date":"2020-04-15","objectID":"/rocketmq_06_nameserver/:0:0","tags":["rocketmq"],"title":"轻量级注册中心：RocketMQ NameServer","uri":"/rocketmq_06_nameserver/"},{"categories":["srccode"],"content":"这节介绍RocketMQ底层通信的原理","date":"2020-03-30","objectID":"/rocketmq_05_netty/","tags":["rocketmq"],"title":"Netty-RocketMQ底层通信的利器","uri":"/rocketmq_05_netty/"},{"categories":["srccode"],"content":"这节介绍RocketMQ底层通信的原理 在之前的内容中有介绍过RocketMQ底层用了Netty来进行通信，下图为RocketMQ通信的大致过程，主要分为Server端和Client端。 客户端通过invokeSyncImpl、invokeAsyncImpl、invokeOnewayImpl这几个方法同服务端交互。 1. NettyRemotingServer Server启动主要是初始化ServerBootstrap，主要配置如下： 设置tcp的参数，包括SO_BACKLOG、SO_REUSEADDR、SO_KEEPALIVE、TCP_NODELAY等。 设置pipeline处理链，包括编码、解码、空闲处理、连接管理、请求分发。 启动完ServerBootstrap后会启动一个定时器，每3秒清除超时的请求。 这里介绍下面几个处理器： NettyEncoder NettyDecoder NettyConnectManageHandler NettyServerHandler 1.1. NettyEncoder NettyEncoder继承自LengthFieldBasedFrameDecoder，主要有用于解码入站数据流，并将数据流解码为RemotingCommand对象。 LengthFieldBasedFrameDecoder（自定义长度解码器）的构造器，涉及5个参数，都与长度域（数据包中的长度字段）相关，具体介绍如下： maxFrameLength：发送的数据包最大长度； lengthFieldOffset：长度域偏移量，指的是长度域位于整个数据包字节数组中的下标； lengthFieldLength：长度域的自己的字节数长度。 lengthAdjustment：长度域的偏移量矫正。 如果长度域的值，除了包含有效数据域的长度外，还包含了其他域（如长度域自身）长度，那么，就需要进行矫正。矫正的值为：包长 - 长度域的值 – 长度域偏移 – 长度域长。 initialBytesToStrip：丢弃的起始字节数。丢弃处于有效数据前面的字节数量。比如前面有4个节点的长度域，则它的值为4。 以NettyEncoder为例，器构造构造方法为 public NettyDecoder() { super(FRAME_MAX_LENGTH, 0, 4, 0, 4); } 即数据流中前4个字节的值表示有效数据域的长度，除开前4个字节外的内容都是有效数据域的内容，不存在偏移量。 接收到数据域的内容后，便会调用RemotingCommand.decode方法，将数据流转为RemotingCommand对象。 RemotingCommand对象分为Header部分和Body部分。Header部分包括固定的一组字段，已经长度不定的扩展字段；Body部分为byte[]，不进行具体的细分。 数据域的解析过程同上面的类似，数据域中前4个自己为Header域的长度，取到Header长度后便能计算出Body长度，从而进行读取。RemotingCommand的内容如下： 根据serializerType的不同，Header的编码会分为Json或者二进制的方式。 1.2. NettyDecoder NettyEncoder的反过程，将RemotingCommand对象序列化为ByteBuffer对象。根据serializerType的不同，Header会编码为JSON或者二进制。 1.3. NettyConnectManageHandler NettyConnectManageHandler继承自ChannelDuplexHandler，用于监听pipeline中入站/出站的事件，主要进行日志记录。 1.4. NettyServerHandler NettyServerHandler继承自SimpleChannelInboundHandler，重写了channelRead0方法，在里面调用了父类NettyRemotingAbstract的processMessageReceived方法，如下： 该方法定义了请求和响应的处理过程。 1.processRequestCommand 处理请求过程，先根据RemotingCommand中的code值判断当前请求是否能够处理，如果不能处理则直接响应不支持。如果可以支持，则会找到对应的处理器，新起线程来处理当前请求。需要说明的是，NettyRemotingServer内部维护这一个processorTable，表示该server可以处理的command，对应的Processor以及对应的线程池。 protected final HashMap\u003cInteger/* request code */, Pair\u003cNettyRequestProcessor, ExecutorService\u003e\u003e processorTable = new HashMap\u003cInteger, Pair\u003cNettyRequestProcessor, ExecutorService\u003e\u003e(64); Processor的定义如下，对于具体的command，会由对应的Processor来处理 public interface NettyRequestProcessor { RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws Exception; boolean rejectRequest(); } RocketMQ提供的Processor如下，其中一个Processor可能会处理一个或者多个code. 2.processResponseCommand 客户端发起一次调用时，会根据请求id，构造一个ResponseFuture，并将其缓存在responseTable字段中，用来表示目前正在进行中的请求。 protected final ConcurrentMap\u003cInteger /* opaque */, ResponseFuture\u003e responseTable = new ConcurrentHashMap\u003cInteger, ResponseFuture\u003e(256); 当有响应的时候，会根据请求id，获取对应的ResponseFuture，再进行后置处理，包括执行回调、释放资源等。 2. NettyRemotingClient Client启动主要是初始化Bootstrap，主要配置如下： 设置tcp的参数，包括TCP_NODELAY、SO_KEEPALIVE、CONNECT_TIMEOUT_MILLIS等。 设置pipeline处理链，包括编码、解码、空闲处理、连接管理、请求分发。 启动完ServerBootstrap后会启动一个定时器，每3秒清除超时的请求。 Client端处理链上的几个处理器，除了NettyClientHandler外都同Server端的一样。而NettyClientHandler也继承自SimpleChannelInboundHandler，并重写了channelRead0方法，在里面调用了父类NettyRemotingAbstract的processMessageReceived方法，过程跟Server端类似。 3. 调用流程 上面介绍了Server端和Client端的启动过程，以及消息的编解码，这里介绍消息的具体请求过程。主要是开头提到的invokeSyncImpl、invokeAsyncImpl和invokeOnewayImpl这几个方法。 3.1. invokeSyncImpl 同步调用 内部是通过countdownlatch等待来模拟的同步调用，如下图： 客户端调用invokeSyncImpl后，client会构造ResponseFeature对象，并根据请求id将其缓存起来，然后调用Netty发送请求后在ChannelFutureListener中等待回调。 这时候客户端会通过countdownlatch等待一定的时间，如果客户端请求成功，则在ChannelFutureListener中直接返回，等待超时时间到达；如果请求失败，则直接通知countdownlatch，不再等待，直接返回 请求到达服务端，经过NettyDecoder、NettyServerHandler后，会调用processRequestCommand方法，最终在对应类型的线程池中提交任务，任务执行完后通过执行糊掉，返回结果 客户端接收到响应后，通过NettyClientHandler，会加油processResponseCommand方法处理，这时会根据请求id获取之前的ResponseReature对象，执行回调，最后清除缓存。 3.2. invokeAsyncImpl 异步调用 相比同步调用，少了等待超时时间，但是增加了semaphore信号量控制最多有多少个连接同时执行。请求发起后，将结果对象缓存起来，结果将通过InvokeCallback进行回调，如果有设置回调函数，结果返回，在回调线程发起后就会将信号量回收，如果没有设置回调函数，结果返回后就会将信号量回收。其余过程大致同同步调用类似。 3.3. invokeOnewayImpl 单步调用 单向请求，无结果，请求成功后不等待结果，直接释放信号量，服务端也不会返回结果。 3.4. MQClientAPIImpl MQClientAPIImpl在之前介绍过，主要为Producer和Consumer提供","date":"2020-03-30","objectID":"/rocketmq_05_netty/:0:0","tags":["rocketmq"],"title":"Netty-RocketMQ底层通信的利器","uri":"/rocketmq_05_netty/"},{"categories":["notes"],"content":"这两天在接触Gin，对它的动态路由功能比较感兴趣，特意做了笔记，顺便跟SpringMVC作下对比","date":"2020-03-16","objectID":"/notes-006-ginvsmvc/","tags":["java","golang"],"title":"动态路由:Gin vs SpringMVC","uri":"/notes-006-ginvsmvc/"},{"categories":["notes"],"content":" 这两天在接触Gin，对它的动态路由功能比较感兴趣，特意做了笔记，顺便跟SpringMVC作下对比。 1.简介 Gin是使用Go/golang语言实现的HTTP Web框架。接口简洁,性能极高。截止1.4.0版本,包含测试代码,仅14K,其中测试代码9K左右,也就是说框架源码仅5K左右。SpringMVC不用过多介绍，Java市场的一把手。 Gin支持动态路由，简单示例如下： import ( \"github.com/gin-gonic/gin\" \"net/http\" ) func main() { r := gin.Default() r.GET(\"/hello/:name\", func(context *gin.Context) { context.String(http.StatusOK, \"Hello : \"+context.Param(\"name\")) }) r.Run() } 对比SpringMVC的例子为： import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloWorldController { @RequestMapping(\"/hello/{name}\") public String antUser (@PathVariable(\"name\") String name) { return \"Hello : \" + name; } } 二者有相似的地方。 2.Gin Gin使用Trie树来实现动态路由。Trie树,即字典树,又称单词查找树或键树,是一种树形结构,是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。 Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有3个基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符。 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符都不相同。 如上图示，为一个保存了8个键的trie结构，“A”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”。其中，键标注在节点中，值标注在节点之下。每一个完整的英文单词对应一个特定的整数。Trie可以看作是一个确定有限状态自动机，尽管边上的符号一般是隐含在分支的顺序中的。 Trie数的常见应用场景包括： 字符串检索 词频统计 前缀检索 前缀词频统计 对所有的字符串按照字典序排序 Gin的路由实现也是跟上面的例子类似，具体实现在tree.go文件里，主要包括trie树的构建和查找过程。 2.1. 建树过程 先看node的定义 type node struct { path string // 当前节点相对路径,即公共前缀 indices string // 所有孩子节点的path[0]组成的字符串，如果子节点有通配符，则为空 children []*node // 孩子节点 handlers HandlersChain // 当前节点的处理函数（包括中间件） priority uint32 // 当前节点及子孙节点的实际路由数量 nType nodeType // 节点类型 maxParams uint8 // 子孙节点的最大参数数量 wildChild bool // 孩子节点是否有通配符（wildcard） fullPath string // 完整的请求路径，各中间节点也有 } 建树过程主要由两个方法来完成 // 根据给定的路径增加一个节点，主要用于处理公共前缀的分割 func (n *node) addRoute(path string, handlers HandlersChain) {} // 主要用于处理新节点的插入 func (n *node) insertChild(numParams uint8, path string, fullPath string, handlers HandlersChain) {} 流程如下： 使用addRoute方法从根节点添加一个新的路径P，如果树为空，则作为新节点直接插入，此时该节点为树中的第一个节点(根节点)，path和fullPath值都为P。如果根节点存在子节点，则找到P跟根节点path的公共前缀，如果不存在公共前缀，则将新节点作为根节点的子节点加入，使用insertChild方法。如果存在公共前缀，则分裂当前节点，将根节点(当前节点)公共前缀后的内容独立为一个子节点，并挂到当前节点下，更新indices；接着获取P去掉公共前缀的第一个字符，判断当前节点indices列表是否存在相同的字符，即判断剩下的内容是要作为新节点加入，还是要继续分裂，如果需要继续分裂，则重复addRoute方法。 以下面这段代码为例， r.GET(\"/q/query\", func(context *gin.Context) { context.String(http.StatusOK,\"Hello \"+context.Query(\"name\")) }) r.GET(\"/q/qaz/:name\", func(context *gin.Context) { context.String(http.StatusOK,\"Hello \"+context.Query(\"name\")) }) r.GET(\"/q/qaj/:name/l\", func(context *gin.Context) { context.String(http.StatusOK,\"Hello \"+context.Query(\"name\")) }) 构建的trie树为： 这里需要指出的是，对于通配符，:xxxx或者*，会作为一个单独的节点出现。 2.2. 查找过程 查找过程比较简单，直接从根节点往下找，知道找到匹配的节点，过程如下： 3.SpringMVC 如下为一个简单的示例： @RestController public class HelloWorldController { @RequestMapping(\"/hello/{name}\") public String antUser (@PathVariable(\"name\") String name) { return \"hello : \" + name; } } 之前在介绍《SpringMVC加载流程》是说过，Spring MVC路由的加载是由RequestMappingHandlerMapping来处理的。该类会查找所有符合条件的Method上的注解，然后添加到父类AbstractHandlerMethodMapping的MappingRegistry中封装为HandlerMethod进行缓存，直接以HashMap的方式。除了RequestMappingHandlerMapping外还有其他HandlerMapping,如SimpleUrlHandlerMapping,BeanNameUrlHandlerMapping等。 当查找符合的HandlerMethod时会遍历所有的HandlerMapping，如果某HandlerMapping能够处理，返回对应的HandlerExecutionChain,同时退出循环，由HandlerAdapter来执行具体的Method,Apdater会完成入参的注入。而RequestMappingHandler的动态路由则体现在HandlerMethod的查找上，该功能主要由AbstractHandlerMethodMapping的lookupHandlerMethod方法来实现。lookupHandlerMethod方法会遍历MappingRegistry中的所有注册对象，通过PatternsRequestCondition的getMatchingCondition来判断，具体交由AntPathMatcher来实现。 AntPathMatcher主要用来做类URLs字符串匹配,可以匹配的规则如下： ？匹配一个字符 *匹配0个或多个字符 **匹配0个或多个目录 具体实现在doMatch方法中。 即SpringMVC是通过遍历所有注册的Url，对每个Url应用AntPathMatcher来判断当前请求的Url是否符合注册的通配符写法，从而找到对应的处理函数。 如下为简单的示意图： 4.参考 https://zh.wikipedia.org/wiki/Trie ","date":"2020-03-16","objectID":"/notes-006-ginvsmvc/:0:0","tags":["java","golang"],"title":"动态路由:Gin vs SpringMVC","uri":"/notes-006-ginvsmvc/"},{"categories":["srccode"],"content":"这节介绍Consumer接收消息的流程，分为Pull和Push模式","date":"2020-02-25","objectID":"/rocketmq_04_consumer/","tags":["rocketmq"],"title":"RocketMQ Consumer接收消息流程","uri":"/rocketmq_04_consumer/"},{"categories":["srccode"],"content":" 这节介绍Consumer接收消息的流程，分为Pull和Push模式。 1. 初始化 上一节讲Rebalance时提到，Consumer接受客户端有两种方式： Broker发现客户端列表有变化，通知所有Consumer执行Rebalance Consumer定时没20秒自动执行Rebalance 其中1.的通知到达Consumer后，会立即触发Rebalance，然后会重置2.的定时器等待时间。二者最后通知Consumer的方式为 Push模式：当有新的Queue分配给客户端时，会新包装一个PullRequest，用于后续自动拉取消息，具体到DefaultMQPushConsumerImpl的executePullRequestImmediately方法 Pull模式：回调DefaultMQPullConsumerImpl的MessageQueueListener有Queue发生改变 2. Push模式 executePullRequestImmediately的内容为： public void executePullRequestImmediately(final PullRequest pullRequest) { this.mQClientFactory.getPullMessageService().executePullRequestImmediately(pullRequest); } 即将PullRequest对象传给了PullMessageService的executePullRequestImmediately方法： public void executePullRequestImmediately(final PullRequest pullRequest) { try { this.pullRequestQueue.put(pullRequest); } catch (InterruptedException e) { log.error(\"executePullRequestImmediately pullRequestQueue.put\", e); } } PullMessageService的结构如下： 内部维护着一个LinkedBlockingQueue属性pullRequestQueue，用于存储待处理的PullRequest;还有一个ScheduledExecutorService，用于延期处理PullRequest。具体流程如下： RebalanceImpl调用DefaultMQPushConsumerImpl的executePullRequestImmediately方法，传入PullRequest DefaultMQPushConsumerImpl内部调用PullMessageService的executePullRequestImmediately方法，该方法会把传入的PullRequest对象放到LinkedBlockingQueue中进行存储，等待后续处理。 PullMessageService会循环从队列中出队一个PullRequest，并调用自身的pullMessage用于后续处理。该动作会从MQClientInstance中选择对应的客户端实例DefaultMQPushConsumerImpl，并委托给它的pullMessage方法。 DefaultMQPushConsumerImpl会先判断当前请求是否满足条件，如果不满足条件，会调用PullMessage的executePullRequestLater方法，将当前请求延后处理。如果满足条件，会封装一个PullCallback对象用于处理异步消息，并调用PullAPIWrapper异步请求Broker拉取消息。 从上面的过程可以看出，Push模式内部还是客户端主动去拉取的，即所谓的封装拉模式以实现推模式,简单示意图如下： 内部通过PullMessageService循环的从PullRequest对应MessageQueue中主动拉取数据。 2.1. DefaultMQPushConsumerImpl.pullMessage(PullRequest) 该方法用于完成从MessageQueue拉取消息的过程，主要过程如下： 判断该MessageQueue对应的PullRequest是否已经标记为drop，如果是则直接返回 进行一系列的检查，如果检查不通过，则等待一定时间后再放回PullMessageService的待处理队列中，主要是通过PullMessageService中的ScheduledExecutorService来做到延迟执行，涉及的情况包括： 如果客户端未准备就绪(DefaultMQPushCOnsumerImpl执行start后status为RUNNING)，则延迟PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION(3000)后再放回PullMessage的队列中 如果是暂停状态，则延迟PULL_TIME_DELAY_MILLS_WHEN_SUSPEND(1000)后再放回PullMessageService的等待队列中 如果缓存的消息数大于配置的拉取线程数阈值(默认1000)，则等待PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL(50)后再返回等待队列中处理 如果缓存的消息大小大于配置的拉取大小阈值(默认100M)，则等待PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL(50)后再返回等待队列中处理 缓存的数据offset相差的偏移量超过设定值(默认2000)，则等待PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL(50)后再返回等待队列中处理 如果没有订阅MessageQueue对应的topic，则等待PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION(3000)后再返回队列中处理 包装PullCallback对象，并调用PullAPIWrapper发起异步请求拉取消息 上面通过PullAPIWrapper收到结果后会将结果包装为PullResult对象并回调PullCallback。PullCallback和PullResult的定义如下： public interface PullCallback { void onSuccess(final PullResult pullResult); void onException(final Throwable e); } public class PullResult { private final PullStatus pullStatus;//请求状态 private final long nextBeginOffset;//Broker返回的下一次开始消费的offset private final long minOffset; private final long maxOffset; private List\u003cMessageExt\u003e msgFoundList;//消息列表，一次请求返回一批消息 } 下面为pullMessage方法处理异步返回结果的流程： 如果请求失败，则等待PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION(3000)后再放回PullMessageService的待处理队列中；处理成功则进入2. 调用PullAPIWrapper对结果进行预处理 根据请求状态进行处理 有新消息(FOUND) 设置PullRequest下次开始消费的起始位置为PullResult的nextBeginOffset 如果结果列表为空则不延迟，立马放到PullMessageService的待处理队列中，否则进入3 将PullResult中的结果List\u003cMessageExt\u003e放入ProcessQueue的缓存中，并通知ConsumeMessageService处理 将该PullRequest放回待处理队列中等待再次处理，如果有设置拉取的间隔时间，则等待该时间后再翻到队列中等待处理，否则直接放到队列中等待处理 没有新消息(NO_NEW_MSG) 设置PullRequest下次开始消费的起始位置为PullResult的nextBeginOffset 如果缓存的待消费消息数为0，则更新offset存储 将PullRequest立马放到PullMessageService的待处理队列中 没有匹配的消息(NO_MATCHED_MSG) 设置PullRequest下次开始消费的起始位置为PullResult的nextBeginOffset 如果缓存的待消费消息数为0，则更新offset存储 将PullRequest立马放到PullMessageService的待处理队列中 不合法的偏移量(OFFSET_ILLEGAL) 设置PullRequest下次开始消费的起始位置为PullResult的nextBeginOffset 标记该PullRequset为drop 10s后再更新并持久化消费offset；再通知Rebalance移除该MessageQueue 下面先介绍下ProcessQueue，这里只标识几个相关的属性： public class ProcessQueue { private final ReadWriteLock lockTreeMap = new ReentrantReadWriteLock(); //缓存的待消费消息","date":"2020-02-25","objectID":"/rocketmq_04_consumer/:0:0","tags":["rocketmq"],"title":"RocketMQ Consumer接收消息流程","uri":"/rocketmq_04_consumer/"},{"categories":["srccode"],"content":"这节介绍Rebalance流程","date":"2020-02-22","objectID":"/rocketmq_03_rebalance/","tags":["rocketmq"],"title":"RocketMQ RocketMQ Rebalance流程分析","uri":"/rocketmq_03_rebalance/"},{"categories":["srccode"],"content":" 这节介绍Rebalance流程。在介绍Consumer消费消息流程前，先介绍Rebalance得流程，该过程涉及到Consumer的启动。 之前介绍过，Topic是一个逻辑概念，Topic下可以划分多个Queue以增加Consumer消费的并行度。在一个Consumer Group内，Queue和Consumer之间的对应关系是一对多的关系：一个Queue最多只能分配给一个Consumer，一个Cosumer可以分配得到多个Queue，如下图 而Rebalance是一种协议，规定了一个 Consumer Group 下的所有 consumer如何达成一致来分配Queue。当Consumer订阅的Topic发生变化，或者Consumer Group内的Consumer实例发送变化时便会触发Rebalance以重新分配每个实例对应的Queue。 1.RebalanceService 前面介绍客户端启动流程时提到，MQClientInstance在start方法中会启动一系列后台任务，其中就包括Rebalance任务，主要调用了RebalanceService的start方法。RebalanceService继承自ServiceThread，start方法会启动一个后台线程，确保每隔一段时间（默认20秒）会调用一次MQClientInstance的doRebalance方法。如下图： MQClientInstance.doRebalance会调用MQConsumerInner.doRebalance。MQConsumerInner是DefaultMQPullConsumerImpl和DefaultMQPushConsumerImp的父接口，如下，即MQClientInstance将doRebalance方法交给了Consumer实例处理。 接着Consumer实例会调用内部RebalnaceImpl的doRebalance方法完成真正的，动作。 这里提一点，RebalanceService被MQClientInstane持有，一个MQClientInstance只有一个Rebalance实例，之前在讲客户端启动时提到，MQClientInstance由MQClientManager管理，跟本机ip,进程pid有关。RebalanceImpl跟Consumer实例相关，一个Consumer实例对应一个RebalanceImpl对象。 2.RebalanceImpl 先介绍该类的基本情况 1.属性 protected final ConcurrentMapConcurrentMap\u003c/*Queue*/MessageQueue, /*Queue消费进度镜像*/ProcessQueue\u003e processQueueTable = new ConcurrentHashMap\u003cMessageQueue, ProcessQueue\u003e(64); //DefaultMQXxxxConsumerImpl updateTopicSubscribeInfo时添加 protected final ConcurrentMap\u003cString/* topic */, Set\u003cMessageQueue\u003e\u003e topicSubscribeInfoTable = new ConcurrentHashMap\u003cString, Set\u003cMessageQueue\u003e\u003e(); //DefaultMQXxxxConsumerImpl subscript时会添加 protected final ConcurrentMap\u003cString /* topic */, /*消息的过滤条件*/SubscriptionData\u003e subscriptionInner = new ConcurrentHashMap\u003cString, SubscriptionData\u003e(); protected String consumerGroup;//Consumer实例所在的ConsumerGroup protected MessageModel messageModel;//消息消费模式 protected AllocateMessageQueueStrategy allocateMessageQueueStrategy;//Queue分配策略，默认为AllocateMessageQueueAveragely 2.继承关系 接第一Part的内容，会调用该类的doRebalce方法，主要逻辑如下： (1) 轮训该实例订阅的所有topic，通过遍历subscriptionInner的值来获取topic信息，该属性内容会在客户端实例调用subscript时增加 (2) 根据topic调用rebalanceByTopic执行rebalance (3)如果是广播模式，则从topicSubscribeInfoTable获取该topic下的所有Queue，用于后续更新。即广播模式，每个客户端都能收到topic下的所有q,为客户端分配的Queue集合为全量的集合。 (4)如果是集群模式，会获取topic下的所有Queue；从broker获取该topic下所有客户端id列表；排序后调用AllocateMessageAueueStrateg获得ConsumerGroup下该客户端应该分配到的Queue集合。即集群模式，每个客户端分到的q列表由AllocateMessageQueueStrategy来分配。 (5) 获取该客户端所属的Queue集合后，调用updateProcessQueueTableInRebalance更新。 (6) 执行完后，如果有发生变化，则调用messageQueueChanged交给子类具体处理。 (7) 调用truncateMessageQueueNotMyTopic移除缓存中不是该实例处理的Queue。 2.1. 从broker查找该topic对应的客户端id列表 从MQClientInstance的缓存中获取该topic对应的broker地址，然后调用Netty直接访问broker获取结果 2.2. 分配客户端实例所属Queue集合 前面说过，广播模式每个客户端实例分配到全量的Queue集合，这里主要介绍集群模式下AllocateMessageQueueStrategy的处理情况。默认为平均分配，实现类为AllocateMessageQueueAveragely。 先看AllocateMessageQueueStrategy的定义 List\u003cMessageQueue\u003e allocate( final String consumerGroup,//当前Consumer实例所属ConsumerGroup final String currentCID,//当前客户端应用ID final List\u003cMessageQueue\u003e mqAll,//待分配的Queue列表 final List\u003cString\u003e cidAll //该topic，该ConsumerGroup下的所有客户端应用ID列表 ); 该方法会选出currentCID所属的Queue列表。AllocateMessageQueueAveragely则是按照currentCID所属的位置进行平均分配，过程如下： 上面在源码里加上了对应的注释。前面提到传进来的mqAll和cidAll都是排过序的，该过程就是按照客户端序号，从所有Queue列表中平均分配自己所属的Queue，涉及到的各种可能如下： 大概过程就是：能整除，则平均分；不能整除，则cid在mod数内的则多分1个Queue，在mod数外的则少分一个。 前面说过，该分配策略执行时，会将topic下的Queue列表和客户端进行排序，在分配时便会导致排在前面的客户端能分到Queue，且分的Queue会多点。考虑一种情况，如果一个ConsumerGroup订阅了2个topic，Topic_X和Topic_Y,每个topic都有2个Queue，同时该ConsumerGroup下有4个客户端实例，因为Rebalance是根据topic来的，所以不会出现4个Queue被平均消费的情况，结果如下如下： 因而在初始化时，最好保证ConsumerGroup下的客户端数量\u003c=Topic下的Queue数量。 2.3. updateProcessQueueTableInRebalance 该方法的定义如下： /** * @param topic topic * @param mqSet Rebalance后该客户端实例，该topic下的所有现有分配到的q集合 * @param isOrder 是否为顺序消费 * @return */ private boolean updateProcessQueueTableInRebalance(final String topic, final Set\u003cMessageQueue\u003e mqSet,final boolean isOrder) {} 前面提到，RebalanceImpl只有一个processQueueTable属性，该属性维护了当前客户端真在处理的所有Queue，以及Queue对应的消费进度，updateProcessQueueTableInRebalance则会更新该属性。 1 找出rebalance后不属于当前客户端实例的Queue或者已经过期的Queue,标记为drop，并由子类判断是否是否需要移除，如果需要移除，则该客户端实例所属的Queue便有改变。 2 判断Rebalance后分配的","date":"2020-02-22","objectID":"/rocketmq_03_rebalance/:0:0","tags":["rocketmq"],"title":"RocketMQ RocketMQ Rebalance流程分析","uri":"/rocketmq_03_rebalance/"},{"categories":["srccode"],"content":"这节介绍Producer发送消息的流程。","date":"2020-02-05","objectID":"/rocketmq_02_producer/","tags":["rocketmq"],"title":"RocketMQ Producer发送消息流程","uri":"/rocketmq_02_producer/"},{"categories":["srccode"],"content":" 这节介绍Producer发送消息的流程。 接上一节开头的Demo，发送消息的写法如下： public class SyncProducer { public static void main (String[] args) throws Exception { // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer (\"GroupTest\"); // 设置NameServer的地址 producer.setNamesrvAddr (\"localhost:9876\"); // 启动Producer实例 producer.start (); for (int i = 0; i \u003c 100; i++) { // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message (\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes (RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send (msg); // 通过sendResult返回消息是否成功送达 System.out.printf (\"%s%n\", sendResult); } // 如果不再发送消息，关闭Producer实例。 producer.shutdown (); } } 发送消息的方法为： SendResult sendResult = producer.send (msg); 其send方法内容如下： public SendResult send( Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { return this.defaultMQProducerImpl.send(msg); } 主要调用了DefaulMQProducerImpl，委托给了DefaultMQProducerImpl的send方法。而DefaultMQProducerImpl又调用了自身的sendDefaultImpl，该方法完成了发送的主要动作。sendDefaultImpl的定义如下： private SendResult sendDefaultImpl( Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout ) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {} 参数包括： Message:消息内容 CommunicationMode:通讯模式，包括同步、异步、单步 SendCallback:异步模式下的回调接口，包括成功和异常通知 timeout:超时时间 如下为SendDefaultImpl的主要执行过程： (1) 确保客户端已经初始化成功 主要确保DefaultMQProducerImpl的状态为RUNNING (2) 查询topic的发布信息 从内部维护的ConcurrentMap\u003cString/* topic */, TopicPublishInfo\u003e中获取topic对应的发布信息，上一节介绍过，该信息会通过后台线程定时更新，如果当前没有topic对应的信息，则会立即调用updateTopicRouteInfoFromNameServer方法实时同步。 TopicPlushInfo用于表示Topic的路由信息，第一节介绍RocketMQ时说过，Topic的数据分布在多个Broker上，同时在一个broker上还会分为若干个Queue以增加并行度。 上图的关系图中，TopicPlushInfo持有一个MessageQueue列表和一个TopicRouteData。MessageQueue表示了各个Queue的映射信息，即上面提到的各个Broker上的Queue。而TopicRouteData则用于描述Broker的位置信息和Queue的配置信息。 (3) 判断是否有路由信息 如果上一步没有查询到topic对应的发布信息，则抛出异常结束，否则转到(4) (4) 计算重试次数 根据通讯模式计算重试次数 int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; 即如果是同步模式，则在失败时会再重试配置的次数(默认为2次)，其他情况不进行重试。 (5) 判断当前是否需要重试 即判断当前执行次数是否已经超过重试次数，如果已经超过，则说明重试次数用完，没法继续尝试，判断当前是否有结果，如果有结果则返回，否则抛出异常结束。如果重试次数没用完，则转到(6) (6) 选取一个延迟较短的broker 选取一个延迟较短的broker,该功能由MQFaultStrategy提供。这里先介绍MQFaultStrategy，其提供了可选的故障延迟机制，对于请求响应较慢的broker，可以在一段时间内将其状态置为不可用。如下图： 可以通过MQFaultStrategy的sendLatencyFaultEnable属性控制是否打开故障延迟机制开关，默认为false不打开。在打开该开关时，则每次选取topic下对应的queue时，会基于之前执行的耗时，在有存在符合条件的broker的前提下，优选选取一个延迟较短的broker，否则再考虑随机选取。 LatencyFaultTolerance用于维护有“故障”broker的“可用”状态。对于每一个被定义为“故障”的broker，LatencyFaultTolerance内部都会有一个对应的FaultItem来表示，其主要内容如下： class FaultItem implements Comparable\u003cFaultItem\u003e { private final String name;//brokername private volatile long currentLatency;//最近发生延迟的时间点 private volatile long startTimestamp;//下一次开始可用的时间点 public FaultItem(final String name) { this.name = name; } public boolean isAvailable() {//判断当前时间是否已经过了设置的开始可用时间点 return (System.currentTimeMillis() - startTimestamp) \u003e= 0; } } 即当一个broker发送故障时，会记录其最近发生延迟的时间点和下一次开始可用的时间点，而一个broker“可用”的意思是指：该broker不存在LatencyFaultTolerance维护的faultItemTable属性中，或者当前时间已经大于该broker下一次开始可用的时间点。 LatencyFaultTolerance通过updateFaultItem方法更新“故障”broker的可用状态，该方法会直接更新faultItemTable中broker对应FaultItem的最近延迟时间和最近开始可用时间点。该方法需要给定指定broker的不可用时间。而判断一个broker是否有故障以及不可用时间的方法，则在MQFaultStrategy的computNotAvaliableDuration方法中,如下： private long computeNotAvailableDuration(final long currentLatency) { for (int i = latencyMax.length - 1; i \u003e= 0; i--) { if (currentLatency \u003e= latencyMax[i]) return this.notAvailableDuration[i]; } return 0; } 其中延迟级别数组latencyMax和不可用时长数组notAvailableDuration的定义如下： private long[] latencyMax = {50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L}; private long[] notAvailableDuration = {0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L}; 即如果当前请求的“延迟时间”超过latencyMax的某个级别，则认为该broker已经是“故障”状态，会从notAvailableDuration中选择该broke对应的不可用时间。从这两组数组的定义也可以看出来，当延迟时间小于50ms则认为该broker状态正常，不用进行故障延迟处理。而“延迟时间","date":"2020-02-05","objectID":"/rocketmq_02_producer/:0:0","tags":["rocketmq"],"title":"RocketMQ Producer发送消息流程","uri":"/rocketmq_02_producer/"},{"categories":["srccode"],"content":"这节介绍RocketMQ客户端的启动流程，即Consumer和Producer的启动流程。","date":"2020-01-08","objectID":"/rocketmq_01_client/","tags":["rocketmq"],"title":"RocketMQ客户端加载流程","uri":"/rocketmq_01_client/"},{"categories":["srccode"],"content":" 这节介绍RocketMQ客户端的启动流程，即Consumer和Producer的启动流程。 1. 客户端demo 首先先看下客户端的demo Producer: public class SyncProducer { public static void main (String[] args) throws Exception { // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer (\"GroupTest\"); // 设置NameServer的地址 producer.setNamesrvAddr (\"localhost:9876\"); // 启动Producer实例 producer.start (); for (int i = 0; i \u003c 100; i++) { // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message (\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes (RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send (msg); // 通过sendResult返回消息是否成功送达 System.out.printf (\"%s%n\", sendResult); } // 如果不再发送消息，关闭Producer实例。 producer.shutdown (); } } Consumer: public class Consumer { public static void main (String[] args) throws InterruptedException, MQClientException { // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer (\"GroupTest\"); // 设置NameServer的地址 consumer.setNamesrvAddr (\"localhost:9876\"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe (\"TopicTest\", \"*\"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener (new MessageListenerConcurrently () { @Override public ConsumeConcurrentlyStatus consumeMessage (List\u003cMessageExt\u003e msgs, ConsumeConcurrentlyContext context) { System.out.printf (\"%s Receive New Messages: %s %n\", Thread.currentThread ().getName (), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); // 启动消费者实例 consumer.start (); System.out.printf (\"Consumer Started.%n\"); } } Producer和Consumer的启动类似，在初始化然后进行必要设置（主要是客户端所属的Group和NameServer地址）后，执行start方法启动后台监听服务，事实上Producer和Consumer都是调用同一个类MQClientInstance的start方法，下图为继承关系： DefaultMQproducer和DefaultMQPushConsumer都继承自ClientConfig，顾名思义ClientConfig表示客户端的配置，包括NameServer地址、客户端地址、客户端实例名等。由于Producer和Consumer都需要同Broker和NameServer交互，所以配置上有很多相同，这两个将主要功能的实现都委托给了对应的Impl(DefaultMQProducerImpl和DefaultMQPushConsumerImpl)。Impl内部调用了MQClientInstance来完成客户端同远程交互的主要功能，而Producer和Consumer则封装自己相关的行为，MQClientInstance内部又委托忒了MQClientAPIImpl。 2. Producer的启动 DefaultMQProducer的启动如下： DefaultMQProducer将start委托给了DefaultMQProducerImpl来完成，主要过程为： DefaultMQProducerImpl先标记客户端当前状态为START_FAILED（初始状态为CREATE_JUST） 调用MQClientManager的getAndCreateMQClientInstance方法获取MQClientInstance，每个客户端实例都会对应一个MQClientInstance，并由MQClientManager管理。MQClientManager内部使用一个Map维护各客户端的关系，key为clientId(格式为ip@instName,instName为pid)，value为MQClientInstance实例。当key不存在时则会初始化一个实例，在初始化时连带初始化MQClientAPIImpl、NettyRemoteClient等。 调用MQClientInstance的registerProducer方法，注册当前客户端自身。实现上是客户端放入client实例缓存中，定时器定时上报，后面会说。 调用MQClientInstance的start方法，启动客户端的后台任务，该方法是重点，后面会介绍。 标记客户端当前状态为RUNNING 调用MQClientInstance的sendHeartbeatToAllBrokerWithLock方法，向所有Broker上报心跳 3. Consumer的启动 DefaultMQPushConsumer的启动如下： DefaultMQPushConsumer同样将start委托给了DefaultMQPushConsumerImpl来完成，流程上也相识。但相比DefaultMQProducer多了很多其他组件来辅助消费过程，如rebalance、offset管理等，主要过程为： DefaultMQPushConsumerImpl先标记客户端当前状态为START_FAILED（初始状态为CREATE_JUST） 同步设置RebalanceImpl的topic(Map\u003cString,String\u003e / \u003ctopic,sub expression\u003e)信息 同DefaultMQProducer一致，调用MQClientManager的getAndCreateMQClientInstance方法获取MQClientInstance，每个客户端实例都会对应一个MQClientInstance，并由MQClientManager管理。MQClientManager内部使用一个Map维护各客户端的关系，key为clientId(格式为ip@instName)，value为MQClientInstance实例。当key不存在时则会初始化一个实例，在初始化时连带初始化MQClientAPIImpl、NettyRemoteClient等。这里需要说明的是，RocketMQ中Consumer的消费模式分为CLUSTERING和BROADCASTING，即集群消费和广播消费。区别在于集群消费时，一条消息只会被一个实例消费，即各实例会平分所有的消息；而广播消费时所有实例都会收到同一条消息。体校在clientId的是，集群模式下instName为pid，而广播模式instName为DEFAULT。 设置RebalanceImpl属性，包括所在Group、消费模式、消息分配策略(平均分配q的策略) 初始化PlullAPIWrapper,设置消息过滤器钩子列表 初始化OffsetStore，设置offset的存储模式，广播模式使用本地存储；集群模式使用远程存储 初始化ConsumeMessageService，根据监听器类型设定消息消费模式(顺序消费/并行消费)，pull模式需要自己指定offset，push不需要设定。 启动ConsumeMessageService 同DefaultMQProducer一致，调用MQClientInstance的registerProducer方法，注册当前客户端自身。实现上是客户端放入client实例缓存中，定时器定时上报，后面会说。 调用MQClientInstance的start方法，启动客户端的后台任务，该方法是重点，后面会介绍。 标记客户端当前状态为RUNNING 判断监听信息是否发生改变，从namesrv更新topic的路由信息 调用MQClientInstance的checkClientInBroker方法，确认该实例已经在broker注册","date":"2020-01-08","objectID":"/rocketmq_01_client/:0:0","tags":["rocketmq"],"title":"RocketMQ客户端加载流程","uri":"/rocketmq_01_client/"},{"categories":["srccode"],"content":"这节介绍Spring MVC","date":"2020-01-07","objectID":"/spring_07_mvc/","tags":["spring"],"title":"Spring MVC","uri":"/spring_07_mvc/"},{"categories":["srccode"],"content":" 这节介绍SpringMVC，SpringMVC是一种基于Java的实现MVC设计模式的请求驱动类型的轻量级Web框架。本章会介绍相关概念，流程，再从源码进行讲解。 1. MVC MVC(Model View Controller)是一种软件设计的框架模式，它采用模型(Model)-视图(View)-控制器(controller)的方法把业务逻辑、数据与界面显示分离。MVC框架模式是一种复合模式，MVC的三个核心部件分别是 Model(模型)：所有的用户数据、状态以及程序逻辑，独立于视图和控制器 View(视图)：呈现模型，类似于Web程序中的界面，视图会从模型中拿到需要展现的状态以及数据，对于相同的数据可以有多种不同的显示形式(视图) Controller(控制器)：负责获取用户的输入信息，进行解析并反馈给模型，通常情况下一个视图具有一个控制器 2. SpringMVC流程 基本上大家都会在网上看到这张图： 这个图描述了SpringMVC处理一个Http请求的基本流程，对应的流程为： 用户发送请求至前端控制器DispatcherServlet。 DispatcherServlet收到请求调用HandlerMapping处理器映射器。 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 DispatcherServlet调用HandlerAdapter处理器适配器。 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。 Controller执行完成返回ModelAndView。 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。 ViewReslover解析后返回具体View. DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet响应用户。 还有大家都会接触到的demo: web.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cweb-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"\u003e \u003ccontext-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003e/WEB-INF/applicationContext.xml\u003c/param-value\u003e \u003c/context-param\u003e \u003clistener\u003e \u003clistener-class\u003eorg.springframework.web.context.ContextLoaderListener\u003c/listener-class\u003e \u003c/listener\u003e \u003cservlet\u003e \u003cservlet-name\u003edispatcher\u003c/servlet-name\u003e \u003cservlet-class\u003eorg.springframework.web.servlet.DispatcherServlet\u003c/servlet-class\u003e \u003cload-on-startup\u003e1\u003c/load-on-startup\u003e \u003c/servlet\u003e \u003cservlet-mapping\u003e \u003cservlet-name\u003edispatcher\u003c/servlet-name\u003e \u003curl-pattern\u003e/*\u003c/url-pattern\u003e \u003c/servlet-mapping\u003e \u003c/web-app\u003e 在applicationContext.xml，指定包的扫描访问并添加标签 \u003ccontext:component-scan base-package=\"xxx\" /\u003e \u003cmvc:annotation-driven /\u003e 添加Controller import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @RequestMapping(\"/hello\") public String excute() { return \"hello\"; } } 上面表示的意思为： 开启ContextLoaderListener加载Spring根Context，对应的配置文件为applicationContext.xml 开启DispatcherServlet监听/*下的所有请求，加载WebContext，对应的配置文件为dispatcher-servlet.xml 指定扫描包路径，并开启mvc注解支持 添加对应的Controller，使用@RestController标记为Controller对象并使用@RequestMapping标记处理的请求路径 3. SpringMVC加载流程 SpringMVC的加载是依赖Servlet切入的，主要依赖两个技术点：Listener和Servlet。 3.1. ContextLoaderListener的加载 从web.xml中可以知道，ContextLoaderListener依赖于Servlet的Listener技术。Listener是在servlet2.3中加入的，主要用于对session、request、context等进行监控。使用Listener需要实现相应的接口。触发Listener事件的时候，tomcat会自动调用相应的Listener的方法。常用的监听接口包括： HttpSessionListener:监听session的创建和销毁。 ServletRequestListener:监听request的创建和销毁 ServletContextListener:监听context的创建和销毁。 这里主要使用了ServletContextListener，用于在Servlet初始化前执行自定义动作。 ContextLoaderListener的定义如下： public class ContextLoaderListener extends ContextLoader implements ServletContextListener { public ContextLoaderListener() { } public ContextLoaderListener(WebApplicationContext context) { super(context); } @Override public void contextInitialized(ServletContextEvent event) { initWebApplicationContext(event.getServletContext()); } @Override public void contextDestroyed(ServletContextEvent event) { closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); } } 该类继承了ContextLoader，并通过contextInitialized方法执行了初始化(传入ServletContext)，通过contextDestroyed方法进行资源销毁回收。重点看ContextLoader方法。 ContextLoader在初始化时，会先执行内部的一个静态代码块： private static final Properties defaultStrategies; static { try { ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, ContextLoader.class); defaultStrategies = PropertiesLoaderUtils.loadProperties(resource); } catch (IOException ex) { throw new IllegalStateException(\"Could not load 'ContextLoader.properties': \" + ex.getMessage()); } } 这一步会加载classpath下的配置文件ContextLoader.properties，该文件将作为默认配置用于初始化Properties对象defaultStrate","date":"2020-01-07","objectID":"/spring_07_mvc/:0:0","tags":["spring"],"title":"Spring MVC","uri":"/spring_07_mvc/"},{"categories":["srccode"],"content":"介绍RocketMQ","date":"2019-12-28","objectID":"/rocketmq_00_basic/","tags":["rocketmq"],"title":"RocketMQ介绍","uri":"/rocketmq_00_basic/"},{"categories":["srccode"],"content":" 消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。Apache RocketMQ是由阿里巴巴开源的可支撑万亿级数据洪峰的分布式消息和流计算平台，于2016年捐赠给Apache Software Foundation，2017年9月25日成为Apache 顶级项目。由于其高稳定性、低延时、高吞吐量等特点，被大规模应用于金融、互联网、物流公司的核心交易支付、实时位置追踪、大数据分析等场景，同时也被电力、交通、汽车、零售等十几个行业的数万家企业广泛使用，是企业数字化转型的核心基础性软件。​ 网上对RocketMQ的介绍很多，还有中文开发者网站http://rocketmq.cloud/zh-cn/index.html，大家可以自行搜索。本章结合网上的各种介绍（内容均来自网上），只对相关的内容、概念进行说明，为后续文章做准备。 工作中也比较多的接触RocketMQ，之前看过RocketMQ的源码，梳理过流程，但是没有输出文档。为此，这边将以RocketMQ 4.4.0版本为例，重新整理源码中相应的流程。 1. 总体架构 如下为RocketMQ的总体架构： 这里涉及到的角色包括： NameServer:NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能： Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活 路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。 NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。 Broker:Broker主要负责消息的存储、投递和查询以及服务高可用保证。Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 Producer:消息发布的角色，支持分布式集群方式部署。 Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Producer Group:一类 Producer 的集合名称，这类 Producer 通常发送一类消息，且消费逻辑一致。 Consumer:消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。 Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。 Consumer Group:一类 Consumer 的集合名称，这类 Consumer 通常消费一类消息，且消费逻辑一致。 2. 工作流程 结合部署架构图，描述集群工作流程： 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。 如下图示： Producer会向一些队列轮流发送消息，这些队列集合称为Topic。Consumer可以做广播消费，也可以做集群消费，如果做广播消费，则一个Consumer实例消费这个Topic对应的所有队列，如果做集群消费，则多个Consumer 实例平均消费这个Topic对应的队列集合。 Topic是逻辑概念，对于RocketMQ，一个Topic可以分布在各个Broker上，把一个Topic分布在一个Broker上的子集定义为一个Topic分片，其实就是在某一broke上一个topic的部分数据 对应上图，TopicA有3个Topic分片，分布在Broker1,Broker2和Broker3上，TopicB有2个Topic分片，分布在Broker1和Broker2上，TopicC有2个Topic分片，分布在Broker2和Broker3上。 将Topic分片再切分为若干等分，其中的一份就是一个Queue（队列）。每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定。每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定, 是消费负载均衡过程中资源分配的基本单元。需要指出的是，在一个Consumer Group内，Queue和Consumer之间的对应关系是一对多的关系：一个Queue最多只能分配给一个Consumer，一个Cosumer可以分配得到多个Queue。这样的分配规则，每个Queue只有一个消费者，可以避免消费过程中的多线程处理和资源锁定，有效提高各Consumer消费的并行度和处理效率。即是负载均衡过程中资源分配的基本单元，同Kafaka相同。 3. 消息 消息(Message)是系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个Topic。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。 可以为消息设置标志（Tag），用于同一Topic下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一Topic下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。 消息的消费可以分为集群消费和广播消费 集群消费（Clustering）：集群消费模式下,相同Consumer Group的每个Consumer实例平均分摊消息。 广播消费（Broadcasting）：广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息。 ","date":"2019-12-28","objectID":"/rocketmq_00_basic/:0:0","tags":["rocketmq"],"title":"RocketMQ介绍","uri":"/rocketmq_00_basic/"},{"categories":["notes"],"content":"这节介绍JVMTI中的Instrument API","date":"2019-12-21","objectID":"/jacoco_03_instrument_api/","tags":["jacoco"],"title":"Instrument API介绍","uri":"/jacoco_03_instrument_api/"},{"categories":["notes"],"content":"1. Instrumentation介绍 JVMTI（JVM Tool Interface）是 Java 虚拟机所提供的 native 编程接口，是 JVMPI（Java Virtual Machine Profiler Interface）和 JVMDI（Java Virtual Machine Debug Interface）的更新版本。JVMTI 提供了一套“代理”程序机制，可以支持第三方工具程序以代理的方式连接和访问 JVM，并利用 JVMTI 提供的丰富的编程接口，完成很多跟 JVM 相关的功能。 Agent 即 JVMTI 的客户端，它和执行 Java 程序的虚拟机运行在同一个进程上。他们通常由另一个独立的进程控制，充当这个独立进程和当前虚拟机之间的中介，通过调用 JVMTI 提供的接口和虚拟机交互，负责获取并返回当前虚拟机的状态或者转发控制命令。java.lang.instrument 包的实现，也是基于这种机制的。在 Instrumentation 的实现当中，存在一个 JVMTI 的代理程序，通过调用 JVMTI 当中于 Java 类相关的函数来完成Java 类的动态操作。 利用 java.lang.instrument 做动态 Instrumentation 是 Java SE 5 的新特性，它把 Java 的 instrument 功能从本地代码中解放出来，使之可以用 Java 代码的方式解决问题。使用 Instrumentation，开发者可以构建一个独立于应用程序的代理程序（Agent），用来监测和协助运行在 JVM 上的程序，甚至能够替换和修改某些类的定义。有了这样的功能，开发者就可以实现更为灵活的运行时虚拟机监控和 Java 类操作了，这样的特性实际上提供了 一种虚拟机级别支持的 AOP 实现方式，使得开发者无需对 JDK 做任何升级和改动，就可以实现某些 AOP 的功能了。 在 Java SE6 里面，最大的改变是运行时的 Instrumentation 成为可能。在 Java SE 5 中，Instrument 要求在运行前利用命令行参数或者系统参数来设置代理类，在实际的运行之中，虚拟机在初始化之时（在绝大多数的 Java 类库被载入之前），instrumentation 的设置已经启动，并在虚拟机中设置了回调函数，检测特定类的加载情况，并完成实际工作。但是在实际的很多的情况下，我们没有办法在虚拟机启动之时就为其设定代理，这样实际上限制了 instrument 的应用。而 Java SE 6 的新特性改变了这种情况，通过 Java Tool API 中的 attach 方式，我们可以很方便地 在运行过程中动态地设置加载代理类，以达到 instrumentation 的目的。 Instrumentation 的最大作用，就是类定义动态改变和操作。在 Java SE 5 及其后续版本当中，开发者可以在一个普通 Java 程序（带有 main 函数的 Java 类）运行时，通过 -javaagent参数指定一个特定的 jar 文件（包含 Instrumentation 代理）来启动 Instrumentation 的代理程序。 2. Transformer Transformer是字节码转换的接口，Instrumentation是管理Transformer、调度Transformer进行字节码转换的门面。 当执行Instrumentation的addTransformer、removeTransformer方法时，最终是调用了TransformerManager的addTransformer、removeTransformer，以此来管理Transformer。 Instrumentation的retransformClasses、redefineClasses是用于通知TransformerManager调度字节码转换的。除此之外，在调用ClassLoader.defineClass1()这个native方法用于进行类的定义时，也会通知TransformerManager调度Transformer来进行字节码转换。这三个字节码转换通知时机分别称为： 加载类时（1） 重定义类时（2） 重转换类时（3） Transformer可以分为两类：可重转换的Transformer、不可重转换的Transformer。任何一个Transformer都可以用于加载类时、重定义类时进行转换。如果是可重转换的Transformer，也可以在重转换时进行转换。对于所有的注册转换器，在发生类加载时（1）或者重定义类时（2），会触发转换器的执行。重转换类时只有可中转换的Transformer会触发。 当存在多个转换器时，转换将由transform调用链组成。也就是说，一个transform调用返回的byte数组将成为下一个调用的输入。 转换将按以下顺序进行： 不可重转换转换器 不可重转换本地（native）转换器 可重转换转换器 可重转换本地（native）转换器 同样，在重转换时（3），不会调用不可重转换转换器，而是重用前一个转换的结果。对于所有其他情况，调用此方法。在每个这种调用组中，转换器将按照注册的顺序调用。 ClassFileTransformer接口只有一个方法： byte[] transform( ClassLoader loader, String className, Class\u003c?\u003e classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException; 其中classfileBuffer字段为加载的class内容的byte数组，返回结果未待初始化的class内容的byte数组。即可以通过该方法修改原class内容，返回修改后的内容来修改类的行为。如果不做任何转换，则要返回null。 如果转换器抛出异常（未捕获的异常），后续转换器仍然将被调用并加载，仍然将尝试重定义或重转换。因此，抛出异常与返回 null 的效果相同。 请参考https://docs.oracle.com/javase/7/docs/api/java/lang/instrument/ClassFileTransformer.html 2.1. redefineClasses 使用提供的类文件重新定义提供的一组类。 该方法用于替换类的定义，而不引用现有的类文件字节，就像从源头进行重新编译以进行修复和继续调试时一样。 在现有的类文件字节要转换的地方应该使用retransformClasses。 该方法对一组class进行操作，以便同时允许多个相互依赖的类的更改，如A类的重新定义可能需要重新定义B类。 如果重新定义的方法具有活动堆栈帧，则这些活动帧将继续运行原始方法的字节码。 重新定义的方法将做用于新的调用。 该方法不会导致任何初始化，除了在常规JVM语义下会发生。 换句话说，重新定义一个类并不会导致它的初始化器被运行。 静态变量的值将保持在调用之前。重新定义的类的实例不受影响。 重新定义可能会改变方法体，常量池和属性。 重定义不能添加，删除或重命名字段或方法，更改方法的签名或更改继承。 这些限制可能在将来的版本中解除。 类文件字节不会被检查，验证和安装，直到应用转换为止，如果结果字节错误，则此方法将抛出异常。如果此方法抛出异常，则不会重新定义任何类。 该方法的定义如下： void redefineClasses(ClassDefinition... definitions) throws ClassNotFoundException,UnmodifiableClassException public ClassDefinition(Class\u003c?\u003e theClass,byte[] theClassFile) { if (theClass == null || theClassFile == null) { throw new NullPointerException(); } mClass = theClass; mClassFile = theClassFile; } 如上所述，该方法需要指定需要替换的Class以及提供自定义类文件的字节码内容，请参考https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/Instrumentation.html#redefineClasses-java.lang.instrument.ClassDefinition…- 2.2. retransformClasses 重新转换提供的一组类。 该方法主要作用于已经加载过的class。可以用ClassFileTransformer对初始化过或者redifine过的class进行重新处理， 无论以前是否发生转换，此函数都将重新运行转换过程。 转换过程遵循以下步骤： 从初始类文件字节开始 对于将canRetransform设置为false的每个转换器，在上一个类加载或重定义期间由转换器返回的字节将被重新用作当前转换的输出，相当于当前转换器不生效 对于将canRetransform设置为true的每个转换器，将会在当前调用该转换器 转换后的类文件字节作为类的新定义安装 该方法对一组class进行操作，以便同时允许多个相互依赖的类的更改，如A类的重新定义可能需要","date":"2019-12-21","objectID":"/jacoco_03_instrument_api/:0:0","tags":["jacoco"],"title":"Instrument API介绍","uri":"/jacoco_03_instrument_api/"},{"categories":["notes"],"content":"这节介绍字节码增强技术","date":"2019-12-13","objectID":"/jacoco_02_class_instrument/","tags":["jacoco"],"title":"字节码增强","uri":"/jacoco_02_class_instrument/"},{"categories":["notes"],"content":" 上节介绍了Java字节码结构，这节介绍字节码增强技术。Java字节码增强指的是在Java字节码生成之后，对其进行修改，增强其功能，这种方式相当于对应用程序的二进制文件进行修改。 常见的字节码增强技术包括： Java自带的动态代理 ASM Javassist 1. 动态代理 在介绍动态代理前，先介绍代理模式。如下图，为代理模式的UML类图： 代理模式是一种设计模式，提供了对目标对象额外的访问方式，即通过代理对象访问目标对象，这样可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。代理类ProxyAction和被代理类CoreActionImpl都实现了同一个接口Action，ProxyAction还持有了CoreActionImpl，以调用被代理类的核心操作。代理模式实现可以分为静态代理和动态代理。 1.1. 静态代理 静态代理完全就是上面UML类图的直译，若代理类在程序运行前就已经存在，那么这种代理方式被成为 静态代理 ，这种情况下的代理类通常都是我们在Java代码中定义的。 通常情况下， 静态代理中的代理类和委托类会实现同一接口或是派生自相同的父类，再通过聚合来实现，让代理类持有一个委托类的引用即可。例子如下： public interface Action { void say(); } public class CoreActionImpl implements Action { @Override public void say() { System.out.println(\"hello world\"); } } public class ProxyAction implements Action { private Action action = new CoreActionImpl(); @Override public void say() { System.out.println(\"before core action\"); action.say(); System.out.println(\"after core action\"); } } 1.2. 动态代理 代理类在程序运行时创建的代理方式被称为动态代理。也就是说，这种情况下，代理类并不是在Java代码中定义的，而是在运行时动态生成的。动态代理利用了JDK API，动态代理对象不需要实现接口，但是要求目标对象必须实现接口，否则不能使用动态代理。例子如下： public class DynamicProxyAction implements InvocationHandler { private Object obj; public DynamicProxyAction(Object obj) { this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"before core action\"); Object res = method.invoke(obj,args); System.out.println(\"after core action\"); return res; } } 使用如下方法进行调用： DynamicProxyAction proxyAction = new DynamicProxyAction(new CoreActionImpl()); Action action = (Action) Proxy.newProxyInstance(DynamicProxyAction.class.getClassLoader(),new Class[]{Action.class},proxyAction); action.say() 自带的动态代理实现要求代理类实现InvocationHandler接口，并在方法invoke中完成具体方法的代理过程。 可以使用如下内容输出代理类内容 byte[] clazzData = ProxyGenerator.generateProxyClass(DynamicProxyAction.class.getCanonicalName() + \"$Proxy0\", new Class[]{Action.class}); OutputStream out = new FileOutputStream(DynamicProxyAction.class.getCanonicalName() + \"$Proxy0\" + \".class\"); out.write(clazzData); out.close(); 得到内容如下: public final class DynamicProxyAction$Proxy0 extends Proxy implements Action { private static Method m1; private static Method m2; private static Method m3; private static Method m0; public DynamicProxyAction$Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void say() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m3 = Class.forName(\"demo.Action\").getMethod(\"say\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } } 可以看到，代理类继承了java.lang.reflect.Proxy类并实现了代理接口。代理类内部除了有代理接口的方法外还额外增加了3个方法equals、toString和hashCode。所有方法的内部实现都委托给了InvocationHandler来执行，该InvocationHandler为传入的DynamicProxyAction。 1.3. Cglib java自带的动态代理一个很明显的要求就是被代理类有实现接口，Cglib代理则是为了解决这个问题而存在的。CGLIB（Code Generator Library）是一个强大的、高性能的代码生成库。其被广泛应用于AOP框架（Spring、dynaop）中，用以提供方法拦截操作，其底层使","date":"2019-12-13","objectID":"/jacoco_02_class_instrument/:0:0","tags":["jacoco"],"title":"字节码增强","uri":"/jacoco_02_class_instrument/"},{"categories":["notes"],"content":"介绍java字节码文件格式","date":"2019-12-08","objectID":"/jacoco_01_class_file_type/","tags":["jacoco"],"title":"Class文件格式","uri":"/jacoco_01_class_file_type/"},{"categories":["notes"],"content":" 我们知道Java是一门跨平台的语言，我们编写的Java代码会被编译成中间class文件以让Java虚拟机解析运行。而Java虚拟机规范仅仅描述了抽象的Java虚拟机，在实现具体的Java虚拟机时，仅指出了设计规范。Java虚拟机的实现必须体现规范中的内容，但仅在确有必要时才应该受制于这些规范。对于完整内容，可以查看原文档，以JDK7为例，可查看https://docs.oracle.com/javase/specs/jvms/se7/html/，或者《深入理解Java虚拟机 JVM高级特性与最佳实践》一书。完整的规范主要包含以下内容： 第2章：概览Java虚拟机整体架构 第3章：介绍如何将Java语言编写的程序转换为虚拟机指令集 第4章：定义class文件格式。它是一种与硬件和操作系统无关的二进制格式，用来表示编译后的类和接口 第5章：定义了Java虚拟机启动以及类和接口的加载、链接和初始化的过程 第6章：定义了Java虚拟机指令集 第7章：提供了一张以操作码值为索引的Java虚拟机操作码助记表 本文只是大概记录项目需要了解的基础概念，着重在介绍Class文件格式上，为该系列后续内容做铺垫。 Class文件是一组以8字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑排列在class文件中，中间没有任何分割符。每个 Class 文件都是由 8 字节为单位的字节流组成，所有的 16 位、32 位和 64 位长度的数据将被构造成 2 个、4 个和 8 个 8 字节单位来表示。 每一个Class文件对应于一个如下所示的ClassFile结构体: 涉及到的内容包括： magic：魔数，魔数的唯一作用是确定这个文件是否为一个能被虚拟机所接受的Class文件。魔数值固定为0xCAFEBABE，不会改变。 minor_version、major_version：副版本号和主版本号，minor_version和major_version的值分别表示Class文件的副、主版本。一个Java虚拟机实例只能支持特定范围内的主版本号（Mi至Mj）和0至特定范围内（0至m）的副版本号。 constant_pool_count：常量池计数器，constant_pool_count的值等于constant_pool表中的成员数加1。 constant_pool[]：常量池，constant_pool是一种表结构，它包含Class文件结构及其子结构中引用的所有字符串常量、类或接口名、字段名和其它常量。 access_flags：访问标志，access_flags是一种掩码标志，用于表示某个类或者接口的访问权限及基础属性。 this_class：类索引 super_class：父类索引 interfaces_count：接口计数器，interfaces_count的值表示当前类或接口的直接父接口数量 interfaces[]：接口表，在interfaces[]数组中，成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即interfaces[0]对应的是源代码中最左边的接口。 fields_count：字段计数器，fields_count的值表示当前Class文件fields[]数组的成员个数。 fields[]：字段表，fields[]数组描述当前类或接口声明的所有字段，但不包括从父类或父接口继承的部分。 methods_count：方法计数器，methods_count的值表示当前Class文件methods[]数组的成员个数。 methods[]：方法表，methods[]数组只描述当前类或接口中声明的方法，不包括从父类或父接口继承的方法。 attributes_count：属性计数器，attributes_count的值表示当前Class文件attributes表的成员个数。 attributes[]：属性表 可用jdk自带的javap命令对class文件进行反编译，以查看内容，如下代码： public class Ex { public void judgeAge(int age) { int step = 0; if (age \u003e 18) { step++; System.out.println(\"a litter old\"); } else { System.out.println(\"a litter cute\"); step++; } System.out.println(step); } public static void main(String[] args) { Ex ex = new Ex(); ex.judgeAge(16); } } 执行 javap -verbose -p Ex.class的结果为 Classfile Ex.class Last modified 2019-11-29; size 788 bytes MD5 checksum 8b5d8ebf38c4441fe7150c10da31ce1b Compiled from \"Ex.java\" public class Ex minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #10.#31 // java/lang/Object.\"\u003cinit\u003e\":()V #2 = Fieldref #32.#33 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #34 // a litter old #4 = Methodref #35.#36 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = String #37 // a litter cute #6 = Methodref #35.#38 // java/io/PrintStream.println:(I)V #7 = Class #39 // Ex #8 = Methodref #7.#31 // Ex.\"\u003cinit\u003e\":()V #9 = Methodref #7.#40 // Ex.judgeAge:(I)V #10 = Class #41 // java/lang/Object #11 = Utf8 \u003cinit\u003e #12 = Utf8 ()V #13 = Utf8 Code #14 = Utf8 LineNumberTable #15 = Utf8 LocalVariableTable #16 = Utf8 this #17 = Utf8 LEx; #18 = Utf8 judgeAge #19 = Utf8 (I)V #20 = Utf8 age #21 = Utf8 I #22 = Utf8 step #23 = Utf8 StackMapTable #24 = Utf8 main #25 = Utf8 ([Ljava/lang/String;)V #26 = Utf8 args #27 = Utf8 [Ljava/lang/String; #28 = Utf8 ex #29 = Utf8 SourceFile #30 = Utf8 Ex.java #31 = NameAndType #11:#12 // \"\u003cinit\u003e\":()V #32 = Class #42 // java/lang/System #33 = NameAndType #43:#44 // out:Ljava/io/PrintStream; #34 = Utf8 a litter old #35 = Class #45 // java/io/PrintStream #36 = NameAndType #46:#47 // println:(Ljava/lang/String;)V #37 = Utf8 a litter cute #38 = NameAndType #46:#19 // println:(I)V #39 = Utf8 Ex #40 = NameAndType #18:#19 // judgeAge:(I)V #41 = Utf8 java/lang/Object #42 = Utf8 java/lang/System #43 = Utf8 out #44 = Utf8 Ljava/io/PrintStream; #45 = Utf8 java/io/PrintStream #46 = Utf8 println #47 = Utf8 (Ljava/lang/String;)V { public Ex(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\u003cinit\u003e\":()V 4: return LineNumberTable: line 1: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LEx; public void judgeAge(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=3, args_","date":"2019-12-08","objectID":"/jacoco_01_class_file_type/:0:0","tags":["jacoco"],"title":"Class文件格式","uri":"/jacoco_01_class_file_type/"},{"categories":["srccode"],"content":"这节介绍Spring AOP","date":"2019-11-30","objectID":"/spring_06-aop/","tags":["spring"],"title":"Spring AOP","uri":"/spring_06-aop/"},{"categories":["srccode"],"content":" 这节介绍Spring AOP。关于Spring AOP的名字就不多做介绍了，网上有很多对AOP的解释。 1. 概念术语 1.1 切面（Aspect） 切面是一个关注点的模块化，这个关注点可能是横切多个对象； 1.2 连接点（Join Point） 连接点是指在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候； 1.3 通知（Advice） 指在切面的某个特定的连接点上执行的动作。Spring切面可以应用5种通知： 前置通知（Before）：在目标方法或者说连接点被调用前执行的通知； 后置通知（After）：指在某个连接点完成后执行的通知； 返回通知（After-returning）：指在某个连接点成功执行之后执行的通知； 异常通知（After-throwing）：指在方法抛出异常后执行的通知； 环绕通知（Around）：指包围一个连接点通知，在被通知的方法调用之前和之后执行自定义的方法。 1.5 切点（Pointcut） 指匹配连接点的断言。通知与一个切入点表达式关联，并在满足这个切入的连接点上运行，例如：当执行某个特定的名称的方法。 1.4 引入（Introduction） 引入也被称为内部类型声明，声明额外的方法或者某个类型的字段。 1.5 目标对象（Target Object） 目标对象是被一个或者多个切面所通知的对象。 1.6 AOP代理（AOP Proxy） AOP代理是指AOP框架创建的对象，用来实现切面（包括通知方法等功能） 1.7 织入（Wearving） 指把切面连接到其他应用出程序类型或者对象上，并创建一个被通知的对象。或者说形成代理对象的方法的过程。 2. 入口 AOP的一般配置如下： 之前BeanDefiniton解析那节提到，XML的解析在classpath下META-INF的spring.handlers里。查看spring-aop模块可以看到如下配置 http\\://www.springframework.org/schema/aop=org.springframework.aop.config.AopNamespaceHandler 该处理类如下 可以看到配置文件的处理交由 org.springframework.aop.config.ConfigBeanDefinitionParser 来处理，该类实现了BeanDefinitionParser接口，该接口的实现内容如下： 该方法主要完成两件事， 注册AspectJAwareAdvisorAutoProxyCreator 解析pointcut,advisor,aspect节点 下面重点看下这两点 3. AspectJAwareAdvisorAutoProxyCreator AspectJAwareAdvisorAutoProxyCreator的继承结构如下： 该类在父类AbstractAutoProxyCreator那实现了接口SmartInstantiationAwareBeanPostProcessor，AbstractAutoProxyCreator主要实现了 方法 postProcessBeforeInstantiation 和方法 postProcessAfterInitialization postProcessBeforeInstantiation会在bean实例化前执行，如果返回非null，则不会实例化该bean。 postProcessAfterInitialization会在bean实例化并初始化后执行，如果返回非null，则使用该实例，否则使用原Bean对象。即对目标对象的包装可以发生在实例化前，也可以发生在初始化后。 3.1. postProcessBeforeInstantiation 如上图示： 在beanName为空或者目标类不包含该beanName的前提下，如果该bean是通知执行对象(advisedBeans)则不进行代理；如果为基础类且需要跳过则不进行代理，同时会将其标记为非通知执行对象。 如果该beanName设置了TargetSource，则调用createProxy方法为该beanName创建代理对象，并将其进行标记，存于targetSourceBeans字段中。这里调用createProxy方法前会调用getAdvicesAndAdvisorsForBean方法获取该bean上设置的通知点。 3.2. postProcessAfterInitialization 该方法主要调用了wrapIfNecessary，先判断初始化后的对象是否需要进行代理，如果需要进行代理，也是同上面一样调用createProxy方法，并调前前会调用getAdvicesAndAdvisorsForBean方法获取该bean上设置的通知点，如下： 该过程会将已经初始化后的bean包装为SingletonTargetSource传入。 3.3. getAdvicesAndAdvisorsForBean 该方法的具体实现在其子类AbstractAdvisorAutoProxyCreator中，内容如下 主要调用了findEligibleAdvisors方法，如果该方法返回为空，则返回DO NOT PROXY. findEligibleAdvisors方法的处理流程为： 找出所有实现了Advisors接口的Bean（配置为Advisor的Bean将会被包装为DefaultBeanFactoryPointcutAdvisor注册到Spring中；配置为Advice的将会被包装为AspectJPointcutAdvisor注册到Spring中） 从所有Advisors中找出能够应用在beanClass上的bean，主要判断Advisors是否命中PointCut的规则 根据Order对Advisor进行排序 3.4. createProxy 如上为createProxy的主要内容，主要是使用相关的Advisor列表和TargetSource生成ProxyFactory对象，委托为ProxyFactory进行代理的包装。主要调用ProxyFacotry的getProxy方法， 该过程会在后面进行讲解. 4. 节点解析 回到ConfigBeanDefinitionParser的parse过程，在注册完AspectJAwareAdvisorAutoProxyCreator后便是XML配置项的解析，主要包括：pointcut,advisor和aspect节点。 pointcut：为每个pointcut配置注册一个AspectJExpressionPointcut，范围为prototype的Bean，会设置expression属性 advisor：为每个advisor配置注册一个DefaultBeanFactoryPointcutAdvisor，需要关联一个advice，通过advice-ref指定对应的Bean；以及关联一个pointcut aspect：包含一个或者多个advice节点已经pointcut节点，pointcut的解析同之前的类似，主要是advice节点。advice类别分为 before：执行前置通知 after：执行后置通知 after-returning：执行返回通知 after-throwing：执行异常通知 around：执行回环通知 对于每个advice都会包装为一个AspectJPointcutAdvisor 5. ProxyFacotry ProxyFactory的结构如下： ProxyFactory主要对ProxyCreatorSupport进行了封装，用于设置TargetSource和各拦截器接口。 ProxyCreatorSupport继承自AdvisedSupport，AdvisedSupport本身持有创建代理的各参数。同时引用了AopProxyFactory，将代理的创建动作委托给了AopProxyFactory。调用ProxyFactory的createAopProxy方法实际调用了AopProxyFactory的createAopProxy方法，该方法需要传入一个AdvisedSupport对象，即ProxyFactory本身。 DefaultAopProxyFactory决定使用哪种方式来创建代理，可选方式为Jdk动态代理或者Cglib，内容如下： 6. aspectj-autoproxy aspectj-autoproxy提供自动完成创建代理织入切面的功能，能够通过配置注解Aspectj织入切面。aspectj-autoproxy 有一个proxy-target-class属性，默认为false，表示使用jdk动态代理织入增强，当配为true时，表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。根据上面的介绍，该动能由AspectJAutoProxyBeanDefinitionParser提供，主要向Spring注册了AnnotationAwareAspectJAutoProxyCreator类。 AnnotationAwareAspectJAutoProxyCreator继承自AspectJAwareAdvisorAutoProxyCreator，只扩展了findCandidateAdvisors方法，将Advisor的搜索范围扩大到了注解上，使之可以用注解进行配置，具体委托给","date":"2019-11-30","objectID":"/spring_06-aop/:0:0","tags":["spring"],"title":"Spring AOP","uri":"/spring_06-aop/"},{"categories":["notes"],"content":"扩展阿里p3c增加对fastjson检查是否打开setAutoType特性的检查","date":"2019-10-25","objectID":"/notes_002_p3c/","tags":["work"],"title":"扩展阿里p3c实现自定义代码规范检查","uri":"/notes_002_p3c/"},{"categories":["notes"],"content":" 前段时间fastjson报出了漏洞，只要打开setAutoType特性就会存在风险，自己测试环境的一个项目被揪出来了-_-!。虽然改动很小，但就是觉得憋屈。fastjson还是挺好的，想着禁用的话太可惜，用的话又要注意安全，就想着找款工具提示下在用fastjson的时候不要打开这个特性。刚好阿里开源了p3c（https://github.com/alibaba/p3c），一款代码规范的检查工具，有对应的ide插件，能在编码过程中对设置的规则进行提示，便打算对它进行拓展，增加对fastjson检查是否打开setAutoType特性的检查。 p3c主要包括3部分： PMD实现(p3c-pmd)：使用PMDhttps://pmd.github.io/来实现代码规范检查 Intellij IDEA插件 Eclipse插件 《阿里巴巴Java开发手册》中的大部分规则都是在p3c-pmd模块中实现的，该部分也是这节研究的主要部分。 1. PMD p3c使用了PMD。PMD是一款静态代码扫描工具，该工具可以做到检查Java代码中是否含有未使用的变量、是否含有空的抓取块、是否含有不必要的对象等。PMD使用JavaCC生成解析器来解析源代码并生成AST(抽象语法树)，通过对AST的检查可以直接从源代码文本层面来对代码进行检查，在PMD内部称为规则。即是否符合规则指的是，穷举源码各种可能的写法，然后在AST上检查是否出现。而规则的实现，重点便在对AST的处理上。 1.1. AST 关于AST的介绍网上有很多，可以直接搜索，这里重要提两点： AST是源代码的抽象语法结构的树状表示 抽象语法树并不依赖于原语言的语法，也就是说同语法分析阶段所采用的上下文无关 PMD使用JavaCC来生成AST。关于JavaCC也可以在网上查看相关资料，这里不多介绍，只要知道JavaCC是一个词法分析生成器和语法分析生成器便行。 1.2. 自定义规则 PMD官方文档介绍了自定义规则的实现步骤，过程比较清晰，这里不赘述，只介绍下本文需要设计的步骤。 1.2.1. 定义规则集 PMD的规则需要配置在XML文件中 新建如下的空文件表示规则集 \u003c?xml version=\"1.0\"?\u003e \u003cruleset name=\"Custom Rules\" xmlns=\"http://pmd.sourceforge.net/ruleset/2.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://pmd.sourceforge.net/ruleset/2.0.0 https://pmd.sourceforge.io/ruleset_2_0_0.xsd\"\u003e \u003cdescription\u003e My custom rules \u003c/description\u003e \u003c!-- Your rules will come here --\u003e \u003c/ruleset\u003e 在上面的ruleset 标签中引用自定义规则 \u003crule ref=\"pathToYourOwnClass\" /\u003e 配置规则集 1.2.2. 配置规则 可以在 rule 标签中对某一规则进行配置 配置提示消息和告警级别 \u003crule ref=\"pathToYourOwnClass\" message=\"message to show\" \u003e \u003cpriority\u003e5\u003c/priority\u003e \u003c/rule\u003e 告警优先级分为1-5个level，1最高，5最低 配置运行参数 可以通过 properties 和 propertie对类属性赋值 1.2.3. 编写规则 规则的编写比较简单，PMD已经给我们做好了配套的开发框架和工具，只要确定后规则出现的情况，按照固定的模式去编写即可。 确定实现方式 可以使用纯Java方式实现，也可以使用XPath方式实现。 对于纯Java方式，PMD框架本身实现了对AST数的遍历，用户只要在遍历各个节点的时候，对自定义规则的各种情况进行分析判断即可，过程类似与DOM文件的SAX解析，以流和事件的方式来解析AST内容。 对于XPath方式，则是将AST作为一个XML数，以XPath的方式来遍历解析内容。 根据测试代码确定可能出现的情况 PMD自带了一个designer，可以用来生成对应代码的AST内容。对于本文需要达到的效果，涉及到如下代码： import com.alibaba.fastjson.parser.ParserConfig; public class NegativeExample { public static void main(String[] args) { ParserConfig.getGlobalInstance().setAutoTypeSupport(true); } } 在designer中可以得到如下的AST内容 具体内容这里就不贴出来了，可以下载desigin然后贴上上面的代码就会有。 对于本文的需求，需要确定在有import ParserConfig 类的时候，调用了 setAutoTypeSupport 方法且参数为 true。当然这个条件是不够严谨的，还需要判断是否调用了 ParserConfig，也要考虑有通过import导入直接写全限定名的。但考虑到一般的写法，以及ide的格式化处理，这样处理已经可以满足大部分场景了。 编写规则实现类 确定了规则的判断条件，就可以着手写代码了。 对于Java方式，可以直接继承 net.sourceforge.pmd.lang.java.rule.AbstractJavaRule 类，然后重写各种节点的visit方法即可。 例如如下，用于判断是否有import ParserConfig 类 private final String PARSER_CONFIG_IMPORT_NAME = \"com.alibaba.fastjson.parser.ParserConfig\"; private boolean hasImport = false; @Override public Object visit(ASTImportDeclaration node, Object data) { if (PARSER_CONFIG_IMPORT_NAME.equals(node.getImportedName())) { hasImport = true; } return super.visit(node, data); } 对于XPath方式，可以通过继承 net.sourceforge.pmd.lang.rule.XPathRule 类，重写 setXPath 方法设定对应的XPath即可。上面提到过，可以通过 property 配置对类的属性进行赋值，因而，对于XPat方式，可以在xml配置中进行如下设置来启用XPath。 \u003crule name=\"My Rule\" language=\"java\" message=\"violation message\" class=\"net.sourceforge.pmd.lang.rule.XPathRule\"\u003e \u003cdescription\u003e Rule Description 3 \u003c![CDATA[ --- here comes your XPath expression ]]\u003e ``` 1.2.4. 测试规则 PMD推荐对于每个规则，至少要有一个正向和逆向的测试用例，来验证规则出现和不出现的情况。对于规则的测试，PMD也提供了一套框架，只要按照约定好的方式添加xml测试文件即可。 PMD约定了几个规则，用来加载测试案例 测试类要继承 net.sourceforge.pmd.testframework.PmdRuleTst类，该整合了Junt，可以在里面增加需要的测试方法。 对于在 src/test/resource 和测试类对应的路径下增加一个xml目录，在增加同第一步同名的xml文件，该文件用于书写测试集。 例如官网给出的例子 规则实现类路径如下： net.sourceforge.pmd.lang.java.rule.bestpractices.AbstractClassWithoutAbstractMethodTest ``` 测试案例集如下： ``` src/test/resources/net/sourceforge/pmd/lang/java/rule/bestpractices/xml/AbstractClassWithoutAbstractMethod.xml ``` xml的规则则可以参考官网介绍，这里不再赘述。 2. p3c-pmd 代码规范实现的主要模块，使用pmd来实现。p3c-pmd模块在代码组织上很工整，可以按照相同的模式增加自定义的规则/规则集。 对于本文需求，打算在该模块的基础上增加一个extend模块，用于实现自定义规则集。如下，为对应的源码路径好规则集路径 本文采用纯Java方式实现规则，按照1.2.3.节的描述，可以得到如下的实现类 public class AvoidFastJsonAutoTypeSupportRule extends AbstractAliRule { private final String PARSER_CONFIG_IMPORT_NAME = \"com.alibaba.fastjson.parser.ParserConfig\"; private final String SET_AUTO","date":"2019-10-25","objectID":"/notes_002_p3c/:0:0","tags":["work"],"title":"扩展阿里p3c实现自定义代码规范检查","uri":"/notes_002_p3c/"},{"categories":["srccode"],"content":"讲解destroyBeans方法方法","date":"2019-10-13","objectID":"/spring_05-destorybean/","tags":["spring"],"title":"Spring DestroySingleton流程","uri":"/spring_05-destorybean/"},{"categories":["srccode"],"content":" 第一节介绍Spring启动(链接)时，介绍AbstractApplicationContext的过销毁过程，主要是调用了内部的destroyBeans方法，这节便来介绍bean的销毁过程。 一.销毁流程 destroyBeans方法内部委托给了DefaultSingletonBeanRegistry的destroySingletons方法。destroySingletons方法如下，比较清晰: 前面介绍过，DefaultSingletonBeanRegistry用一个Map缓存着所有的单例实例，对于对象的销毁，只要简单的将其从Map中移除就行。主要处理的是依赖关系下的bean销毁顺序以及回调接口的处理。上面先对disposableBeans中所涉及到的bean逐个进行销毁，然后再清理所有的依赖关系和缓存的单例实例。 上一节提到，disposableBeans中存放的是存在销毁时需要进行方法回调的DisposableBeanAdapter对象，key为对应的bean name，会在bean初始化后进行判断并且存入。这里会优先处理这些bean的销毁，下面重点介绍下destroySingleton方法。 二.destroySingleton 如上描述了该方法的大致过程，分别为 将DefaultSingletonBeanRegistry中缓存的各种单例实例清除掉 执行disposableBeans.remove方法，移除该beanName，这里会返回一个DisposableBean对象 删除dependentBeanMap中beanName的内容，也是执行remove的方法，会返回依赖于beanName的其他bean name列表，再依次调用destorySingleton销毁这些bean 对当前的DisposableBean执行destory 删除containedBeanMap中beanName的内容，执行的remove方法，hi返回beanName依赖的其他bean name列表，再依次调用destorySingleton销毁这些bean 从而具体的回调发生在第4步，开头提到，bean在实例化后会以DisposableBeanAdapter存放进disposableBeans中，从而该类实现了具体的回调过程。 三.DisposableBeanAdapter DisposableBeanAdapter的结构如下，其实现了DisposableBean接口，因而可以如上面说的，在destroySingleton方法进行回调。它在构造方法中对几个重要的属性进行了赋值，用于存储销毁动作相关的信息，包括： Bean：待销毁bean对象 beanName：待销毁bean的beanName destroyMethodName：待销毁要调用的方法，该方法来源于destory-method配置项，如果为(inferred)，则会将回调方法赋值为close或者shutdown destoryMethod：destoryMethodName对应的Method对象 beanPostProcessors：需要处理该bean的DestructionAwareBeanPostProcessor回调列表。在实例化DisposableBeanAdapter对象时，会过滤系统中的BeanPostProcessor列表，找出实现DestructionAwareBeanPostProcessor接口，且requiresDestruction方法返回true的实例，用于后续进行回调。（InitDestroyAnnotationBeanPostProcessor类实现了该方法，用以回调@PreDestory注解的方法，CommonAnnotationBeanPostProcessor继承自该类，设置了destroyAnnotationType为PreDestroy.class） 当按照第（二）部分第4步执行时，该类会按照如下顺序执行销毁动作： 如果beanPostProcessors列表不为空，则回调DestructionAwareBeanPostProcessor的postProcessBeforeDestruction方法，即执行@PreDestory注解方法 如果实现了DisposableBean，则回调DisposableBean的destroy方法，即执行DisposableBean接口方法 如果配置了destroy-method，则执行配置的方法，即执行destory-method配置方法 ","date":"2019-10-13","objectID":"/spring_05-destorybean/:0:0","tags":["spring"],"title":"Spring DestroySingleton流程","uri":"/spring_05-destorybean/"},{"categories":["srccode"],"content":"讲解BAbstractBeanFactory的getBean方法","date":"2019-10-06","objectID":"/spring_04_getbean/","tags":["spring"],"title":"Spring GetBean的流程","uri":"/spring_04_getbean/"},{"categories":["srccode"],"content":" 第一节讲解Spring启动（链接）的时候说到，Spring内部先解析了所有的配置，加载所有的Bean定义后，再根据需要对Bean进行实例化和初始化。除开Spring自己主动新建的对象，第一次根据Bean定义加载对象的动作出现在AbstractApplicationContext的invokeBeanFactoryPostProcessors方法，该方法会在Spring容器中找出实现了BeanFactoryPostProcessor接口的bean列表并执行。根据之前介绍的内容，内部主要调用了AbstractBeanFactory的getBean方法，这节将对该方法进行讲解。 一、getBean 在这之前，先介绍BeanFactory的层次结构，如下： 涉及到的接口和实现类为： AliasRegistry：别名管理接口，定义了别名管理的功能 SimpleAliasRegistry：AliasRegistry的默认实现，内部用一个 ConcurrentHashMap：管理别名 SingletonBeanRegistry：单例实例管理接口，定义了单例管理的功能 DefaultSingletonBeanRegistry：单例管理实现类，内部用Map维护着被实例化后的所有单例、单例工厂等相关信息。Map的键为bean的唯一标识，Spring内部成为raw name，一般等同于Bean定义中的id或者name或者别名等，具体规则可以从上节BeanDefinition的加载查看（链接），值为相应的对象实例。这边需要指出的一点时，对于bean定义中具有别名意义的字段，如一定情况下的name以及alias字段，只存在于SimpleAliasRegistry维护的内部Map中，通过递归查询的方式可以从一个给定的别名查找到指定的id。 如下，DefaultSingletonBeanRegistry维护的Map中存在key为testBean，value为TestBean的对象，SimpleAliasRegistry维护的Map中存在Key为testBeanAlias1，value为testBean的记录。当通过testBeanAlias1查找bean时，会先通过AliasRegistry查找到testBean，再从通过BeanRegistry查找到对应的Bean实例。 FactoryBeanRegistrySupport：增加缓存FactoryBean实例功能，DefaultSingleBeanRegistry在生成单例后便不再持有对应的FactoryBean BeanFactory：定义了Bean容器的基本查询接口，同时设定了以\u0026前缀来区别工厂Bean，即如果beanName前面有\u0026则返回对应Bean的工厂Bean对象而不是该Bean对象。 HierarchicalBeanFactory：在BeanFactory接口上增加了父子层级关系，以实现双亲委托。 ConfigurableBeanFactory：按照规矩，增加了修改功能的接口，同时增加了Scope特性，默认分为single单例和prototype多例。 AbstractBeanFactory：BeanFacoty的基本实现。 AbstractBeanFactory的getBean方法内部调用了doGetBean，该方法提供了根据beanName获取实例的具体实现，代码如下(删除了相关的注释和空格)： protected \u003cT\u003e T doGetBean( final String name, final Class\u003cT\u003e requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException { /*(1)*/ final String beanName = transformedBeanName(name); Object bean; /*(2)*/ Object sharedInstance = getSingleton(beanName); /*(3)*/ if (sharedInstance != null \u0026\u0026 args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); } else { logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); } } bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } /*(4)*/ else { /*(5)*/ if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } /*(6)*/ BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null \u0026\u0026 !containsBeanDefinition(beanName)) { String nameToLookup = originalBeanName(name); if (args != null) { return (T) parentBeanFactory.getBean(nameToLookup, args); } else { return parentBeanFactory.getBean(nameToLookup, requiredType); } } /*(7)*/ if (!typeCheckOnly) { markBeanAsCreated(beanName); } try { /*(8)*/ final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); /*(9)*/ String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } registerDependentBean(dep, beanName); try { getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } /*(10)*/ if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, new ObjectFactory\u003cObject\u003e() { @Override public Object getObject() throws BeansException { try { return createBean(beanName, mbd, args); } catch (BeansException ex) { destroySingleton(beanName); throw ex; } } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } /*(11)*/ else if (mbd.isPrototype()) { Object prototypeInstance = null; try { beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } bean = getObjectForBeanInstance(prototypeInstance, name, ","date":"2019-10-06","objectID":"/spring_04_getbean/:0:0","tags":["spring"],"title":"Spring GetBean的流程","uri":"/spring_04_getbean/"},{"categories":["srccode"],"content":"讲解Bean定义的加载过程","date":"2019-10-04","objectID":"/spring_03_beanload/","tags":["spring"],"title":"Spring BeanDefinition的加载","uri":"/spring_03_beanload/"},{"categories":["srccode"],"content":" 前面提到AbstractRefreshableApplicationContext在刷新BeanFactory时，会调用loadBeanDefinitions方法以加载系统中Bean的定义，下面将讲解Bean定义的加载过程。 一．XML定义 XML配置的加载由AbstractXmlApplicationContext实现，方法实现如下： 主要是实例化了一个XmlBeanDefinitionReader对象，对其设置了Environment对象（具体过程可以上一篇）等后，调用XmlBeanDefinitionReader进行解析。直接跟踪进去，得到如下内容： 其中参数inputSource为XML配置文件，Resource则该配置文件的描述，主要描述了该配置文件在classpath中的位置和可用于加载该配置文件的加载器。doLoadDocument方法比较简单，主要是加载指定的配置文件，返回一个JDK内置的XML解析Document对象，以便于解析XML DOM节点。 重点看下registerBeanDefinitions方法，如下： 该方法最终委托给了BeanDefinitonDocumentReader来完成Bean的解析。在这之前，初始化了一系列相关对象。包括： 使用DefaultBeanDefinitionDocumentReader作为BeanDefinitionDocumentReader接口的实现 创建了一个XmlReaderContext用于保存解析过程中使用到的各个相关对象，如资源描述对象Resource、ReaderEventListener事件监听器、XmlBeanDefinitionReader以及NamespaceHandlerResolver命名空间解析器。其中划重点的是DefaultNamespaceHandlerResolver，该类完成了自定义XML格式的解析，后面会有讲解。 初始相关对象后便将解析过程委托给了DefaultBeanDefinitionDocumentReader来进行处理，该类的重点为parseBeanDefinitions方法，在调用该方法前，先初始化了一个BeanDefinitionParserDelegate对象，如下： 并将该delegate对象传入了parseBeanDefinitions方法。BeanDefinitionParserDelegate主要提供了命名空间为http://www.springframework.org/schema/beans（下面简写为beans空间）的XML文件解析过程。该命名空间定义了4个主要的XML标签，分别为beans、bean、import和alias以及这些标签对应的属性，如下为该命名空间的示例，定义了一个基础的Bean。 需要注意的是，上面在初始化BeanDefinitionParserDelegate后会先解析XML上\u003cbeans\u003e标签上的默认属性，包括：default-lazy-init、default-merge、default-autowire、default-dependency-check、default-autowire-candidates、default-init-method和default-destroy-method这些全局属性。 下面看下parseBeanBefinitoins方法： 该方法会对当前节点所属命名空间进行判断，分为默认命名空间和自定义命名空间，其中默认命名空间指的是上面提到的beans空间。对于默认命名空间，会逐一解析每个DOM子节点，判断子节点的命名空间，最终委托给两个方法：处理默认命名空间的parseDefaultElement方法和处理自定义命名空间的parseClustomElement方法。 parseDefautlElement方法如上， 对beans空间定义的各个标签分别进行了处理： 解析import标签时，会读取resource属性指定的配置文件，加载后再解析该文件中的bean定义。 解析alias标签时，读取标签的name和alias属性，添加到BeanRegistry缓存中。 解析bean标签时，直接委托给BeanDefinitionParserDelegate来处理，过程为： 获取id属性值作为beanName 获取name属性值作为aliases，该属性值可以配置多个，以 , 或者 ; 符进行分割，将作为该bean的别名使用；若id指为空，且name不为空，则使用第一个name值作为id值 检查beanName和aliases的唯一性 解析bean其他配置，生成GenericBeanDefinition对象 若beanName为空，则为其分配一个 对于步骤3.d，处理过程为： 获取class属性值 获取parent属性值 初始化GenericBeanDefinition实例 解析bean节点的属性，设置到BeanDefinition中，包括：scope、abstract、lazy-init、autowired、dependency-check、autowire-candidate、primary、init-method、destroy-method、factory-method、factory-bean 解析description子节点，获取值设置bean的描述内容 解析meta子节点列表，获取key、value值设置附加元数据信息 解析lookup-method子节点列表，获取name、bean值设置方法注入信息 解析replaced-method子节点列表，获取值设置需要动态代理的方法信息 解析constructor-arg子节点列表，获取值设置构造参数信息 解析property子节点列表，获取值设置属性信息 解析qualifier子节点列表，获取值进行设置 上面解析完bean的配置后，会再处理子节点中其他命名空间的配置，使用NamespaceHandler的decorate方法，用以修改Bean定义内容，这部分将使用下面的内容，放在后面一起讲。 解析beans标签时，会进行递归处理 如上，默认命名空间主要用于解析bean的定义，经过上面的处理，bean定义的解析就已经完成，会将实例对象注册到上下文中进行保存 下面介绍parseClustomElement方法，顾名思义，该方法主要用来处理自定义命名空间的XML标签的，可以当做是spring XML配置处理的一种扩展手段，如下，为该方法的内容： 主要委托给了NamespaceHandlerResolver，通过查找到对应节点对应命名空间的Handler，调用该Handler的parse方法进行处理。 前面说过，NamespaceHandlerResolver使用了DefaultNamespaceHandlerResolver作为实现，跟踪resolve方法进去如下： 过程为： 获取已有的Handler处理列表，返回结果为一个Map，Key为XML命名空间，值可能为代表对应Handler类型的Spring对象或者已经实例化后的Handler对象，取决于之前是否已经调用过 若指为Handler对象，则直接返回 若为String对象，表明未初始化过，则初始化该类，并执行init初始化方法，然后将其重新返回Map中 对于第（1）步中Handler处理列表的获取，Spring会扫描classpath中所有位于META-INF中的spring.handlers配置文件，将所有内容读取到一个Map中并返回。 如上，为spring-context模块提供的spring.handlers文件，提供了该模块自定义命名空间标签的支持。如下为自定义命名空间的例子： 主要引入了context空间的spring-configured标签和annotation-config标签。 至此，介绍了XML配置下的bean解析。 二、注解配置 下面介绍Spring以注解的方式进行bean加载的过程，如下，为开启注解加载所需要的配置： 根据前面的内容，component-scan为http://www.springframework.org/schema/context命名空间中的标签，处理对象在spring-context模块的spring.handlers文件中定义，对应的是类org.springframework.context.config.ContextNamespaceHandler，如下： 查看该类，可以知道，component-scan由ComponentScanBeanDefinitionParser处理，如下： 主要过程为： 获取base-package属性内容赋值给basePackage 替换basePackage中的占位符内容 根据 , ; \\t \\n 分割符分割basePackage，得到多个包路径 解析component-scan配置内容，返回ClassPathBeanDefinitionScanner对象 解析设置use-default-filters参数 解析设置resource-pattern参数 解析设置name-generator参数 解析设置scope-resolver、scoped-proxy等参数 解析设置include-filter、exclude-filter等参数, ClassPathBeanDefinitionScanner对象再初始化时默认增加了org.springframework.stereotype. Com","date":"2019-10-04","objectID":"/spring_03_beanload/:0:0","tags":["spring"],"title":"Spring BeanDefinition的加载","uri":"/spring_03_beanload/"},{"categories":["srccode"],"content":"这节介绍environment，默认环境变量的加载以及初始化内容","date":"2019-10-03","objectID":"/spring_02_env/","tags":["spring"],"title":"Spring Environment的加载","uri":"/spring_02_env/"},{"categories":["srccode"],"content":" 这节介绍environment，默认环境变量的加载以及初始化内容。 之前在介绍spring启动过程讲到，第一步进行环境准备时就会初始化一个StandardEnvironment。下图为Environment类图的接口，可以分为4块内容： ConversionService（蓝）：类型转换服务 PropertySource（绿）:键值对数据源 PropertyResolver（红）:键值对服务，包括类型转换 Environment（紫）:环境配置数据服务 1.ConversionService 提供了类型转换服务，能将源目标转换为目标类型，同时提供了管理功能，内部维护了各类型转换映射关系。其实从ConversionService和ConverterRegistry接口就能看出该模块的功能，如下： ConversionService接口为主要的对外功能接口，提供查询的能力。 ConverterRegistry接口为主要的管理接口，提供添加和删除的能力。而ConfigurableConversionService继承自上面二者，则提供了Converter的CRUD功能。结构上也延续了Spring固有的风格，将执行接口作为主要功能对外提供单一的接口，再通过继承的方式，以Configurable开头的子接口，扩展出管理功能，使得责任分离更加立体。 接下来是GenericConversionService类，该类提供了接口全部实现，下图展示了其主要实现: GenericConversionService结构上可以说是一个小型的管理系统，内部维护了一个Converters对象，用于“底层”管理所有的GenericConverter。同时还维护了一个ConcurrentReferenceHashMap用于缓存常用的GenericConverter。 Converters在存储GenericConverter时还进行了分类，如果GenericConverter有指定能够解析的类别（ConvertiablePair：包括SourceType和TargetType）时，则使用一个LinkedHashMap按Key Value进行存储，在存储时会遍历可解析的类别，将该GenericConverter追加到对应的Value列表末尾，因而可以看到该Map的Value是一个LinkedList。对应没有指定能解析的类别的GenericConverter，则直接放到LinkedHashSet维护的集合中。 Converters在查询时会遍历源类型和目标类型的组合结果，以查找匹配的目标GenericConverter对象。如下： 对于getRegisteredConverter方法，会先使用Key从LinkedHashMap中查找是否有匹配的Converter,再遍历相应的Value,查找到能处理的转换器。若Map中无法查到，则遍历LinkedHashSet，以查到到能处理的转换器。 由上知道，Converters在查找时存在多次遍历列表的过程，在频率过多时效率会比较低下，因而GenericConversionService内部维护了一个ConcurrentReferenceHashMap提供缓存的功能，该Map提供了同ConcurrentHashMap相同的功能，但是能够存储对应的软引用，从而能在内存不足时自动进行内存回收。在查到转换器时，会先试着从缓存中查找，如果获取不到，则会转而从Converters中查找，当从Converters中查找到后便会put到ConcurrentReferenceHashMap缓存中。 DefaultConversionService是一个单例，继承自GenericConversionService，在初始化后自动添加了默认的转换器，包括Scalar相关的、集合相关的等转换器。 ####2.PropertySource PropertySource代表了一个包含键值对的数据源。从类定义上看，有一个表示数据源名字的name字段，还有一个表示具体数据源泛型T的source字段。而数据源的设置则是通过构造方法传入的，同时方法提供了通过键名获取键值的抽象方法getProperty。此外还有其他抽象方法，如containsProperty等。 EnumerablePropertySource继承自PropertySource，增加了getPropertyNames方法，要求子类返回内存持有的键名列表。同时实现了containsProperty方法，通过判断所给的键名是否存在上述返回的键名列表中从而判断是否包含该键名。 MapPropertySource继承自EnumerablePropertySource，顾名思义，内部通过Map维护各键值对内容。类似的还有PropertiesPropertySource，内部通过Properties维护各键值对内容。 SystemEnvironmentPropertySource是MapPropertySource的装饰器，继承自MapPropertySource，为其添加了键名转换功能，以应对环境变量、shell参数的环境。在通过键名获取键值时，会先根据原键名进行查找，查找不到则通过对键进行转换再尝试查找，具体查找过程为： 通过name查找 将name中的 . 转换为 _ 查找 将name中的 – 转换为 _ 查找 将name中的 . 和 _ 转换为 – 查找 将name转换为大写，再进行（1） - （4）的过程 PropertySources的实现如下，扩展了PropertySource接口，将单个数据源的能力扩展到了多个。MutablePropertySources作为PropertySources的实现，内部维护了一个List对象，用以存储给个数据源，并将自身的行为封装为List。 3.PropertyResolver PropertyResolver定义了一系列接口，以提供了对外根据键名获取相应值的功能，同时提供了类型转换和占位符替换的功能，是ConversionService和PropertySource的结合。ConfigurablePropertyResolver接口继承自PropertyResolver接口，老规则，扩展了设置的功能，主要是设置类型转换器和占位符的相关属性。 AbstractPropertyResolver提供了除PropertySource功能外的其余实现。使用DefaultConversionService作为默认的类型转换实现，使用 ${ 和 } 作为占位符的前后缀，使用:作为默认值分割符，同时引入PropertyPlaceholderHelper用于占位符的解析和替换。而getProperty的实现则留到了了子类PropertySourcesPropertyResolver中，其引入了PropertySources用以维护多个键值对数据源。获取指定属性值过程如下： 通过遍历数据源的方式，查到对应的值后，会进行占位符的替换，替换完占位符后会进行类型的转换。类型转换直接用的DefaultConversionService，这个上面已经介绍过了，下面介绍占位符替换。 占位符替换的功能是在PropertyResolver接口中定义的，分为严格和不严格模式，如下： resolvePlaceholders为不严格模式，如果没法替换占位符，则直接忽略，resolveRequiredPlaceholders为严格模式，如果占位符没法替换则会抛出异常。如上面说的，AbstractPropertyResolver实现时都委托给PropertyPlaceholderHelper的replacePlaceholders方法。 如上，该方法要求传入一个源字符串，同时提供一个PlaceholderResolver数据源，一遍解析出占位符内容后能够从数据源中获取对应的值。为了保持类功能的单一职责，从而增加了一个内部接口PlaceholderResolver。上面提到，在这个模块中的键值对数据源都是由PropertySourcesPropertyResolver维护的，事实上上面方法截图的实现中，getPropertyAsRawString方法也确实是由PropertySourcesPropertyResolver提供实现的，下面看下占位符的解析。 占位符的解析过程如上流程，主要过程为： 根据${前缀得到startIndex 查找跟${前缀配对的}后缀，如${xxx${yy}z}，得到第二个}后缀的下标endIndex 截取${和}中间的内容得到placeholder 由于placeholder的内容可能也可能包含占位符，因而要递归处理placeholder，既占位符可以嵌套，内层的结果可以当做外层的Key使用 placeholder解析完后，将其作为Key从键值对源中获取对应的值propVal 如果propVal值为空，则判断是否存在:分割符，如果有分割符，则进行分割，并使用前端内容作为Key再次查找值。若该次查找结果不为空，则使用该次结果为propVal的值，否则使用第二段内容作为默认值 若第（5）/（6）步中propVal结果不为空，则判断从键值对源中获取的值是否也有占位符，若有占位符，则再次进行解析，若没有，则将结果替换回原字段中，更新startIndex，继续下次解析。 若第（5）/（6）步中propVal结果不空，则会根据设置的解析模式来判断下一步行为，如果未不严格模式，则跳过该次内容，更新star","date":"2019-10-03","objectID":"/spring_02_env/:0:0","tags":["spring"],"title":"Spring Environment的加载","uri":"/spring_02_env/"},{"categories":["srccode"],"content":"Spring用了挺久的了，但是没系统做过总结，刚好前段时间在做一个Spring封装的项目，趁机回顾了下，便基于Spring framework 4.3.22做了源码分析","date":"2019-10-02","objectID":"/spring_01_start/","tags":["spring"],"title":"Spring启动流程","uri":"/spring_01_start/"},{"categories":["srccode"],"content":" Spring用了挺久的了，但是没系统做过总结，刚好前段时间在做一个Spring封装的项目，趁机回顾了下，便基于Spring framework 4.3.22做了源码分析。 刚开始接触Spring时的入门例子大致如下： 设置配置文件路径，初始化ApplicationContext然后获取Bean，处理完后关闭context即可。这一节先来了解Spring的启动过程。 一. 启动 跟踪ClassPathXmlApplicationContext的构造方法可以看到如下内容： 里面设置了配置文件的路径，并且调用了父类AbstractApplicationContext的refresh方法，该方法完成了Spring环境的初始化。如下，为refresh方法的主要过程（为方便排版，去除了原来的注释和空格）： 下面将介绍各个方法步骤的内容，但不进行过多的深入，后面会单独对每个深入的细节进行详细的介绍，这节先介绍大概过程。 1.1. try 1.prepareRefresh PrepareRefresh的内容如上，该方法主要进行环境的准备，包括Context的启动时间，活动状态，然后会设置context中的配置数据源，使用默认的StandardEnvironment对象，该对象添加了System.env()属性和System.properties()属性。initPropertySources方法用于初始化context 中 environment的属性源。在AbstractApplicationContext中为空实现。其他子类的实现如下： 对于GenericWebApplicationContext和AbstractRefreshableWebApplicationContext的实现大致一致，都是: 通过在getEnvironment方法中，重写createEnvironment方法，将默认的StandardEnvironment替换为StandardServletEnvironment， Environment的关系图为： 因而会执行该类的initPropertySources方法，为context添加ServletContext和ServletConfig对应的配置属性源。具体的Environment中配置属性源的加载会在后面单独进行介绍。 2.obtainFreshBeanFactory 该方法的实现如下，通过refreshBeanFacotry重置AbstractApplicationContext持有的BeanFacotry，然后通过getBeanFacotry获得该对象再返回。 AbstractApplicationContext中refreshBeanFacoty方法和getBeanFactory方法都是抽象方法，具体实现在AbstractRefreshableApplicationContext上。 如上，增加了方法的注释，重点在于loadBeanDefinitions方法，该抽象方法在具体实现子类上用于处理不同场景下Bean定义的加载，如Xml配置，注解配置，Web环境等，具体实现会在后面展开。 目前，只是完成了Bean定义的加载，没有出现Bean的实例化。 3.prepareBeanFactory 为第2步返回的BeanFactory设置基础属性。包括： 设置ClassLoader 设置beanFactory的表达式语言处理器，默认使用EL表达式，可以使用#{bean.xxx}的形式来调用相关属性值 添加默认的属性编辑器 添加后置处理器ApplicationContextAwareProcessor，在Bean初始化后自动执行各Aware接口的set方法，包括ResourceLoaderAware、ApplicationEventPublisherAware、MessageSourceAware、ApplicationContextAware、EnvironmentAware 添加需要忽略的依赖注入类型，这些类型会在ApplicationContextAwareProcessor中通过BeanPostProcessor后置处理，包括第（4）点涉及的各内容 预先设置用于自动依赖注入的接口对象，包括BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext 如果存在loadTimeWeaver这个Bean，则增加对应的后置处理器 如果不存在environment，systemProperties，systemEnvironment这3个默认的环境属性Bean，则注册对应的单例，这3个对象已经在第1步中初始化完成 具体可以看源码，这步主要预先设置公共的单例Bean并添加一些公共的后置处理动作，主要体现在BeanPostProcessor上。 4.postProcessBeanFactory 所有Bean的定义已经加载完成，但是没有实例化，这一步可以修改bean定义或者增加自定义的bean，AbstractApplicationContext中为空实现。 如上，以AbstractRefreshableWebApplicationContext为例，其增加了ServletContextAwareProcessor后置处理器，用于处理ServletContextAware接口和ServletConfigAware接口中相关对象的自动注入。同时新增了Web相关的应用范围，包括：request,session,globalSession和application，并增加了各范围默认的单例对象。最后增加了Web环境相关的环境配置Bean,包括servletContext，servletConfig，contextParameters和contextAttributes。 该步骤的功能同第3步类似，都能够增加一些后置处理器。 5.invokeBeanFactoryPostProcessors 在Spring容器中找出实现了BeanFactoryPostProcessor接口的Bean并执行。Spring容器会委托给PostProcessorRegistrationDelegate的invokeBeanFactoryPostProcessors方法执行，内容如下： invokeBeanFactoryPostProcessors在处理时，将BeanFactoryPostProcessor分为了两类进行处理，BeanFactoryPostProcessor和BeanDefinitionRegistryPostProcessor，其中BeanDefinitionRegistryPostProcessor继承自BeanFactoryPostProcessor。执行的时候，先找出所有的BeanDefinitionRegistryPostProcessor执行再找出所有BeanFactoryPostProcessor执行。因为BeanDefinitionRegistryPostProcessor继承自BeanFactoryPostProcessor，所以执行后者时会过滤掉前者的内容。 在执行BeanDefinitionRegistryPostProcessor时，会按照如下的优先级，分类先执行postProcessBeanDefinitionRegistry方法，再统一执行所有的postProcessBeanFactory方法，，规则为： 筛选实现了PriorityOrdered接口的BeanDefinitionRegistryPostProcessor实现 筛选实现了Ordered接口的BeanDefinitionRegistryPostProcessor实现，并执行 执行其他BeanDefinitionRegistryPostProcessors 在执行BeanFactoryPostProcessor也会按照如上的规则，执行BeanFactoryPostProcessor方法。 这里会实例化并初始化实现BeanFactoryPostProcessor接口的类并执行，若存在依赖的的Bean也会被初始化和实例化，具体的过程会在介绍Bean初始化过程时说明。 6.registerBeanPostProcessors 从Spring容器中找出的BeanPostProcessor接口的Bean，并添加到BeanFactory内部维护的List属性中，以便后续Bean被实例化的时候调用这个BeanPostProcessor进行回调处理。该方法委托给了PostProcessorRegistrationDelegate类的registerBeanPostProcessors方法执行。执行过程同步骤5类似，也是按照优先级进行了筛选，具体顺序为： 将实现PriorityOrdered接口的BeanPostProcessor列表注册到ApplicationContext中 将实现Ordered接口的BeanPostProcessor列表注册到ApplicationContext中 将剩余的BeanPostProcessor列表注册到ApplicationContext中 将实现MergedBeanDefinitionPostProcessor接口的BeanPostProcessor列表注册到ApplicationContext中 其中MergedBeanDefinitionPostProcessor接口继承自","date":"2019-10-02","objectID":"/spring_01_start/:0:0","tags":["spring"],"title":"Spring启动流程","uri":"/spring_01_start/"},{"categories":["srccode"],"content":"对Sentinel集群模式做分析","date":"2019-10-01","objectID":"/sentinel_03_module_cluster/","tags":["sentinel"],"title":"Sentinel Culster流程分析","uri":"/sentinel_03_module_cluster/"},{"categories":["srccode"],"content":" 前面介绍了sentinel-core的流程，提到在进行流控判断时，会判断当前是本地限流，还是集群限流，若是集群模式，则会走另一个分支，这节便对集群模式做分析。 一.基本概念 namespace：限流作用于，用于区分一个规则作用于什么范围 flowId：代表全局唯一的规则 ID，Sentinel 集群限流服务端通过此 ID 来区分各个规则，因此务必保持全局唯一。一般 flowId 由统一的管控端进行分配，或写入至 DB 时生成。 thresholdType：代表集群限流阈值模式。其中单机均摊模式下配置的阈值等同于单机能够承受的限额，token server 会根据客户端对应的 namespace（默认为 project.name 定义的应用名）下的连接数来计算总的阈值（比如独立模式下有 3 个 client 连接到了 token server，然后配的单机均摊阈值为 10，则计算出的集群总量就为 30）；而全局模式下配置的阈值等同于整个集群的总阈值。 二.通信框架 sentinel-cluster基于netty提供了一套远程通信框架，分为客户端和服务，其使用了jdk自带的SPI，提供了一些接口的默认实现。如下图为sentinel-cluster-client客户端模块的默认实现类。 InitFunc的加载是通过InitExecutor加载的，InitExecutor在sentinel-core模块中。InitExecutor会在全局访问内加载所有InitFunc的实现类，并调用其init方法完成初始化。该模块中配置的InitFunc实现类为DefaultClusterClientInitFunc，该类会初始化通信协议中各种类型的编码和解码处理类。编解码器将调用注册工厂RequestDataWriterRegistry和ResponseDataDecodeRegistry的方法进行注册，供后续使用。系统提供了PING,FLOW（流控）和PARAM_FLOW（热点参数流控）三种编解码器。 上图为sentinel-cluster的通信协议格式，请求和响应中有个4个字节的消息id和1个字节的消息类型，剩下的就是消息体，对于响应格式，有1个字节的状态信息。需要说明的是，在初始化Netty客户端时，增加了两个filter： 也就是说在发送一个消息时，会自动加上长度为2个字节的消息长度头部，在读取时也会自动省略2个字节的消息长度头部。 为了解析上面的消息格式，在提供了注册方法之上，sentinel还提供了ClientEntityCodeProvider，统一了报文的处理。 如上，该类在static静态代码块中进行了初始化，使用SPI，获取RequestEntityWriter和ResponseEntityDecoder的实现类，这两种实现类也在该模块中指定了默认实现：DefaultResponseEntityDecoder和DefaultRequestEntityWriter。即处理过程为 ClientEntityCodecProvider-\u003eResponseEntityDecoder-\u003eResponseDataDecodeRegisty-\u003e EntityDecoder ClientEntityCodecProvider-\u003eRequestEntityWriter-\u003eRequestDataWriterRegisty-\u003e EntityWriter 系统还提供了TokenClientHandler类，用于响应数据流，进行相应的处理 如上只列出了比较重要的属性和方法。该类继承了ChannelInboundHandlerAdapter并实现了对应的方法，currentState属性用于标记客户端当前的状态，disconnectCallback则用于负责在断线时进行重连。TokenClientHandler实现channelActive方法，会在连接建立时会发送PING请求给服务端；实现channelUnregistered方法，会在连接断开时调用disconnectCallback，在一定时间后进行重连，等待时间跟失败次数有关；实现channelRead方法，会在有响应数据时，接收响应内容，并进行处理，处理流程如下： 在经过Netty处理解析为消息类型对象后，会判断该响应的类型，如果是PING消息的响应，则直接输出日志，否则将从TokenClientPromiseHolder中根据消息id设置对应的响应内容，以便消息发送线程能够获得响应。 上面提到的TokenClientPromiseHolder用于缓存请求消息。如下图，发送消息后，会获取对应的ChannelPromise对象，并根据消息存于TokenClientPromiseHolder中。ChannelPromise会等待Netty请求响应回来，对应的流程如上面InBound流程。在请求正常响应后，会根据消息id再从TokenClientPromiseHolder中获取对应的响应结果。 Cluster模块的核心接口为TokenService ，ClusterTokenServer和ClusterTokenClient。其中ClusterTokenClient内部主要类为NettyTransportClient，在上面已经进行了说明，下面说下其他两个接口。TokenService ，ClusterTokenServer在模块中的关系如下图： 其中接口都由SPI给出了默认的实现，如下： 下面对涉及到的接口和类进行说明。 TokenService：token服务接口，提供了requestToken和requestParamToken方法，分别表示获取流控令牌和获取热点参数令牌。提供的默认实现为DefaultTokenService，会在TokenServiceProvider初始化时使用SPI进行加载。 ClusterTokenServer：服务端上层接口，提供了start和stop方法用于服务端的启动和停止。 NettyTransportServer：ClusterTokenServer的netty实现，同客户端对应，有如下的pipeline配置 其中编解码器的处理同客户端类似，只是增加了服务端的处理器：TokenServerHandler。TokenServerHandler继承自ChannelInboundHandlerAdapter用以在连接建立和有数据交互时进行相应的处理： 实现channelActive：在连接建立时将其缓存起来 实现channelInactive：在连接断开时移除缓存 实现channelRead：在有数据到来时，进行处理。这里会使用RequestProcessorProvider加载的RequestProcessor实现类，根据请求的类型(type字段)选择相应的处理类进行处理。系统现在提供的处理类有FlowRequestProcessor和ParamFlowRequestProcessor，这两者最后都将通过TokenServiceProvider获得DefaultTokenService对象，调用其来完成请求。 SentinelDefaultTokenServer：包装了NettyTransportServer方法，增加了ServerTransportConfigObserver用于监听服务端配置项的更改，从而更新自身。 EmbeddedClusterTokenServer：继承自TokenService和ClusterTokenServer，用于内嵌服务端模式，默认实现为DefaultEmbeddedClusterTokenServer。 DefaultEmbeddedClusterTokenServer：主要组合了DefaultTokenService和SentinelDefaultTokenServer对象用以实现接口方法。 结合上面服务端的实现，可以得到客户端请求一个token的流程如下： 客户端调用DefaultClusterTokenClient的requestToken方法获取token，其内部会委托NettyTransportClient编码后发给服务端 服务端NettyTransportServer收到请求后，由TokenServerHandler的channelRead方法处理这里会根据请求内容中的type，委托给对应的消息处理处理，如FlowRequestProcessor FlowRequestProcessor会调用TokenServiceProvider获取对应的TokenService实现类，默认为DefaultTokenService。然后委托为该类进行处理。 三.统计逻辑 由上可知，cluster模式下，token的获取是由DefaultTokenService来负责的，分为两种：普通流控和热点参数流控。二者的实现基本一致，这里只对普通流控做讲解，即DefaultTokenService中的requestToken方法，如下为处理流程。 当请求requestToken方法时，请求参数包括: ruleId：规则id acquireCount：需要获取的token数 prioritized：是否支持优先 DefaultTokenService会先根据ruleId，使用ClusterFlowRuleManager获得对应的FlowRule规则对象。ClusterFlowRuleManager会在更新规则或者加载规则时根据ruleId缓存在Map中，且分配唯一一个","date":"2019-10-01","objectID":"/sentinel_03_module_cluster/:0:0","tags":["sentinel"],"title":"Sentinel Culster流程分析","uri":"/sentinel_03_module_cluster/"},{"categories":["srccode"],"content":"对Sentinel主要流程和实现做分析","date":"2019-09-30","objectID":"/sentinel_02_module_core/","tags":["sentinel"],"title":"Sentinel Core流程分析","uri":"/sentinel_02_module_core/"},{"categories":["srccode"],"content":" 上次介绍了Sentinel的基本概念，并在文章的最后介绍了基本的用法。这次将对用法中的主要流程和实现做说明，该部分主要涉及到源码中的sentinel-core模块。 1.token获取 如上为token获取的主流程，首先会先获取线程的上下文对象Context，然后根据ResourceName查找对应的处理槽链，获得SlotChain后，生成该次调用动作的Entry对象，该对象会关联对应SlotChain。内部会调用SlotChain的entry方法，让entry动作进入每个槽，后续需要调用Entry的exit方法，让exit动作进入SlotChain的每个槽。 其中第三步生成的Entry对象为CtEntry对象，其模型上是一个链表，会将每次entry动作生成的Entry对象串联起来 如上图，每new一个CtEntry，都会传入context对象。由于每次操作会将当前Entry赋值context的curEntry，每次new一次时，会检查该属性，如果为空，则是第一个节点，直接复制给curEntry；如果非空，则该值为上一个节点，将该值复制给当前值的parent，并将该值的child指向当前节点。做完这些动作后将context的curEntry指向当前节点。具体过程如上图示。 执行entry.exit，内部会判断context.curEntry是否是执行时的entry，此举是为了控制exit顺序保持后进先出。如果判断不通过，说明不是按照后进先出的顺序执行exit，会从执行的entry开始，到根节点逐个进行exit，并抛出异常。如果判断通过，则调用对应的SlotChain执行exit，并更改context.curEntry，将其指向当前节点的父节点，但不解除Entry链的关系。 2.查找处理槽链 执行时会先从本地的缓存中查找是否已经有该资源对应的处理槽链，如果没有，则重新新生成一个。新加载时，使用SPI，查找系统提供的SlotChainBuilder实现，若有除默认的DefaultSlotChainBuilder之外的实现在，则使用第一个，否则使用默认的Builder。默认的Builder提供的处理槽链如下 3.执行处理槽链 槽的处理过程如下： ProcessorSlotChain为一个链表，执行slot的entry方法会进入到Slot的内部，在内部可以通过fireEntry执行链表中下一个slot的entry方法(如果存在)。如上，在fireEntry之前和之后可以有每个slot自己的处理逻辑，从而形成了类似过滤器链的结构。同理，exit过程也类似 3.1. NodeSelectorSlot 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级；该动作发生在fireEntry动作前。 如下代码将构建出相对应的调用路径: 执行SphU.entry时会先获取线程上下文对应的Context，如果没有则新增一个。对于node1C，直接调用SphU.entry，会自动生成一个默认的Context，内部会调用ContextUtil.enter，并设置EntranceNode(sentinel_default_context)，然后将该EntranceNode接入到虚拟EntranceNode(machine-root)的子节点列表中。对于node2A和node3A，由于调用了ContextUtil.enter，相当于显示指定了Context，并设置了EntraceNode(entrance1)和EntraceNode(entrance2)。SphU.entry在没有指定EntryType时，将设置EntryType为OUT。 实现代码如下： 实现上，由于同一个资源共享同一个ProcessorSlotChain对象，因而不同Context调用同一个资源时会使用到同一个NodeSelectorSlot对象。代码中直接使用ContextName相当于是使用了ResourceName-ContextName进行判断。为了在对应的Context下构建调用链，内部维护了一个Map\u003cString,DefaultNode\u003e，其中key为对应线程上下文的ContextName,value为该上下文调用链中的各个Node。对于第一次访问的资源，会在对应的Context链下新增一个Node，并将该节点做为子节点链接到链上最近访问的那个节点上，从而完成调用链的构建。对于重复出现的资源，只会使用第一次出现的顺序。在该slot获得的Node节点将传入后续各个槽进行处理。 3.2.ClusterBuilderSlot 用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据；该动作发生在fireEntry动作前。 上面的例子经过该slot后将新增如下ClusterNode节点 上面说过，由于同一个资源共享同一个ProcessorSlotChain对象，因而不同Context调用同一个资源时会使用到同一个NodeSelectorSlot对象，为了统计该种资源的Cluster信息，直接使用一个ClusterNode节点表示即可。 实现上，ClusterBuilderSlot还持有一个静态的ClusterNodeMap，用于缓存所有资源的ClusterNode信息。当经过该slot时，会判断Map中是否有该资源的节点信息，没有则新建一个。 上面还有一段内容是设置节点的Origin信息节点的内容。如下图，ClusterNode统计了同一种资源的统计信息，而不区分不同的Context来源，内部使用originCountMap区分不同的来源的统计情况。 对于默认的sentinel_default_context，其orgin设置为空(\"\")，因而Cluster没有该Context的Origin信息 3.3.LogSlot 用于打印日志，在发生限流或者降级时输出特定日志；该动作发生在fireEntry动作后。 3.4.StatisticSlot 用于记录、统计不同纬度的 runtime 指标监控信息；该动作发生在fireEntry动作后。 该Slot的动作发生在fireEntry后，根据上面SlotChain执行图，该动作会在后续Slot检查执行后再执行。后续检查包括了权限检查，系统指标，用户自定义的限流和降级规则。 如下图，该Slot的动作如下： 若成功经过后续各个Slot的检查，相当于获得了token，则会更新统计信息，包括增加线程数（ThreadNum），增加通过请求数（PassRequest），涉及的节点包括： 当前节点；当前节点的Origin节点（若存在） 全局Entrance_Node节点（若当前节点类型为EntryType.IN）；执行后将调用onPass回调函数。 其他情况如图示，包括: 在获取token设置了优先策略，等待超时抛出PriorityWaitExeption（注：为什么只增加ThreadNum但不增加PassRequest，却执行了onPass回调函数？这里PriorityWatitException并不是BlockException，抛出PriorityWaitException时，该请求已经获取了令牌，可以执行后续的操作，只是不在当前窗口，这点后续会说明） 后续Slot规则不通过，抛出BlockException 发生其他异常，这时候会设置当前节点的Error值，为exit动作做判断 退出的动作如下，该行为发生在fireExit前，用于统计成功时的响应时间，减去获取token时的线程数，增加成功请求数（SuccessRequest） 具体的统计方法，后续会对StatisticNode做说明。 3.5.SystemSlot 通过系统的状态，例如 load1 等，来控制总的入口流量； 检查当前系统指标是否正常，只检查入口流量节点。包括全局QPS，全局线程数，全局平均响应时间，系统负载，CPU负载。 3.6.AuthoritySlot 根据配置的黑白名单和调用来源信息，来做黑白名单控制； 3.7.FlowSlot 用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； 首先会根据规则设定的模式，选择处理方式，有Local和Cluster两种，这里先介绍Local方式。 Local方式时，先选择统计数据的节点，再根据设定的限流器获取token，达到限流的目的。 3.7.1 选择统计数据的节点 这一步将根据给定设置的应用范围，和限流策略来选择对应的节点。 这边先介绍默认的应用范围和限流策略，分为： 应用范围：default，other 限流策略：DIRECT，RELATE，CHAIN 选择时，将根据调用方LimitApp来选择对应的节点。若规则作用于origin上且除default和other外,如果是DIRECT策略，返回origin节点；若是作用于default上，如果是DIRECT策略，返回Cluster节点；若是作用于other上，如果是DIRECT策略，返回origin节点。上述其他情况的选择过程都是相同的，即：如果资源名为空，返回空；如果是RELATE策略，使用ClusterNode节点数据；如果是CHIAN策略，且当前节点名同规则名一致，使用当前节点数据，否则返回为空，详情可以看代码。 获得数据节点后，便可以使用规则中指定的限流器校验节点的数据，以获取token。 3.7.2 根据限流器获取token 系统提供的限流器包括： 默认限","date":"2019-09-30","objectID":"/sentinel_02_module_core/:0:0","tags":["sentinel"],"title":"Sentinel Core流程分析","uri":"/sentinel_02_module_core/"},{"categories":["srccode"],"content":"Sentinel是阿里开源的一款高性能的限流框架。这里将对Sentinel的使用和实现进行介绍","date":"2019-09-29","objectID":"/sentinel_01_basic/","tags":["sentinel"],"title":"Sentinel基本概念","uri":"/sentinel_01_basic/"},{"categories":["srccode"],"content":" Sentinel是阿里开源的一款高性能的限流框架。这里将对Sentinel的使用和实现进行介绍。 这里先介绍下Sentinel中涉及到的基本概念，包括使用上或者实现上。主要是笔者在阅读文档和源码时经常会接触到的对象。 Resource 资源是整个Sentinel最基本的一个概念。可以是一段代码，一个http请求，一个微服务，总而言之，他是Sentinel需要保证的实体。大部分情况下，我们可以使用方法签名，URL或者是服务名称来作为资源的名称。它在Sentinel中的体现是：ResourceWrapper，他有两个子类： StringResourceWrapper 使用string来标识一个资源 MethodResouceWrapper 使用一个函数签名来标识一个资源 Node 节点是用来存储统计数据的基本数据单元，Node本身只是一个接口，它有多个实现： StatisticNode 唯一的直接实现类，实现了流量统计的基本方法，在StatisticSlot中使用 ClusterNode 继承自StatisticNode，对于某一个资源的全局统计 DefaultNode 继承自StatisticNode，对于某一个资源在相应上下文中的实现，保存了一个指向ClusterNode的引用。另外还保存了子节点列表，当在同一个context下多次调用SphU.entry不同资源时会创建子节点 EntranceNode 继承自DefaultNode，代表一个调用的根节点，一个Context会对应到一个EntranceNode Context 上下文是用来保存当前调用的元数据，存储在ThreadLocal中，它包含了几个信息： EntranceNode 整个调用树的根节点，即入口 Entry 当前的调用点 Node 关联到当前调用点的统计信息 Origin 通常用来标识调用方，这在我们需要按照调用方来区分流控策略的时候会非常有用 每当我们调用SphU.entry()或者 SphO.entry()获取访问资源许可的时候都需要当前线程处在某个context中，如果我们没有显式调用ContextUtil.enter()，默认会使用Default context。如果我们在一个上下文中多次调用SphU.entry()来获取多个资源，一个调用树就会被创建出来 NullContext 超过系统能够创建的最大会话数则返回NullContext，后续不对该会话做过滤校验，直接放过。 Entry 每次SphU.entry()调用都会返回一个Entry，Entry保持了所有关于当前资源调用的信息： createTime 这个资源调用的创建时间 currentNode SphU.entry请求进入的资源在当前上下文中的统计数据Node originNode SphU.entry请求进入的资源对于特定origin调用方的统计数据node Entry的实现类为CtEntry，它其中除了上述信息之外，还保存了额外的信息： parent 调用树链条中上一个entry child 调用树链条中的下一个entry chain 当前调用资源所使用的限流工作责任链，包括各个Slot context 当前调用点所属的上下文 EntryType EntryType 说的是这次请求的流量类型，共有两种类型：IN 和 OUT 。 IN：是指进入我们系统的入口流量，比如 http 请求或者是其他的 rpc 之类的请求。 OUT：是指我们系统调用其他第三方服务的出口流量。 入口、出口流量只有在配置了系统规则时才有效。 设置Type 为 IN 是为了统计整个系统的流量水平，防止系统被打垮，用以自我保护的一种方式。 设置Type 为 OUT 一方面是为了保护第三方系统，比如我们系统依赖了一个生成订单号的接口，而这个接口是核心服务，如果我们的服务是非核心应用的话需要对他进行限流保护；另一方面也可以保护自己的系统，假设我们的服务是核心应用，而依赖的第三方应用老是超时，那这时可以通过设置依赖的服务的 rt 来进行降级，这样就不至于让第三方服务把我们的系统拖垮。 Slot Entry 创建的时候，同时也会创建一系列功能插槽（slot chain），这些插槽有不同的职责，例如: NodeSelectorSlot 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级； ClusterBuilderSlot 则用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS,thread count 等等，这些信息将用作为多维度限流，降级的依据； LogSlot 用于打印日志 StatisticSlot 则用于记录、统计不同纬度的 runtime 指标监控信息； SystemSlot 则通过系统的状态，例如 load1 等，来控制总的入口流量； AuthoritySlot 则根据配置的黑白名单和调用来源信息，来做黑白名单控制； FlowSlot 则用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； DegradeSlot 则通过统计信息以及预设的规则，来做熔断降级； Slot只绑定在CtEntry上 ProcessorSlotChain 功能槽处理链，entry进入一个槽可以添加自己的动作，之后后fire动作会entry下一个槽，exit同理 注意，实现上相同资源共享一个ProcessorSlotChain ，可以跨Context LimitApp 流控规则中的 limitApp 字段用于根据调用来源进行流量控制。该字段的值有以下三种选项，分别对应不同的场景： default：表示不区分调用者，来自任何调用者的请求都将进行限流统计。如果这个资源名的调用总和超过了这条规则定义的阈值，则触发限流。 {some_origin_name}：表示针对特定的调用者，只有来自这个调用者的请求才会进行流量控制。例如 NodeA 配置了一条针对调用者caller1的规则，那么当且仅当来自 caller1 对 NodeA 的请求才会触发流量控制。 other：表示针对除 {some_origin_name} 以外的其余调用方的流量进行流量控制。例如，资源NodeA配置了一条针对调用者 caller1 的限流规则，同时又配置了一条调用者为 other 的规则，那么任意来自非 caller1 对 NodeA 的调用，都不能超过 other 这条规则定义的阈值。 同一个资源名可以配置多条规则，规则的生效顺序为：{some_origin_name} \u003e other \u003e default 介绍完了上面的基本概念，下面给出Sentinel的基本用法： List\u003cFlowRule\u003e rules = new ArrayList\u003cFlowRule\u003e(); FlowRule rule1 = new FlowRule(); rule1.setResource(KEY); // set limit qps to 20 rule1.setCount(20); rule1.setGrade(RuleConstant.FLOW_GRADE_QPS); rule1.setLimitApp(\"default\"); rules.add(rule1); ​ Entry entry = null; ​ try { entry = SphU.entry(KEY); // token acquired, means pass,do biz logic } catch (BlockException e1) { //block,handle block logic } catch (Exception e2) { // biz exception,handle biz exception logic } finally { if (entry != null) { entry.exit(); } } ​ 如上，为sentinel的基本用法: 先设定好规则，在进入需要受保护的资源前，尝试获取token，若成功获取token，则可以执行相关逻辑，否则抛出异常进行处理，最后释放所获得的token 。 ","date":"2019-09-29","objectID":"/sentinel_01_basic/:0:0","tags":["sentinel"],"title":"Sentinel基本概念","uri":"/sentinel_01_basic/"},{"categories":["notes"],"content":"关于JAVA中EOF标识的讲解","date":"2019-09-28","objectID":"/notes_001_java_eof/","tags":["work","java"],"title":"Java的EOF标识？","uri":"/notes_001_java_eof/"},{"categories":["notes"],"content":" 这篇是关于JAVA中EOF标识的讲解，之前在工作上碰到过一个问题，有人问过，不能通过判断EOF来知道文件有没有读取完毕吗？其实，还真不能。 直接从JDK接口文档入手，以FileInputStream为例，JDK接口文档给出了明确的说明： 使用FileInputStream的read方法读取文件时，当返回-1就表明读到了文件末尾，如果期间出现IO异常，则会抛出一个IOException。而对于EOF文件结束符，其实是不存在的。在Linux系统之中，EOF根本不是一个字符，而是当系统读取到文件结尾，所返回的一个信号值，例如在C语言中，EOF是一个定义在头文件stdio.h的常量，一般等于-1。对于JAVA的实现，我们可以通过查看FileInputStream的源码查看，如下： 其中read0为native方法，需要查看jvm源码。根据JVM源码定位进去，发现read0调用readSingle方法： 源码看这FileInputStream.c（http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/5b86f66575b7/src/share/native/java/io/FileInputStream.c） 而readSingle方法位于io_util.c中： 搓这里io_util.c（http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/5b86f66575b7/src/share/native/java/io/io_util.c） 跟踪IO_Read方法，可以得到如下源码实现： 源文件分别位于io_util_md.h(http://hg.openjdk.java.net/jdk/jdk/file/bd45ce23b1ac/src/java.base/unix/native/libjava/io_util_md.h)和io_util_md.c(http://hg.openjdk.java.net/jdk/jdk/file/bd45ce23b1ac/src/java.base/unix/native/libjava/io_util_md.c) 所以，其实read方法最后还是调用了操作系统的read方法,该方法跟具体的操作系统相关，在linux下，有如下的说明 也就是，当使用read方法去读文件时，如果读到了文件末尾，没有字符返回时，则该方法返回0，如果出现异常，则返回-1.然后，JDK在readSingle方法里进行了包装，如果返回0，则在JDK层面返回-1，如果返回-1，则抛出IOException.因而，JAVA中没有EOF这个标识符，而是使用-1来标识文件结束。 ","date":"2019-09-28","objectID":"/notes_001_java_eof/:0:0","tags":["work","java"],"title":"Java的EOF标识？","uri":"/notes_001_java_eof/"},{"categories":["notes"],"content":"介绍常见的分布式一致性协议","date":"2019-09-27","objectID":"/notes_000_distrubte_protocol/","tags":["distrubute"],"title":"分布式一致性协议","uri":"/notes_000_distrubte_protocol/"},{"categories":["notes"],"content":" 介绍常见的分布式一致性协议 一．CAP/BASE 1. CAP理论 CAP理论又称之为布鲁尔定理（Brewer’S theorem），认为在设计一个大规模可扩放的网络服务时候不能同时兼容：一致性（consistency）、可用性（Availability）、分区容错（Partition-tolerance）。 一致性：在分布式系统中的所有数据备份，在同一时刻是否有同样的值。（等同于所有节点访问同一份最新的数据副本） 可用性：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。 分区容忍性：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择 CAP理论容易理解，网上也有关于该理论的说明，包括模型的简易证明；弱条件下模型的成立等。 参考资料： http://www.cnblogs.com/mmjx/archive/2011/12/19/2290540.html http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html 2. BASE理论 BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency） 基本可用：分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 软状态：允许系统存在中间状态，而该中间状态不会影响系统整体可用性 最终一致性：系统中的所有数据副本经过一定时间后，最终能够达到一致的状态 二．两阶段提交 两阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法。 在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。 如上图示，该协议分为两个阶段： 请求阶段（commit-request phase，或称表决阶段，voting phase） 在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。 提交阶段（commit phase） 在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行相应的操作。 二阶段提交算法的最大缺点就在于它在执行过程中间，节点都处于阻塞态。即节点之间在等待对方的响应消息时，它将什么也做不了。特别是，当一个节点在已经占有了某项资源的情况下，为了等待其他节点的响应消息而陷入阻塞状态时，当第三个节点尝试访问该节点占有的资源时，这个节点也将连带陷入阻塞状态。 另外，协调者节点指示参与者节点进行提交等操作时，如有参与者节点出现了崩溃等情况而导致协调者始终无法获取所有参与者的响应信息，这时协调者将只能依赖协调者自身的超时机制来生效。但往往超时机制生效时，协调者都会指示参与者进行回滚操作。这样的策略显得比较保守。 参考资料 https://en.wikipedia.org/wiki/Two-phase_commit_protocol 三．三阶段提交 与两阶段提交不同的是，三阶段提交是“非阻塞”协议。三阶段提交在两阶段提交的第一阶段与第二阶段之间插入了一个准备阶段，同时对于协调者和参与者都设置了超时机制，使得原先在两阶段提交中，参与者在投票之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。 如上图示，该协议分为三个阶段： canCommit 协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 preCommit 协调者根据参与者的反应情况来决定是否可以进行事务的PreCommit操作。根据响应情况，有以下两种可能. 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 发送预提交请求,Coordinator向Cohort发送PreCommit请求，并进入Prepared阶段。 事务预提交,Cohort接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 响应反馈,如果Cohort成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 发送中断请求,Coordinator向所有Cohort发送abort请求。 中断事务,Cohort收到来自Coordinator的abort请求之后（或超时之后，仍未收到Cohort的请求），执行事务的中断。 doCommit 该阶段进行真正的事务提交，也可以分为以下两种情况: 执行提交 A.发送提交请求。Coordinator接收到Cohort发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有Cohort发送doCommit请求。 B.事务提交。Cohort接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 C.响应反馈。事务提交完之后，向Coordinator发送ACK响应。 D.完成事务。Coordinator接收到所有Cohort的ACK响应之后，完成事务。 中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 参考资料： https://en.wikipedia.org/wiki/Three-phase_commit_protocol https://my.oschina.net/wangzhenchao/blog/736909 四. Paxos 1.背景 在常见的分布式系统中，总会发生诸如机器宕机或网络异常等情况。Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。这里某个数据的值并不只是狭义上的某个数，它可以是一条日志，也可以是一条命令（command）等，根据应用场景不同，某个数据的值有不同的含义。 2.相关概念 在Paxos算法中，有三种角色： Proposer：提案发起者，向集群中的其他节点发一个提案Proposal，该提案中有一个对应的值。 Acceptor：提案接受者，负责处理接收到的提议，他们的回复就是一次投票。会存储一些状态来决定是否接收一个值。 Learners：不参与提案的发起和投票，学习已经被Acceptor接受的提案 3.目标 保证最终有一个value会被选定，当value被选定后，进程最终也能获取到被选定的value。 4.两个原则 安全性原则：保证不能做错的事。只能有一个值被批准，不能出现第二个值把第一个覆盖的情况；每个节点只能学习到已经被批准的值，不能学习没有被批准的值。 存活原则：只要有多数服务器存活并且彼此间可以通信最终都要做到的事。最终会批准某个被提议的值；一个值被批准了，其他服务器最终会学习到这个值。 5.Basic Paxos Basic Paxos算法分为两个阶段。具体如下： 阶段一： Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二： 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 示例过程如下，其中MaxN,AccerptN,AcceptV分别表示Acceptor的最大响应提案编号，接受的最大编号和接受编号对应的值: 6.推导过程 1）只有一个Acceptor，只要Acceptor接受它收到的第一个提案并被选定，则可以保证只有一个value会被选定。 2）多个Acceptor 提案(Propersal) = [","date":"2019-09-27","objectID":"/notes_000_distrubte_protocol/:0:0","tags":["distrubute"],"title":"分布式一致性协议","uri":"/notes_000_distrubte_protocol/"},{"categories":["srccode"],"content":"这节介绍Redis的集群模式","date":"2019-09-26","objectID":"/redis_06_cluster/","tags":["redis"],"title":"Redis集群","uri":"/redis_06_cluster/"},{"categories":["srccode"],"content":" 这节介绍Redis的集群模式 主从模式提供了读写分离的支持，Sentinel提供了高可用的保障，满足了读模式下的横向扩展，但主节点只有一个，集中式的写模式无法应对不断增长的写需求。 Redis 3.x 版本提供了Redis cluster功能，服务端sharding使用槽作为分布式的解决方案。对于 2.x版本，则通过客户端API提供的客户端sharding方式，使用一致性哈希来实现数据分片。此外，twiter开源的twemproxy 和豌豆荚的codis，则采用代理模式来实现。 1 服务端模式 对于客户端来说，整个集群被看做一个整体，客户端可以连接任意一个节点进行操作，就像操作单一Redis数据库一样。当客户端操作的key没有分配到该节点上时，会返回转向指令，指向正确的节点。 1.1 集群的建立 3.x 版本的Redis节点可以通过打开clustrer-enabled选项来开启服务器的集群模式，再通过 CLUSTER MEET \u003cip\u003e \u003cport\u003e 命令连接其他节点。 新加入的节点B通过CLUSTER MEET命令同节点A建立连接后，节点A会通过Gossip协议将节点B的信息传播给集群中的其他节点，当其他节点发现新加入的节点B后也会主动同它建立连接。处于集群状态的节点同单机模式下的服务器实例没什么区别，只是只能使用db 0 数据库，同时除了执行单机模式下的任务外还会执行集群所需的任务，如Gossip的消息的传播。 1.2 槽指派 Redis集群使用槽来存储分片信息，集群中的每个节点负责处理16384个槽中的一部分。对于每个写操作，通过计算crc(key)%16384对key值进行hashing，分配到16384个槽中的一个，然后由对应的节点处理。 节点负责哪些槽信息可以通过向节点发送 CLUSTER ADDSLOTS \u003cslot\u003e [slot …] 来指派。分配完槽信息后，该节点会将自身的信息传播给集群中的机器节点，使得集群中的所有节点都有全部的槽分配信息。当16384个槽都有节点在处理时，节点处于上线状态；相反的，如果有任何一个槽没有得到处理，那么集群处于下线状态。 集群中的某个节点在收到一个请求时，会先判断是否由自己来处理，如果不是，则会向客户端返回 MOVE \u003cslot\u003e \u003cip\u003e:\u003cport\u003e 错误命令，该命令给出了请求所属的槽以及对应节点的ip和端口号。客户端在收到MOVE错误时，会转到对应的节点重新发送之前的命令。注意，需要使用客户端的集群模式才会自动跳转,如下： redis-cli -c -h xxx -p xxx ``` \u0026emsp;当动态添加或者减少节点时，需要将16384个槽做重新分片，槽中的键值也要迁移。重新分片可以在线执行，使用自带的```redis-trib```工具。 ##### 1.3 高可用和故障转移 \u0026emsp;Redis集群，要保证```16384```个槽对应的节点都正常工作，如果某个节点发生故障，那它负责的槽也就失效，整个集群将不能工作。可以使 ``` CLUSTER REPLICATE \u003cnode_id\u003e ``` 将节点配置成主从结构来增加节点的可用行。 \u0026emsp;集群中的每个节点会定期的向其他节点发送PING消息来检测对方的状态，一个节点的状态可以为```在线```，```疑似下线```和```下线```。当某个节点n发现半数以上负责处理槽的主节点都将某个主节点x标记为疑似下线状态时，节点n将节点x标记为下线状态，并向集群广播消息。 \u0026emsp;当节点x的从节点收到主节点下线的消息时，会对该节点进行故障转移。同Sentinel选举新的leader Sentinel节点一样，节点x的从节点会向集群中负责处理槽的其余主节点获取选票，以在节点x的从节点中选出新的主节点。新的主节点会撤销已下线主节点的槽指派，并分配给自己，然后向集群中的其他节点广播自己为新主节点的消息。 #### 2 客户端模式 \u0026emsp;客户端模式下每个节点都是单一的实例，需要由客户端应用自己管理key所在的分片，以及处理节点的故障转移，Redis的客户端Jedis提供了分片的支持。 ![](2.png) \u0026emsp;Jedis对Sharded的实现主要是在```ShardedJedis.java```和```ShardedJedisPool.java```中,可以见[这里](https://segmentfault.com/a/1190000002691429)。 \u0026emsp;Jedis的Redis Sharding实现具有如下特点： 1. 采用[一致性哈希算法](http://www.cnblogs.com/lpfuture/p/5796398.html)，将key和节点name同时hashing，然后进行映射匹配，采用的算法是```MURMUR_HASH```。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。 2. 为了避免一致性哈希只影响相邻节点造成节点分配压力，ShardedJedis会对每个Redis节点根据名字(没有的话，Jedis会赋予缺省名字)会虚拟化出160个虚拟节点进行散列。根据权重也可虚拟化出160倍数的虚拟节点。用虚拟节点做映射匹配，可以在增加或减少Redis节点时，key在各 Redis节点移动再分配更均匀，而不是只有相邻节点受影响。 3. Sharded Jedis支持```keyTagPattern```模式，即抽取key的一部分keyTag做sharding，这样通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。 #### 3 代理模式 \u0026emsp;通过在客户端和实际Redis服务中间增加代理层，代理模块实现Redis协议，客户端连接代理和连接原生的Redis实例没有什么区别，上层应用可以像使用单机的Redis一样使用，代理会处理请求的转发，不停机的数据迁移等工作，所有后边的一切事情，对于前面客户端来说是透明的，可以简单的认为后边连接是一个内存无限大的Redis服务。 ![](3.png) \u0026emsp;Twitter的```twemproxy```和豌豆荚的```codis```就是该模式的实现。关于```codis```的介绍，可以看[这里]( http://www.cnblogs.com/wangdaijun/p/6156397.html)。 \u0026emsp;同前面两种模式相比，代理模式的好处在于，客户端和服务端无需作出变更，主要维护工作在于代理模块中；同后端实际实例的连接数落在了代理上，能够有效的控制客户端过多造成的连接数暴增；提供sharding功能，支持服务器集群水平扩展。同时，由于增加了代理，客户端到真正的实例服务器需要走两次网络。 ","date":"2019-09-26","objectID":"/redis_06_cluster/:0:0","tags":["redis"],"title":"Redis集群","uri":"/redis_06_cluster/"},{"categories":["srccode"],"content":"这节介绍Redis的高可用解决方案：Sentinel","date":"2019-09-25","objectID":"/redis_05_sentinel/","tags":["redis"],"title":"Redis Sentinel","uri":"/redis_05_sentinel/"},{"categories":["srccode"],"content":" 这节介绍Redis的高可用解决方案：Sentinel 1.介绍 Sentinel是Redis官方推荐的高可用(HA)解决方案，当用Redis做master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换。 Sentinel本身是一个运行在特殊模式下的Redis服务器，它能监控多个master-slave集群，发现master宕机后能进行自动切换。 2.获取信息方式 sentinel通过配置项中的 sentinel monitor \u003cmaster name\u003e \u003cmaster ip\u003e \u003cmaster port\u003e \u003cquorum\u003e 选项来获取master节点的信息。 在启动后sentinel会建立同master节点的命令连接和订阅连接。以便通过命令连接向主节点发送命令，通过订阅连接订阅服务器的 sentinel:hello 频道。 sentinel每10秒会向master节点发送INFO命令，通过分析命令的返回结果能够知道主节点和从节点的信息。对于每个从节点，sentinel也会向它建立一个命令连接和订阅连接。 sentinel每2秒通过命令连接向所监听的节点发送订阅命令，如 PUBLISH _sentinel_:hello ….. 其中的信息包括了sentinel本身的信息以及自己记录的主节点信息。同时，sentinel也会订阅_sentinel_:hello频道，所以sentinel能够以这种方式同其他的sentinel节点通信，以同步信息,见goosip协议。 当sentinel从订阅信息中发现一个新的sentinel节点时，会向该新发现的节点建立命令连接，最后监视同一主服务器的各个sentinel节点会形成互相连接的网络。 3.节点失效 配置项 sentinel down-after-milliseconds \u003c主节点名\u003e \u003c中断时间ms\u003e 设置了sentinel主观下线的时间。sentinel每隔一秒就会向主节点发送PING命令，如果master在“中断时间”内不回应PONG 或者是回复了一个错误消息，那么这个sentinel会主观地(单方面地)认为这个master已经不可用了(SDOWN)。 当sentinel判断主节点已经处于主观下线状态后，会向其他sentinel发送 is-master-down-by-add 命令，以询问其他sentinel的状态，确认该主节点是否处于下线状态（主观下线或者客观下线）。当回复的下线状态的数量达到配置项中的quorum值时，则该sentinel会将主节点标记为客观下线状态（ODOWN）。 当sentinel判断主节点处于客观下线状态后，会触发故障转移。 4.故障转移 发生故障转移时，会从监听主节点的sentinel中选举出主的sentinel来处理故障转移的过程。选举的过程类似于Raft协议，由标记客观下线的sentinel节点充当candidate，向其他sentinel节点（follower）发起投票，当某个candidate从follower获得的票数超过一半后，该候选者就会成为leader。而sentinel中的epoch，配置纪元类似于Raft中的term，每次选举后都会自增。主要过程为： 每个充当candidate的sentinel节点都会要求其他sentinel节点发送is-master-down-addr命令，将自己设置为leader。 收到命令的sentinel节点，如果当前epoch和candidate传给他的epoch一样，说明他已经把自己的票投给了其他candidate。投过票给别的sentinel后，在当前epoch内自己就只能成为follower。如果该节点还没投过票，会采取先到先得的规则，将自己的票投给请求的candidate节点。 收到回复的candidate节点，会检查响应的epoch值和leader_runid值是否同自身的值一致，是的话则表示获得了一票。 当某个candidate节点获得半数以上的票数时，该节点便成为了leader节点。 如果一定时间内没法选举出leader节点，则每个candidate节点会等待随机时间后再次发起选举，知道选出leader节点为止。 选举出领头sentinel节点后，将由该节点处理故障转移，过程如下： 在已下线主节点的所有从节点中，选出一个从节点，将其转换为主节点。 主sentinel会按照下面的规则选择适合的slave节点上升为master节点： 去除已下线的slave节点 去除最近五秒内没有回复过主sentinel节点INFO信息的slave节点 去除与已下线主节点连接断开超过down-after-milliseconds*10毫秒的slave节点 根据各slave节点的优先级，从小到大排序，选择优先级最小的节点。对于相同优先级的节点，选择复制偏移量最大和runid最小的节点。 最后向被选择出来的slave节点发送SLAVE OF NO ONE命令。 向已下线主节点下的所有从节点发送SLAVE OF命令，改为复制新的主节点。 将已下线主节点设置为新主节点的从节点。 其中，上面步骤1)中的slave节点优先级由redis配置文件中的slave-priority N 选项控制。0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被 哨兵挑选提升为master。 上步骤2) 中，从节点需要同步新的主节点的信息，期间会导致从节点不可用，可以通过 sentinel parallel-syncs mymaster \u003cn\u003e 来控制同时进行同步的从节点的数量。这个数字越小，完成故障转移所需的时间就越长，但是如果这个数字越大，就意味着越多的slave因为复制而不可用。 5.脑裂时的数据一致性 Redis不保证强一致性，在发生网络故障时，有可能出现脑裂。从脑裂发生到网络恢复正常，复制结束的这段时间里，异常主节点写入的数据将丢失。为了避免数据的丢失，可以对主节点增加如下配置： min-slaves-to-write 1 #执行写操作所需的最少slave服务器数量，如果数量少于设定的值，写操作将被拒绝 min-slaves-max-lag 10 #网络延迟的最大时间，当写操作延迟大于所设定的时间，写操作将被拒绝 ","date":"2019-09-25","objectID":"/redis_05_sentinel/:0:0","tags":["redis"],"title":"Redis Sentinel","uri":"/redis_05_sentinel/"},{"categories":["srccode"],"content":"这节介绍Redis的发布与订阅","date":"2019-09-24","objectID":"/redis_04_publish/","tags":["redis"],"title":"Redis发布与订阅","uri":"/redis_04_publish/"},{"categories":["srccode"],"content":" 这节介绍Redis的发布与订阅 Redis提供了发布与订阅的功能，客户端能够向服务器订阅某个频道，当其他客户端向服务器的该频道发布消息时，服务器会将消息推送到订阅该频道的客户端。提供的命令包括： SUBSCRIBE channel [channel …] 该命令可以向服务器订阅多个频道的消息。与之对应的有UNSUBSCRIBE命令。 PSUBSCRIBE pattern [pattern …] 该命令可以向服务器订阅多个频道中满足对应模式的消息。与之对应的有UNPSUNSCRIBE命令。 PUBLISH channel message 客户端向服务器对应的频道发布消息。 PUBSUB CHANNELS [pattern] 查看服务器当前被订阅的频道信息。 PUBSUB NUMSUB [pattern …] 可以查看对应频道的订阅者数量。 PUBSUB NUMPAT 可以查看服务器当前被订阅模式的数量。 内部实现比较简单，服务器记录客户端与订阅频道的关系，以链表的方式存储，执行对应命令的时候通过遍历链表获得相应的数据执行后输出。 ","date":"2019-09-24","objectID":"/redis_04_publish/:0:0","tags":["redis"],"title":"Redis发布与订阅","uri":"/redis_04_publish/"},{"categories":["srccode"],"content":"这节介绍Redis的主从复制过程,包括建立和复制","date":"2019-09-23","objectID":"/redis_03_copy/","tags":["redis"],"title":"Redis主从复制","uri":"/redis_03_copy/"},{"categories":["srccode"],"content":" 这节介绍Redis的主从复制过程,包括建立和复制。 1.复制的建立 1.1 SLAVEOF命令 Redis支持主从模式以提供读写分离，可以通过在从服务器的客户端上执行如下命令以连接主服务器： SLAVEOF IP PORT 或者在配置文件中配置SLAVEOF选项。 1.2 建立过程 SLAVEOF命令包括以下几个步骤： 从服务设置主服务器的地址和端口，从服务器会保存客户端上送的地址和端口。 从服务器同主服务器建立套接字连接。 从服务器向主服务器发送PING命令，通过判断响应是否为PONG或者有没超时，以检查套接字连接是否正常和主服务器能否正常处理命令请求。 身份验证。主服务器的requirepass选项和从服务器的masterauth选项用于身份验证，必须同时设置或者同时去除，才能让身份验证通过（或者不进行身份证验证）。 发送端口信息。 从服务器通过 REPLCONF listening-port 从服务器端口 命令向主服务器发送自己的监听端口号。主服务器收到命令后会将信息进行存储，用于后续INFO replication命令的输出。 执行同步。 从服务器向主服务器发送同步命令，复制主服务器上的数据使之保持一致。 命令传播。 同步完成后，主服务器会一直将自己执行的写命令发送给从服务器以保持同步。在这个过程，从节点会以每秒一次的频率，向主节点发起心跳检测，以保证连接的正常。 2.复制的过程 Redis的复制分为同步和命令传播两个操作： 同步操作使用SYNC或者PSYNC命令将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 命令传播操作用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，主服务器会将该命令发送给从服务器执行，使主从服务器保持一致状态。 2.1 SYNC SYNC命令会触发全量同步，执行步骤包括： 从服务器向主服务器发送SYN命令 主服务器收到命令后执行BGSAVE命令，并将之后的写命令记录到一个缓冲区中。 主服务器会将生成的RDB文件传给从服务器，从服务器接收到文件后会清空自己的本地的数据，然后载入该RDB文件。 主服务器将缓冲区中的记录发送给从服务器。 SYNC命令的不足在于，从节点同主节点连接断开重新连接后如果距离上一次的同步时间不久，数据量不大的情况下也会执行全量同步，会影响性能。为了处理这种情况，Redis 2.8后的版本提供PSYNC命令。 2.2 PSYNC PSYNC命令分为增量同步和全量同步两种情况。全量同步用于初次复制的情况，对于断线重连后的情况，主节点会判断是否满足条件，如果满足则会执行增量同步，否则使用全量同步，这个条件依赖于PSYNC命令的实现，包括： 主从节点的复制偏移量 主节点的复制积压缓冲区 服务器的运行ID。 复制偏移量：主节点在向从节点传播N个字节的数据时，会将自己的复制偏移量加N；从节点收到数据后，也会更新自己的复制偏移量，该值可以用于判断主从节点是否状态一致。 复制积压缓冲区：固定长度的先进先出队列，存储着偏移量和字节值的关系。主节点在进行命令传播时，将命令发送给从节点后，会同时将其写入复制积压缓冲区中。当断线重连后，如果从节点上送的复制偏移量还存在队列中，则执行增量同步，将缓冲区中，复制偏移量后的字节传播给从节点，否则将执行全量同步。 服务器运行ID：长度40的16进制字符串，由Redis服务器在启动后自动分配。主从节点建立连接后会互换ID，在断线重连后，从节点可以使用ID来判断新连接上的主节点是否同上次的一致，如果不是直接执行全量同步，否则尝试使用增量同步。 PSYNC的执行步骤如下： 3 过期键的复制 关于过期键的复制，持久化对复制的影响，以及4.0后提供的从节点到从节点的复制等，可以参考官方的文档。 ","date":"2019-09-23","objectID":"/redis_03_copy/:0:0","tags":["redis"],"title":"Redis主从复制","uri":"/redis_03_copy/"},{"categories":["srccode"],"content":"这节介绍Redis的持久化，包括RDB和AOF两种方式","date":"2019-09-22","objectID":"/redis_02_persist/","tags":["redis"],"title":"Redis持久化","uri":"/redis_02_persist/"},{"categories":["srccode"],"content":" 这节介绍Redis的持久化，包括RDB和AOF两种方式。 1.RDB持久化 Redis能够将内存中的数据持久化到RDB文件中，避免数据丢失。RDB文件的格式如下示： 第一部分是开头的5个字节，值为REDIS，第二部分是长度为4个字节的版本号，值为一个字符串表示的整形。database部分包含零个或任意多个数据库，以及各个数据库中的键值对数据，database的结构如下示： EOF为1字节的结束符号，check_sum为8字节长的校验和，这个校验和是通过前面4个部分计算出来的。 可以使用SAVE或者BGSAVE命令生成RDB文件。SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求。BGSAVE命令则会派生出一个子进程，然后由子进程负责创建RDB文件，父进程继续处理命令请求。 BGSAVE除了可以通过命令来手动执行外，还可以通过配置项来定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。配置格式为： save N M 表示服务器在N秒内对数据进行了至少M次修改。该配置可以有多个，只要满足其中一个条件就会触发BGSAVE。当BGSAVE命令执行时，父进程会fork一个子进程，子进程会将当前内存中的数据写到磁盘上的一个临时文件。当临时文件写完后会将原来的RDB文件替换掉，这样的好处是可以使用copy-on-write。 RDB文件只是服务器在某个时刻的快照，潜在的风险就是会丢失两次备份之间的数据，同时在服务器出现问题时也可能丢失最新的数据。 RDB文件生成的文件名默认为dump.rbd，在文件会在服务器启动时自动载入。注意，如果开启了AOF持久化，则服务器优先加载AOF文件。只有在AOF持久化关闭的状态下，才会加载RDB文件。 2.AOF持久化 不同于RDB文件以保存数据库中键值对值的方式，AOF文件以追加的方式，将所有的写命令以请求协议的格式保存到文件中来记录数据库的状态，因而文件内容是可识别的纯文本，可以直接查看。 当有写命令到达时，服务器会执行客户端发来的命令，然后将执行后的写命令追加到AOF缓冲区中。追加完数据后服务器会判断是否需要执行文件写入和文件同步动作，当判断结果为需要时会将缓冲区中的内容写入到磁盘中，由于操作系统的特性，在没有调用fsync或者fdataasync同步函数时，操作系统通常会将写入数据暂时保存在一个内存缓冲区里面，等到缓冲区的空间被填满或者过了指定的时间后，才真正的将缓冲区中的数据写入到磁盘里面。AOF文件的持久化策略由appendfsync选项的值控制，包括always，everysec和no，分别为： 每一次写操作都会调用一次fsync；每隔一秒进行一次fsync； 不主动调用fsync，依赖于操作系统。 Redis提供了AOF重写功能，来应对文件过大的情况。执行AOF重写时，父进程会fork一个子进程，让子进程来处理数据的持久化。子进程会遍历内存中的所有键值对，对于每一个键值对，会转为一条写操作，并将对应类型的请求协议写入到临时文件中。比如，在一段时间内，服务器处理了客户端的如下请求： SADD key “val1” SADD key “val2” SREM key “val1” SADD key “val3” 则原来的4条命令，在重写后等同于1条命令: SADD key “val2” ”val3” 由于使用了fork命令，为了解决在重写的过程中，因为新的写请求命令到来而导致父子进程的数据不一致的情况，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用。当Redis服务器执行完一个写命令后，它会同时将该命令发送给AOF缓冲区和AOF重写缓冲区。当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号后，将AOF重写缓冲区的命令写到临时AOF文件中，之后将临时AOF文件原子的覆盖现有的AOF文件，该过程是阻塞的进行的。 不同于RDB文件的载入，由于需要执行AOF文件的命令，在使用AOF重建数据库时，Redis服务器会创建一个不带网络连接的伪客户端，使用伪客户端循环的执行文件中的每一个写命令直到AOF文件读取结束。 ","date":"2019-09-22","objectID":"/redis_02_persist/:0:0","tags":["redis"],"title":"Redis持久化","uri":"/redis_02_persist/"},{"categories":["srccode"],"content":"这节介绍Redis基本结构","date":"2019-09-21","objectID":"/redis_01_basic/","tags":["redis"],"title":"Redis基本结构","uri":"/redis_01_basic/"},{"categories":["srccode"],"content":" 之前看了《Redis设计与实现》这本书，对Redis的认识加深了一些，便做了一些总结，同时也记录下自己的一些想法。 这节先介绍Redis提供的基本结构，主要分为底层的基本结构和以对象形式包装的Object结构。 1.SDS C字符串在redis中主要用于无须对字符串值进行修改的地方，对于需要修改字符串的场景，则使用SDS（简单动态字符串）。 SDS的结构如下示： 其中buff是字符串缓冲区，用于存放字符串，len为buf数组中已使用字节的数量，free为buf数组中未使用字节的数量。注意，buff中存放的是二进制数据，使用len属性来判断字符串是否结束，保留’\\0’符号是为了兼容部分C函数。 同C字符串相比，由于SDS记录了相关的使用情况，因而能够以常数复杂度获取字符串长度，并且能够杜绝缓冲区溢出。同时，通过使用空间预分配和惰性空间释放两种策略，能够减少修改字符串时带来的内存重分配次数。 所谓空间预分配是指，当对SDS进行修改的时候，并且需要对SDS空间进行扩展的时候，程序不仅会为SDS分配修改所需要的空间，还会为SDS分配额外的未使用空间。其分配策略是如下定义的：如果对SDS修改后的长度小于1MB，那么程序分配和len属性同样大小的未使用空间；如果对SDS修改后的长度大于等于1MB，那么程序会分配1MB的未使用空间。通过空间预分配策略，redis可以减少连续执行字符串增长操作所需要的内存重分配次数。 所谓惰性空间释放，就是当需要缩短SDS保存的字符串的时候，程序并不立即使用内存重新分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录下来，并等将来使用。 SDS的行为同Java中的StringBuilder类似。 2.list list结构是个标准的无环双向链表实现，结构如下: 具体过程不再讲解，网上对该结构的讲解比较多。 3.dict dict结构是个标准的字典实现，使用链地址法解决冲突。Dict的结构如下: 其中ht是一个长度为2的数组，一般情况下只使用了ht[0]，ht[1]用于rehash过程。rehashidx记录了rehash的过程，-1表示没有在进行。redis采用渐进式rehash的方式来rehash，防止在数量庞大时导致服务器在一段时间内停止服务。 渐进式rehash的主要过程为：为dict的ht[1]哈希表分配空间，可以是扩容，也可以是缩容;将保存在ht[0]中的所有键值对重新计算索引值，rehash到ht[1]上;迁移完成后释放ht[0]，将ht[1]设置为ht[0],并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。 4.jump List 跳表是有序集合的底层实现之一。 关于跳表的细节，可以看下面的介绍 redis使用跳表不用红黑树的原因在于： 在插入、删除、查找以及迭代输出有序序列这几个操作上，跳表跟红黑树的时间复杂度是一样的，但是在按区间查找数据的操作上，跳表的效率比红黑树更高。 跳表较红黑树更好实现，意味着可读性好、不易出错。 跳表更加灵活，可以通过改变索引结构来平衡执行效率和内存消耗之间的关系 5.intset 当一个集合只包含整数值元素，并且这个集合的元素数量不多时，redis就会使用整数集合作为集合的底层实现。下面是intset的结构 其中content用于存储整数集合的值，length为content的长度，encoding为content中存储的整数的类型，可以为int_16,int_32和int_64。 当需要新增元素到intset里时，redis会保证元素是有序的。如果content长度不够或者新增的类型同encoding的类型不同，还会出发intset的升级。升级过程包括重新分配content大小（以新的encoding类型为准），必要时提升encoding的类型，移动元素的位置，最后修改length属性。 注意，intset不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。 6.zipList 当一个列表键只包含少量列表项，并且每个列表项要么就是小整数，要么就是长度比较短的字符串，那么就会使用压缩列表来做列表键的底层实现。 压缩列表的结构如下: 每个zipList节点的组成部分如下: 每个节点保存一个字节数据或者一个整数值，其中字节数组和整数值都允许保存不同的长度,由encoding属性决定。previous_entry_length属性则记录了前一个节点的长度，使用1个字节或者5个字节来存储，在新节点加入时可能引起连锁更新. 7.object Redis以对象的形式来存储键值，提供了字符串对象，列表对象，哈希对象，集合对象和有序集合对象5种类型。并使用引用计数来管理对象的回收。 对象结构的主要属性包括type，encoding和ptr属性。 其中type属性记录了对象的类型，这个属性的值包括: 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 encoding记录了对象使用了什么数据结构的对象底层实现，这个属性的值包括: 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long类型的整数 REDIS_ENCODING_EMBSTR embstr编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 1.REDIS_STRING 字符串对象的编码可以为INT,EMBSTR或者RAW。当字符串对象保存的是整数，且该整数能够用long来表示，则使用int存储整数值;当保存的是一个字符串，且长度小于39字节，则使用embstr编码，大于39字节则使用raw编码.关于两者的区别，可以看下面的说明。而embstr要以39个字节来划分的原因可以看这个说明 2.REDIS_LIST 列表对象的编码可以为ZIPLIST或者LINKEDLIST。 当列表对象可以同时满足以下两个条件时，列表对象使用ziplist编码： 列表对象保存的所有字符串元素的长度都小于64字节; 列表对象保存的元素数量小于512个 若不满足则使用linkedlist编码，该条件可以通过配置文件的配置项list-max-ziplist-value和list-max-ziplist-entries进行修改。 3.REDIS_HASH 哈希对象的编码可以为ZIPLIST或者HASHTABLE 当哈希对象可以同时满足以下两个条件时，哈希对象使用ziplist编码： 哈希对象保存的所有键值对的键和值的字符串当度都小于64字节; 哈希对象保存的键值对数量小于512个 若不满足则使用hashtable编码，该条件可以通过配置文件的配置项hash-max-ziplist-value和hash-max-ziplist-entries进行修改。 4.REDIS_SET 集合对象的编码可以为INTSET或者HASHTABLE 当集合对象可以同时满足以下两个条件时，使用intset编码： 集合对象保存的所有元素都是整数值; 集合对象保存的元素数量不超过512个 若不满足则使用hashtable编码，该条件可以通过配置文件的配置项set-max-intset-entries进行修改。 5.REDIS_ZSET 有序集合的编码可以为ZIPLIST或者SKIPLIST 当有序集合对象同时满足以下两个条件时，使用ziplist 有序集合保存的元素数量小于128个; 有序集合保存的所有元素成员的长度都小于64字节; 若不满足则使用skiplist编码，该条件可以通过配置文件的配置项zset-max-ziplist-entries和zset-max-ziplist-values进行修改。 ","date":"2019-09-21","objectID":"/redis_01_basic/:0:0","tags":["redis"],"title":"Redis基本结构","uri":"/redis_01_basic/"},{"categories":null,"content":"关于","date":"2019-08-02","objectID":"/about/","tags":null,"title":"相关平台","uri":"/about/"},{"categories":null,"content":" 微信公众号 头条号 ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"相关平台","uri":"/about/"}]